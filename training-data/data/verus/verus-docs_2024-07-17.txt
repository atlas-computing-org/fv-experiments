================
File: ./guide/README.md
================

# Requirements

To build the guide locally, you will need to install [mdBook](https://rust-lang.github.io/mdBook/).
The simplest approach is often to run `cargo install mdbook`.

# Building

To build the guide, run `mdbook serve`.  This will render the guide
and start a local webserver where you can view your updated guide.

================
File: ./guide/book.toml
================

[book]
language = "en"
multilingual = false
src = "src"
title = "Verus Tutorial and Reference"

[rust]
edition = "2018"

[output.html]
curly-quotes = true

[output.html.playground]
runnable = false

================
File: ./guide/src/reference-implication.md
================

# Implication (==&gt;, &lt;==, and &lt;==&gt;)

The operator `P ==> Q`, read _P implies Q_, is equivalent to `!P || Q`.

This can also be written backwards: `Q <== P` is equivalent to `P ==> Q`.

Finally, `P <==> Q` is equivalent to `P == Q`. It is sometimes useful for readability,
and because `<==>` has the same syntactic precedence as `==>`
rather than the precedence of `==`.

================
File: ./guide/src/exec_lib.md
================

# Executable libraries: Vec

The previous section discussed the mathematical collection types
`Seq`, `Set`, and `Map`.
This section will discuss `Vec`, an executable implementation of `Seq`. 
Verus supports some functionality of Rust's `std::vec::Vec` type. To use 
`Vec`, include `use std::vec::Vec;` in your code.

You can allocate `Vec` using `Vec::new` and then push elements into it:

```rust
{{#include ../../../rust_verify/example/guide/lib_examples.rs:test_vec1}}
```

The code above is able to make assertions directly about the `Vec` value `v`.
You could also write more compilicated specifications and proofs about `Vec` values.
In general, though, Verus encourages programmers to write `spec` functions
and `proof` functions about mathematical types like `Seq`, `Set`, and `Map` instead
of hard-wiring the specifications and proofs to particular concrete datatypes like `Vec`.
This allows `spec` functions and `proof` functions to focus on the essential ideas,
written in terms of mathematical types like `Seq`, `Set`, `Map`, `int`, and `nat`,
rather than having to fiddle around with finite-width integers like `usize`,
worry about arithmetic overflow, etc.

Of course, there needs to be a connection between the mathematical types
and the concrete types, and specifications in `exec` functions will commonly have to move
back and forth between mathematical abstractions and concrete reality.
To make this easier, Verus supports the syntactic sugar `@` for extracting
a mathematical `view` from a concrete type.
For example, `v@` returns a `Seq` of all the elements in the vector `v`:

```rust
{{#include ../../../rust_verify/example/guide/lib_examples.rs:test_vec2}}
```

Using the `Seq` view of the `Vec` allows us to use the various features of `Seq`,
such as concatenation and subsequences,
when writing specifications about the `Vec` contents.

Verus support for `std::vec::Vec` is currently being expanded. For up-to-date
documentation, visit [this link](https://verus-lang.github.io/verus/verusdoc/vstd/std_specs/vec/index.html).
Note that these functions provide specifications for `std::vec::Vec` functions. Thus,
for example, `ex_vec_insert` represents support for the `Vec` function `insert`. Code written 
in Verus should use `insert` rather than `ex_vec_insert`.

Documentation for `std::vec::Vec` functionality can be found [here](https://doc.rust-lang.org/std/vec/struct.Vec.html).

================
File: ./guide/src/reference-var-modes.md
================

# Variable modes

In addition to having three function modes, Verus has three _variable_ modes: `exec`, `tracked`, and `ghost`. Only `exec` variables exist in the compiled code, while `ghost` and `tracked` variables are "erased" from the compiled code.

See [this tutorial page](./modes.md) for an introduction to the concept of modes.
The tracked mode is an advanced feature, and is discussed more in the [concurrency guide](https://verus-lang.github.io/verus/state_machines/intro.html).

## Variable modes and function modes

Which variables are allowed depends on the expression mode, according to the following table:

|            | Default variable mode | `ghost` variables | `tracked` variables | `exec` variables |
|------------|-----------------------|-------------------|---------------------|------------------|
| spec code  | `ghost`               | yes               |                     |                  |
| proof code | `ghost`               | yes               | yes                 |                  |
| exec code  | `exec`                | yes               | yes                 | yes              |

Although `exec` code allows variables of any mode, there are some restrictions; see below.

## Using `tracked` and `ghost` variables from a `proof` function.

By default, any variable in a proof function has `ghost` mode. Parameters, variables,
and return values may be marked tracked. For example:

```rust
fn some_proof_fn(tracked param: Foo) -> (tracked ret: RetType) {
    let tracked x = ...;
}
```

For return values, the `tracked` keyword can only apply to the entire return type.
It is not possible to selectively apply `tracked` to individual elements of a tuple,
for example.

To mix-and-match tracked and ghost data, there are a few possibilities.
First, you can create a struct
marked `tracked`, which individual fields either marked `ghost` or `tracked`.

Secondly, you can use the `Tracked` and `Ghost` types from Verus's builtin library to
create tuples like `(Tracked<X>, Ghost<Y>)`. These support pattern matching:

```rust
proof fn some_call() -> (tracked ret: (Tracked<X>, Ghost<Y>)) { ... }

proof fn example() {
    // The lower-case `tracked` keyword is used to indicate the right-hand side
    // has `proof` mode, in order to allow the `tracked` call.
    // The upper-case `Tracked` and `Ghost` are used in the pattern matching to unwrap
    // the `X` and `Y` objects.
    let tracked (Tracked(x), Ghost(y)) = some_call();
}
```

## Using `tracked` and `ghost` variables from an `exec` function.

Variables in `exec` code may be marked `tracked` or `ghost`. These variables will be erased
when the code is compiled. However, there are some restrictions.
In particular, variables marked `tracked` or `ghost` may be declared anywhere in an `exec` block. However, such variables may only be _assigned_ to from inside a `proof { ... }` block.

```rust
fn some_exec_fn() {
    let ghost mut x = 5; // this is allowed

    proof {
        x = 7; // this is allowed
    }

    x = 9; // this is not allowed
}
```

Futhermore:

 * Arguments and return values for an `exec` function must be `exec` mode.

 * Struct fields of an `exec` struct must be `exec` mode.

To work around these, programs can use the `Tracked` and `Ghost` types.
Like in proof code, Verus supports pattern-matching for these types.

```rust
exec fn example() {
    // Because of the keyword `tracked`, Verus interprets the right-hand side
    // as if it were in a `proof` block.
    let tracked (Tracked(x), Ghost(y)) = some_call();
}
```

To handle parameters that must be passed via `Tracked` or `Ghost` types, 
you can unwrap them via pattern matching:

```rust
exec fn example(Tracked(x): Tracked<X>, Ghost(y): Ghost<Y>) {
    // Use `x` as if it were declared `let tracked x`
    // Use `y` as if it were declared `let tracked y`
}
```

## Cheat sheet

### Proof function, take tracked or ghost param

```rust
proof fn example(tracked x: X, ghost y: Y)
```

To call this function from proof code:

```rust
proof fn test(tracked x: X, ghost y: Y) {
    example(x, y);
}
```

To call this function from exec code:

```rust
fn test() {
    let tracked x = ...;
    let ghost y = ...;

    // From a proof block:
    proof { example(x, y); }
}
```

### Proof function, return ghost param

```rust
proof fn example() -> (ret: Y)
```

To call this function from proof code:

```rust
proof fn test() {
    let y = example();
}
```

To call this function from exec code:

```rust
fn test() {
    let ghost y = example();
}
```

### Proof function, return tracked param

```rust
proof fn example() -> (tracked ret: X)
```

To call this function from proof code:

```rust
proof fn test() {
    let tracked y = example();
}
```

To call this function from exec code:

```rust
fn test() {
    // In a proof block:
    proof { let tracked y = example(); }

    // Or outside a proof block:
    let tracked y = example();
}
```

### Proof function, return both a ghost param and tracked param

```rust
proof fn example() -> (tracked ret: (Tracked<X>, Ghost<Y>))
```

To call this function from proof code:

```rust
proof fn test() {
    let tracked (Tracked(x), Ghost(y)) = example();
}
```

To call this function from exec code:

```rust
fn test() {
    // In a proof block:
    proof { let tracked (Tracked(x), Ghost(y)) = example(); }

    // or outside a proof block:
    let tracked (Tracked(x), Ghost(y)) = example();
}
```

### Exec function, take a tracked and ghost parameter:

```rust
fn example(Tracked(x): Tracked<X>, Ghost(y): Ghost<Y>)
```

To call this function from exec code:

```rust
fn test() {
    let tracked x = ...;
    let ghost y = ...;

    example(Tracked(x), Ghost(y));
}
```

### Exec function, return a tracked and ghost value:

```rust
fn example() -> (Tracked<X>, Ghost<Y>)
```

To call this function from exec code:

```rust
fn test() {
    let (Tracked(x), Ghost(y)) = example();
}
```

### Exec function, take a tracked parameter that is a mutable reference:

```rust
fn example(Tracked(x): Tracked<&mut X>)
```

To call this function from exec code:

```rust
fn test() {
    let tracked mut x = ...;

    example(Tracked(&mut x));
}
```

================
File: ./guide/src/breaking_proofs_into_pieces.md
================

# Breaking proofs into smaller pieces

## Motivation

If you write a long function with a lot of proof code, Verus will
correspondingly give the SMT solver a long and difficult problem to solve. So
one can improve solver performance by breaking that function down into smaller
pieces. This performance improvement can be dramatic because solver response
time typically increases nonlinearly as proof size increases. After all,
having twice as many facts in scope gives the solver far more than twice as
many possible paths to search for a proof. As a consequence, breaking
functions down can even make the difference between the solver timing out and
the solver succeeding quickly.

## Moving a subproof to a lemma

If you have a long function, look for a modest-size piece `P` of it that
functions as a proof of some locally useful set of facts `S`. Replace `P` with
a call to a lemma whose postconditions are `S`, then make `P` the body of that
lemma. Consider what parts of the original context of `P` are necessary to
establish `S`, and put those as `requires` clauses in the lemma. Those
`requires` clauses may involve local variables, in which case pass those
variables to the lemma as parameters.

For instance:
```
fn my_long_function(x: u64, ...)
{
    let y: int = ...;
    ... // first part of proof, establishing fact f(x, y)
    P1; // modest-size proof...
    P2; //   establishing...
    P3; //   facts s1 and s2...
    P4; //   about x and y
    ... // second part of proof, using facts s1 and s2
}
```
might become
```
proof fn my_long_function_helper(x: u64, y: int)
    requires
        f(x, y)
    ensures
        s1(x),
        s2(x, y)
{
    P1; // modest-size proof...
    P2; //   establishing...
    P3; //   facts s1 and s2...
    P4; //   about x and y
}

fn my_long_function(x: u64, ...)
{
    ... // first part of proof, establishing fact f(x, y)
    my_long_function_helper(x, y);
    ... // second part of proof, using facts s1 and s2
}

```

You may find that, once you've moved `P` into the body of the lemma, you can
not only remove `P` from the long function but also remove significant
portions of `P` from the lemma where it was moved to. This is because a lemma
dedicated solely to establishing `S` will have a smaller context for the
solver to reason about. So less proof annotation may be necessary to get it to
successfully and quickly establish `S`. For instance:

```
proof fn my_long_function_helper(x: u64, y: int)
    requires
        f(x, y)
    ensures
        s1(x),
        s2(x, y)
{
    P1; // It turns out that P2 and P3 aren't necessary when
    P4; //    the solver is focused on just f, s1, s2, x, and y.
}
```

## Dividing a proof into parts 1, 2, ..., n

Another approach is to divide your large function's proof into `n` consecutive
pieces and put each of those pieces into its own lemma. Make the first lemma's
`requires` clauses be the `requires` clauses for the function, and make its
`ensures` clauses be a summary of what its proof establishes. Make the second
lemma's `requires` clauses match the `ensures` clauses of the first lemma, and
make its `ensures` clauses be a summary of what it establishes. Keep going
until lemma number `n`, whose `ensures` clauses should be the `ensures`
clauses of the original function. Finally, replace the original function's
proof with a sequence of calls to those `n` lemmas in order.


For instance:
```
proof fn my_long_function(x: u64)
    requires r(x)
    ensures  e(x)
{
    P1;
    P2;
    P3;
}
```
might become
```
proof fn my_long_function_part1(x: u64) -> (y: int)
    requires
        r(x)
    ensures
        mid1(x, y)
{
    P1;
}

proof fn my_long_function_part2(x: u64, y: int)
    requires
        mid1(x, y)
    ensures
        mid2(x, y)
{
    P2;
}

proof fn my_long_function_part3(x: u64, y: int)
    requires
        mid2(x, y)
    ensures
        e(x)
{
    P3;
}

proof fn my_long_function(x: u64)
    requires r(x)
    ensures  e(x)
{
    let y = my_long_function_part1(x);
	my_long_function_part2(x, y);
	my_long_function_part3(x, y);
}

```
Since the expressions `r(x)`, `mid1(x, y)`, `mid2(x, y)`, and `e(x)` are each
repeated twice, it may be helpful to factor each out as a spec function and
thereby avoid repetition.

================
File: ./guide/src/syntax.md
================

# Verus Syntax

The code below illustrates a large swath of Verus' syntax.

```rust
{{#include ../../../rust_verify/example/syntax.rs}}
```

================
File: ./guide/src/quantproofs.md
================

# Proofs about forall and exists

The previous sections emphasized the importance of triggers
for `forall` and `exists` expressions.
Specifically, if you know `forall|i| f(i)`,
then the SMT solver will instantiate `i` by looking at triggers,
and if you want to prove `exists|i| f(i)`,
then the SMT solver will look at triggers to find a witness `i` such that `f(i)` is true.
In other words, *using* a `forall` expression relies on triggers
and *proving* an `exists` expression relies on triggers.
We can write these cases in the following table:

|        | proving                                 | using                                |
|--------|-----------------------------------------|--------------------------------------|
| forall | usually just works; otherwise assert-by | triggers                             |
| exists | triggers                                | usually just works; otherwise choose |

What about the other two cases,
proving a `forall` expression and using an `exists` expression?
These cases are actually easier to automate and do not rely on triggers.
In fact, they often just work automatically,
as in the following examples:

```rust
{{#include ../../../rust_verify/example/guide/quants.rs:just_works}}
```

In these examples, the triggers play no role.
To emphasize this, we've used a `dummy` function for the trigger
that doesn't even appear anywhere else in the examples,
and the SMT solver still verifies the functions with no difficulty.
(Note, though, that if you called one of the functions above,
then the caller would have to prove the `exists` expression
or use the `forall` expression,
and the caller would have to deal with triggers.)

If you want some intuition for why the SMT solver doesn't
rely on triggers to verify the code above,
you can think of the verification as being similar to the verification of the following code,
where the quantifiers are eliminated and the quantified variables
are hoisted into the function parameters:

```rust
{{#include ../../../rust_verify/example/guide/quants.rs:hoist}}
```

## Proving forall with assert-by

Sometimes a proof doesn't "just work" like it does in the simple examples above.
For example, the proof might rely on a lemma that is proved by induction,
which the SMT solver cannot prove completely automatically.
Suppose we have a lemma that proves `f(i)` for any even `i`:

```rust
spec fn f(i: int) -> bool { ... }

proof fn lemma_even_f(i: int)
    requires
        is_even(i),
    ensures
        f(i),
{ ... }
```

Now suppose we want to prove that `f(i)` is true for all even `i`:

```rust
{{#include ../../../rust_verify/example/guide/quants.rs:test_even_f_fail1}}
```

The proof above fails because it doesn't call `lemma_even_f`.
If we try to call `lemma_even_f`, though, we immediately run into a problem:
we need to pass `i` as an argument to the lemma,
but `i` isn't in scope:

```rust
{{#include ../../../rust_verify/example/guide/quants.rs:test_even_f_fail2}}
```

To deal with this, Verus supports a special form of `assert ... by`
for proving `forall` expressions:

```rust
{{#include ../../../rust_verify/example/guide/quants.rs:test_even_f}}
```

Inside the body of the `assert ... by`,
the variables of the `forall` are in scope
and the left-hand side of the `==>` is assumed.
This allows the body to call `lemma_even_f(i)`.

## Using exists with choose

The example above needed to bring a `forall` quantifier variable into scope
in order to call a lemma.
A similar situation can arise for `exists` quantifier variables.
Suppose we have the following lemma to prove `f(i)`:

```rust
spec fn g(i: int, j: int) -> bool { ... }

proof fn lemma_g_proves_f(i: int, j: int)
    requires
        g(i, j),
    ensures
        f(i),
{ ... }
```

If we know that there exists some `j` such that `g(i, j)` is true,
we should be able to call `lemma_g_proves_f`.
However, we run into the problem that `j` isn't in scope:

```rust
{{#include ../../../rust_verify/example/guide/quants.rs:test_g_proves_f_fails}}
```

In this situation,
we can use `choose` (discussed in the [previous section](./exists.md))
to extract the value `j` from the `exists` expression:

```rust
{{#include ../../../rust_verify/example/guide/quants.rs:test_g_proves_f}}
```

================
File: ./guide/src/static.md
================

# Static items

Verus supports static items, similar to `const` items. Unlike `const` items, though,
`static` items are only usable in `exec` mode. Note that this requires them to be
_explicitly_ marked as `exec`:

```
exec static x: u64 = 0;
```

The reason for this is consistency with `const`; for `const` items, the default mode
for an unmarked const item is the [dual `spec`-`exec` mode](./const.md).
However, this mode is not supported for `static` items; therefore, static items
need to be explicitly marked `exec`.

Note there are some **limitations** to the current support for `static` items.
Currently, a static item cannot be referenced from a spec expression. This means, for example,
that you can't prove that two uses of the same static item give the same value
if those uses are in different functions. We expect this limitation will be lifted
in the future.

================
File: ./guide/src/calc.md
================

# Structured Proofs by Calculation

## Motivation

Sometimes, you need to establish some relation `R` between two expressions, say,
`a_1` and `a_n`, where it might be easier to do this in a series of steps, `a_1`
to `a_2`, `a_2` to `a_3`, ... all the way to `a_n`. One might do this by just
doing all the steps at once, but as mentioned in the section on
[assert-by](./assert_by.md), a better approach might be to split it into a
collection of restricted contexts. This is better, but still might not be ideal,
since you need to repeat each of the intermediate expressions at each point.

## `calc!`ulations, to Reduce Redundant Redundancy

The `calc!` macro supports structured proofs through calculations.

In particular, one can show `a_1 R a_n` for some transitive relation `R` by performing a series
of steps `a_1 R a_2`, `a_2 R a_3`, ... `a_{n-1} R a_n`. The calc macro provides both convenient
syntax sugar to perform such a proof conveniently, without repeating oneself too often, or
exposing the internal steps to the outside context.

The expected usage looks like:

```rust
calc! {
  (R)
  a_1; { /* proof that a_1 R a_2 */ }
  a_2; { /* proof that a_2 R a_3 */ }
   ...
  a_n;
}
```

For example,

```rust
{{#include ../../../rust_verify/example/guide/calc.rs:simple}}
```

which is equivalent to proving `a <= 5` using `a <= b <= 5`. In this case, each
of the intermediate proofs are trivial, thus have an empty `{}` block, but in
general, can have arbitrary proofs inside their blocks.

Notice that you mention `a_1`, `a_2`, ... `a_n` only once each. Additionally,
the proof for each of the steps is localized, and restricted to only its
particular step, ensuring that proof-context is not polluted.

The body of the function where this `calc` statement is written only gets to see
`a_1 R a_n`, and not any of the intermediate steps (or their proofs), further
limiting proof-context pollution.

Currently, the `calc!` macro supports common transitive relations for `R` (such
as `==` and `<=`). This set of relations may be extended in the future.

## Relating Relations to Relations

While a relation like `<=` might be useful to use like above, it is possible
that not every intermediate step needs a `<=`; sometimes one might be able to be
more precise, and maintaining this (especially for documentation/readability
reasons) might be useful. For example, one might want to say `a_1 <= a_2 == a_3
<= a_4 < a_5 <= ...`.

This is supported by `calc` by specifying the extra intermediate relations
inline (with the default being the high-level relation). These relations are
checked to be consistent with the top-level relation, in order to maintain
transitivity (so for example, using `>` in the above chain would be caught and
reported with a helpful message).

A simple example of using intermediate relations looks like the following:

```rust
{{#include ../../../rust_verify/example/guide/calc.rs:transitive}}
```

This example is equivalent to saying `x <= y` using `x == 5 - 3 < 5 <= y`.

================
File: ./guide/src/overview.md
================

# Verus overview

Verus is a tool for verifying the correctness of code written in Rust.
The main goal is to verify full functional correctness of low-level systems code,
building on ideas from existing verification frameworks like
[Dafny](https://github.com/dafny-lang/dafny),
[Boogie](https://github.com/boogie-org/boogie),
[F*](https://github.com/FStarLang/FStar),
[VCC](https://www.microsoft.com/en-us/research/project/vcc-a-verifier-for-concurrent-c/),
[Prusti](https://github.com/viperproject/prusti-dev),
[Creusot](https://github.com/xldenis/creusot),
[Aeneas](https://github.com/AeneasVerif/aeneas),
[Cogent](https://github.com/NICTA/cogent),
[Coq](https://coq.inria.fr/),
and
[Isabelle/HOL](https://isabelle.in.tum.de/overview.html).
Verification is static: Verus adds no run-time checks,
but instead uses computer-aided theorem proving to statically verify
that executable Rust code will always satisfy some user-provided specifications
for all possible executions of the code.

In more detail, Verus aims to:
- provide a pure mathematical language for expressing specifications
  (like Dafny, Creusot, F*, Coq, Isabelle/HOL)
- provide a mathematical language for expressing proofs
  (like Dafny, F*, Coq, Isabelle/HOL)
  based exclusively on classical logic (like Dafny)
- provide a low-level, imperative language for expressing executable code (like VCC),
  based on Rust (like Prusti, Creusot, and Aeneas)
- generate small, simple verification conditions that an SMT solver
  like [Z3](https://microsoft.github.io/z3guide/docs/logic/intro) can solve efficiently,
  based on the following principles:
  - keep the mathematical specification language close to
    the SMT solver's mathematical language (like Boogie)
  - use lightweight linear type checking, rather than SMT solving,
    to reason about memory and aliasing
    (like Cogent, Creusot, Aeneas, and [linear Dafny](https://github.com/secure-foundations/dafny/tree/betr/docs/Linear))

We believe that Rust is a good language for achieving these goals.
Rust combines low-level data manipulation, including manual memory management,
with an advanced, high-level, safe type system.
The type system includes features commonly found in higher-level verification languages,
including algebraic datatypes (with pattern matching), type classes, and first-class functions.
This makes it easy to express specifications and proofs in a natural way.
More importantly, Rust's type system includes sophisticated support for linear types and borrowing,
which takes care of much of the reasoning about memory and aliasing.
As a result, the remaining reasoning can ignore most memory and aliasing issues,
and treat the Rust code as if it were code written in a purely functional language,
which makes verification easier.

# This guide

This guide assumes that you're already somewhat familiar with the basics of Rust programming.
(If you're not, we recommend spending a couple hours on the [Learn Rust](https://www.rust-lang.org/learn) page.)
Familiarity with Rust is useful for Verus,
because Verus builds on Rust's syntax and Rust's type system to express specifications, proofs, and executable code.
In fact, there is no separate language for specifications and proofs;
instead, specifications and proofs are written in Rust syntax and type-checked with Rust's type checker.
So if you already know Rust, you'll have an easier time getting started with Verus.

Nevertheless, verifying the correctness of Rust code requires concepts and techniques
beyond just writing ordinary executable Rust code.
For example, Verus extends Rust's syntax (via macros) with new concepts for
writing specifications and proofs, such as `forall`, `exists`, `requires`, and `ensures`,
as well as introducing new types, like the mathematical integer types `int` and `nat`.
It can be challenging to prove that a Rust function satisfies its postconditions (its `ensures` clauses)
or that a call to a function satisfies the function's preconditions (its `requires` clauses).
Therefore, this guide's tutorial will walk you through the various concepts and techniques,
starting with relatively simple concepts (basic proofs about integers),
moving on to more moderately difficult challenges (inductive proofs about data structures),
and then on to more advanced topics such as proofs about arrays using `forall` and `exists`
and proofs about concurrent code.

All of these proofs are aided by an automated theorem prover
(specifically, [Z3](https://microsoft.github.io/z3guide/docs/logic/intro),
a satisfiability-modulo-theories solver, or "SMT solver" for short).
The SMT solver will often be able to prove simple properties,
such as basic properties about booleans or integer arithmetic,
with no additional help from the programmer.
However, more complex proofs often require effort from both the programmer and the SMT solver.
Therefore, this guide will also help you understand the strengths and limitations of SMT solving,
and give advice on how to fill in the parts of proofs that SMT solvers cannot handle automatically.
(For example, SMT solvers usually cannot automatically perform proofs by induction,
but you can write a proof by induction simply by writing a recursive Rust function whose `ensures`
clause expresses the induction hypothesis.)

================
File: ./guide/src/reference-flag-record.md
================

# Record flag

Sometimes, you might wish to record an execution trace of Verus to share, along with all the necessary dependencies to reproduce an execution.
This might be useful for either packaging up your verified project, or to report a Verus bug to the [issue tracker](https://github.com/verus-lang/verus/issues).

The `--record` flag will do precisely this.  In particular, to record an execution of Verus (say, `verus foo --bar --baz`), simply add the `--record` flag (for example, `verus foo --bar --baz --record`).  This will re-run Verus, and package all the relevant source files, along with the execution output and version information into a zip file (`yyyy-mm-dd-hh-mm-ss.zip`) in your current directory.

================
File: ./guide/src/forall.md
================

# forall and triggers

Let's take a closer look at the following code,
which uses a `forall` expression in a `requires` clause
to prove an assertion:

```rust
{{#include ../../../rust_verify/example/guide/quants.rs:quants_use_forall}}
```

The `forall` expression means that `0 <= i < s.len() ==> is_even(s[i])`
for all possible integers `i`:

```
...
0 <= -3 < s.len() ==> is_even(s[-3])
0 <= -2 < s.len() ==> is_even(s[-2])
0 <= -1 < s.len() ==> is_even(s[-1])
0 <= 0 < s.len() ==> is_even(s[0])
0 <= 1 < s.len() ==> is_even(s[1])
0 <= 2 < s.len() ==> is_even(s[2])
0 <= 3 < s.len() ==> is_even(s[3])
...
```

There are infinitely many integers `i`, so the list shown above is infinitely long.
We can't expect the SMT solver to literally expand the `forall` into
an infinite list of expressions.
Furthermore, in this example, we only care about one of the expressions,
the expression for `i = 3`,
since this is all we need to prove `assert(is_even(s[3]))`:

```rust
0 <= 3 < s.len() ==> is_even(s[3])
```

Ideally, the SMT solver will choose just the `i` that are likely to be relevant
to verifying a particular program.
The most common technique that SMT solvers use for choosing likely relevant `i`
is based on *triggers*
(also known as SMT patterns or just
[patterns](https://microsoft.github.io/z3guide/docs/logic/Quantifiers)).

A *trigger* is simply an expression or set of expressions that the SMT solver uses as a pattern
to match with.
In the example above, the `#[trigger]` attribute marks the expression `is_even(s[i])`
as the trigger for the `forall` expression.
Based on this attribute,
the SMT solver looks for expressions of the form `is_even(s[...])`.
During the verification of the `test_use_forall` function shown above,
there is one expression that has this form: `is_even(s[3])`.
This matches the trigger `is_even(s[i])` exactly for `i = 3`.
Based on this pattern match, the SMT solver chooses `i = 3` and introduces the following fact:

```rust
0 <= 3 < s.len() ==> is_even(s[3])
```

This fact allows the SMT solver to complete the proof about the assertion
`assert(is_even(s[3]))`.

Triggers are the way you program the instantiations of the `forall` expressions
(and the way you program proofs of `exists` expressions, as discussed in a later section).
By choosing different triggers, you can influence how the `forall` expressions
get instantiated with different values, such as `i = 3` in the example above.
Suppose, for example, we change the assertion slightly so that we assert
`s[3] % 2 == 0` instead of `is_even(s[3])`.
Mathematically, these are both equivalent.
However, the assertion about `s[3] % 2 == 0` fails:

```rust
{{#include ../../../rust_verify/example/guide/quants.rs:trigger_fails}}
```

This fails because there are no expressions matching the pattern `is_even(s[...])`;
the expression `s[3] % 2 == 0` doesn't mention `is_even` at all.
In order to prove `s[3] % 2 == 0`,
we'd first have to mention `is_even(s[3])` explicitly:

```rust
{{#include ../../../rust_verify/example/guide/quants.rs:test_use_forall_succeeds1}}
```

Once the expression `is_even(s[3])` coaxes the SMT solver into instantiating the
`forall` expression with `i = 3`,
the SMT solver can use the resulting `0 <= 3 < s.len() ==> is_even(s[3])`
to prove `s[3] % 2 == 0`.

Alternatively, we could just choose a trigger that is less picky.
For example, the trigger `s[i]` matches any expression of the form
`s[...]`, which includes the `s[3]` inside `s[3] % 2 == 0` and
also includes the `s[3]` inside `is_even(s[3])`:

```rust
{{#include ../../../rust_verify/example/guide/quants.rs:test_use_forall_succeeds2}}
```

In fact, if we omit the `#[trigger]` attribute entirely,
Verus chooses the trigger `s[i]` automatically:

```rust
{{#include ../../../rust_verify/example/guide/quants.rs:test_use_forall_succeeds3}}
```

In fact, Verus prints a note stating that it chose this trigger:

```
note: automatically chose triggers for this expression:
   |
   |         forall|i: int| 0 <= i < s.len() ==> is_even(s[i]), // Verus chooses s[i] as the trigger
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

note:   trigger 1 of 1:
   |
   |         forall|i: int| 0 <= i < s.len() ==> is_even(s[i]), // Verus chooses s[i] as the trigger
   |                                                     ^^^^

note: Verus printed one or more automatically chosen quantifier triggers
      because it had low confidence in the chosen triggers.
```

Verus isn't sure, though,
whether the programmer wants `s[i]` as the trigger or `is_even(s[i])` as the trigger.
It slightly prefers `s[i]` because `s[i]` is smaller than `is_even(s[i])`,
so it chooses `s[i]`,
but it also prints out the note encouraging the programmer to review the decision.
The programmer can accept this decision by writing `#![auto]` before the quantifier body,
which suppresses the note:

```rust
{{#include ../../../rust_verify/example/guide/quants.rs:test_use_forall_succeeds4}}
```

## Good triggers and bad triggers

So ... which trigger is better, `s[i]` or `is_even(s[i])`?
Unfortunately, there's no one best answer to this kind of question.
There are tradeoffs between the two different choices.
The trigger `s[i]` leads to more pattern matches than `is_even(s[i])`.
More matches means that the SMT solver is more likely to find relevant
instantiations that help a proof succeed.
However, more matches also means that the SMT solver is more likely to generate
irrelevant instantiations that clog up the SMT solver with useless information,
slowing down the proof.

In this case, `s[i]` is probably a good trigger to choose.
It matches whenever the function `test_use_forall_succeeds4`
talks about an element of the sequence `s`,
yielding a fact that is likely to be useful for reasoning about `s`.
By contrast, suppose we chose the following bad trigger, `0 <= i`:

```rust
{{#include ../../../rust_verify/example/guide/quants.rs:test_use_forall_bad1}}
```

In principle, this would match any value that is greater than or equal to 0,
which would include values that have nothing to do with `s` and are unlikely
to be relevant to `s`.
In practice, Verus doesn't even let you do this:
triggers cannot contain equality or disequality (`==`, `===`, `!=`, or `!==`),
any basic integer arithmetic operator (like `<=` or `+`),
or any basic boolean operator (like `&&`):

```
error: trigger must be a function call, a field access, or a bitwise operator
    |
    |         forall|i: int| (#[trigger](0 <= i)) && i < s.len() ==> is_even(s[i]),
    |                        ^^^^^^^^^^^^^^^^^^^^
```

If we really wanted, we could work around this by introducing an extra function:

```rust
{{#include ../../../rust_verify/example/guide/quants.rs:test_use_forall_bad2}}
```

but this trigger fails to match, because the code doesn't explicitly mention `nonnegative(3)`
(you'd have to add an explicit `assert(nonnegative(3))` to make the code work).
This is probably just as well; `s[i]` is simply a better trigger than `nonnegative(i)`,
because `s[i]` mentions `s`, and the whole point of
`forall|i: int| 0 <= i < s.len() ==> is_even(s[i])`
is to say something about the elements of `s`,
not to say something about nonnegative numbers.

================
File: ./guide/src/equality.md
================

# Equality

Equality behaves differently in ghost code than in executable code.
In executable code, Rust defines `==` to mean a call to the `eq` function of the `PartialEq` trait:

```rust
{{#include ../../../rust_verify/example/guide/equality.rs:eq1}}
```

For built-in integer types like `u8`, the `x.eq(y)` function is defined as we'd expect,
returning `true` if `x` and `y` hold the same integers.
For user-defined types, though, `eq` could have other behaviors:
it might have side effects, behave nondeterministically,
or fail to fulfill its promise to implement an
equivalence relation,
even if the type implements the Rust [`Eq` trait](https://doc.rust-lang.org/std/cmp/trait.Eq.html):

```rust
{{#include ../../../rust_verify/example/guide/equality.rs:eq2}}
```

In ghost code, by contrast, the `==` operator is always an equivalence relation
(i.e. it is reflexive, symmetric, and transitive):

```rust
{{#include ../../../rust_verify/example/guide/equality.rs:eq3}}
```

Verus defines `==` in ghost code to be true when:
- for two integers or booleans, the values are equal
- for two structs or enums, the types are the same and the fields are equal
- for two `&` references, two Box values, two Rc values, or two Arc values, the pointed-to values are the same
- for two RefCell values or two Cell values, the pointers to the interior data are equal (not the interior contents)

In addition, collection dataypes such as `Seq<T>`, `Set<T>`, and `Map<Key, Value>`
have their own definitions of `==`,
where two sequences, two sets, or two maps are equal if their elements are equal.
As explained more in [specification libraries](spec_lib.md) and [extensional equality](extensional_equality.md),
these sometimes require the "extensional equality" operator `=~=` to help prove equality
between two sequences, two sets, or two maps.

================
File: ./guide/src/while.md
================

# Loops and invariants

The previous section developed a tail-recursive implementation of `triangle`:

```rust
{{#include ../../../rust_verify/example/guide/recursion.rs:tail}}
```

We can rewrite this as a `while` loop as follows:

```rust
{{#include ../../../rust_verify/example/guide/recursion.rs:loop}}
```

The loop is quite similar to the tail-recursive implementation.
(In fact, internally, Verus verifies the loop as if it were its own function,
separate from the enclosing `loop_triangle` function.)
Where the tail-recursive function had preconditions,
the loop has *loop invariants* that describe what must
be true before and after each iteration of the loop.
For example, if `n = 10`,
then the loop invariant must be true 11 times:
before each of the 10 iterations,
and after the final iteration.

Notice that the invariant `idx <= n` allows for the possibility that `idx == n`,
since this will be the case after the final iteration.
If we tried to write the invariant as `idx < n`,
then Verus would fail to prove that the invariant is maintained after the final iteration.

After the loop exits,
Verus knows that `idx <= n` (because of the loop invariant)
and it knows that the loop condition `idx < n` must have been false
(otherwise, the loop would have continued).
Putting these together allows Verus to prove that `idx == n` after exiting the loop.
Since we also have the invariant `sum == triangle(idx as nat)`,
Verus can then substitute `n` for `idx` to conclude `sum == triangle(n as nat)`,
which proves the postcondition of `loop_triangle`.

Just as verifying functions requires some programmer effort to write
appropriate preconditions and postconditions,
verifying loops requires programmer effort to write loop invariants.
The loop invariants have to be neither too weak (`invariant true` is usually too weak)
nor too strong (`invariant false` is too strong),
so that:
- the invariants hold upon the initial entry to the loop
  (e.g. `idx <= n` holds for the initial value `idx = 0`, since `0 <= n`)
- the invariant still holds at the end of the loop body,
  so that the invariant is maintained across loop iterations
- the invariant is strong enough to prove the properties we want
  to know after the loop exits (e.g. to prove `loop_triangle`'s postcondition)

As mentioned above,
Verus verifies the loop separately from the function that contains the loop
(e.g. separately from `loop_triangle`).
This means that the loop does not automatically inherit preconditions
like `triangle(n as nat) < 0x1_0000_0000` from the surrounding function ---
if the loop relies on these preconditions,
they must be listed explicitly in the loop invariants.
(The reason for this is to improve the efficiency of the SMT solving
for large functions with large while loops;
verification runs faster if Verus breaks the surrounding function and the loops into separate pieces
and verifies them modularly.)

================
File: ./guide/src/ghost_vs_exec.md
================

# Ghost code vs. exec code

The purpose of `exec` code is to manipulate physically real values ---
values that exist in physical electronic circuits when a program runs.
The purpose of ghost code, on the other hand,
is merely to *talk about* the values that `exec` code manipulates.
In a sense, this gives ghost code supernatural abilities:
ghost code can talk about things that could not be physically implemented at run-time.
We've already seen one example of this with the types `int` and `nat`,
which can only be used in ghost code.
As another example, ghost code can talk about the result of division by zero:

```rust
{{#include ../../../rust_verify/example/guide/modes.rs:ghost_abilities0}}
```

This simply reflects the SMT solver's willingness to reason about the result of division by zero
[as an unspecified integer value](https://microsoft.github.io/z3guide/docs/theories/Arithmetic/#division).
By contrast, Verus reports a verification failure if `exec` code attempts to divide by zero:

```
error: possible division by zero
    |
    |     let y = x / 0; // FAILS
    |             ^^^^^
```

Two particular abilities of ghost code[^note_tracked] are worth keeping in mind:
- Ghost code can copy values of any type,
  even if the type doesn't implement the Rust `Copy` trait.
- Ghost code can create a value of any type[^note_uninhabited],
  even if the type has no public constructors
  (e.g. even if the type is struct whose fields are all private to another module).

For example, the following `spec` functions create and duplicate values of type `S`,
defined in another module with private fields and without the `Copy` trait:

```rust
{{#include ../../../rust_verify/example/guide/modes.rs:ghost_abilities1}}
```

These operations are not allowed in `exec` code.
Furthermore, values from ghost code are not allowed to leak into `exec` code ---
what happens in ghost code stays in ghost code.
Any attempt to use a value from ghost code in `exec` code will result in a compile-time error:

```rust
{{#include ../../../rust_verify/example/guide/modes.rs:ghost_abilities2}}
```

```
error: cannot call function with mode spec
    |
    |         let pair = duplicate_S(s); // FAILS
    |                    ^^^^^^^^^^^^^^
```

As an example of ghost code that uses these abilities,
a call to the Verus [`Seq::index(...)` function](https://github.com/verus-lang/verus/blob/main/source/vstd/seq.rs)
can duplicate a value from the sequence, if the index `i` is within bounds,
and create a value out of thin air if `i` is out of bounds:
```
impl<A> Seq<A> {
...
    /// Gets the value at the given index `i`.
    ///
    /// If `i` is not in the range `[0, self.len())`, then the resulting value
    /// is meaningless and arbitrary.

    pub spec fn index(self, i: int) -> A
        recommends 0 <= i < self.len();
...
}
```

---

[^note_tracked]: Variables in `proof` code can opt out of these special abilities using
the `tracked` annotation (see section TODO),
but this is an advanced feature that can be ignored for now.

[^note_uninhabited]: This is true even if the type has no values in `exec` code,
like the Rust `!` "never" type
(see the "bottom" value in [this technical discussion](https://github.com/Chris-Hawblitzel/rust/wiki/Three-kinds-of-code-...-specification,-proof,-and-executable)).

================
File: ./guide/src/SUMMARY.md
================

# Summary

[Verus overview](./overview.md)

# Getting started

- [Getting started](./getting_started.md)

# Tutorial

- [Basic specifications](specs.md)
    - [assert, requires, ensures, ghost code](./requires_ensures.md)
    - [Expressions and operators for specifications](./operators.md)
    - [Integers and arithmetic](./integers.md)
    - [Equality](./equality.md)
- [Specification code, proof code, executable code](modes.md)
    - [spec functions](spec_functions.md)
    - [proof functions, proof blocks, assert-by](proof_functions.md)
    - [spec functions vs. proof functions, recommends](spec_vs_proof.md)
    - [Ghost code vs. exec code](ghost_vs_exec.md)
    - [const declarations](const.md)
- [Recursion and loops](recursion_loops.md)
    - [Recursive spec functions, decreases, fuel](recursion.md)
    - [Recursive exec and proof functions, proofs by induction](induction.md)
    - [Loops and invariants](while.md)
        - [Loops with break](break.md)
    - [Lexicographic decreases clauses and mutual recursion](lex_mutual.md)
- [Datatypes: struct and enum]() <!--- Andrea --->
    - [Defining datatypes]() <!--- Andrea --->
    - [Querying the discriminant (`#[is_variant]`)]() <!--- Andrea --->
    - [Proving properties of fields]() <!--- Andrea --->
- [Basic libraries and spec closures](vstd.md)
    - [Specification libraries: Seq, Set, Map](spec_lib.md)
    - [INTERLUDE: using assert and assume to develop proofs](develop_proofs.md)
    - [Spec closures](spec_closures.md)
    - [Executable libraries: Vec](exec_lib.md)
- [Quantifiers](quants.md)
    - [forall and triggers](forall.md)
    - [Multiple variables, multiple triggers, matching loops](multitriggers.md)
    - [exists and choose](exists.md)
    - [Proofs about forall and exists](quantproofs.md)
    - [Example: binary search](binary_search.md)
    - [Ambient (`broadcast`) lemmas](broadcast_proof.md)
- [Higher-order executable functions]()
    - [Passing functions as values](./exec_funs_as_values.md)
    - [Closures]()
- [SMT solving, automation, and where automation fails](smt_failures.md) <!--- Chris --->
    - [What's decidable, what's undecidable, what's fast, what's slow]() <!--- Chris --->
    - [Integers and nonlinear arithmetic](nonlinear.md)
    - [Bit vectors and bitwise operations](bitvec.md)
    - [forall and exists: writing and using triggers, inline functions]() <!--- Chris --->
    - [Recursive functions]() <!--- Chris --->
    - [Extensional equality](extensional_equality.md)
    - [Libraries: incomplete axioms for Seq, Set, Map]() <!--- Chris --->
- [Improving SMT performance]() <!--- Chris --->
    - [Modules, hiding, opaque, reveal]() <!--- Chris --->
    - [Quantifier profiling](profiling.md) <!--- Bryan --->
    - [Hiding local proofs with `assert (...) by { ... }`](assert_by.md)
    - [Structured proof by calculation](calc.md) <!--- JayB --->
    - [Proof by computation](assert_by_compute.md) <!--- Bryan --->
    - [Spinning off separate SMT queries]()
    - [Breaking proofs into smaller pieces](breaking_proofs_into_pieces.md)
- [Mutation, references, and borrowing]() <!--- Andrea --->
    - [Requires and ensures with mutable references]() <!--- Andrea --->
    - [Assertions containing mutable references]() <!--- Andrea --->
- [Traits]()
- [Ghost and tracked variables]()
- [Low-level pointers and concurrency]()
- [Attributes and directives]()
    - [external and external_body]()
    - [inline]()
    - [opaque]()
    - [decreases_by]()
    - [when_used_as_spec]()
- [Strings]() <!--- Andrea --->
    - [String library]() <!--- Andrea --->
    - [String literals]() <!--- Andrea --->
- [Macros]()
- [Tools and command-line options]()
    - [Proof Debugger]() <!--- Chanhee --->
    - [IDE Support](ide_support.md)
    - [Syntax Highlighting]()

- [Verification and Rust]()
  - [Why Rust?]()
  - [Supported Rust features]()
  - [Borrowing and lifetimes]()
  - [Mutable borrows]()
  - [Interior mutability](./interior_mutability.md)
  - [Alternatives to unsafe]()

- [Understanding the guarantees of a verified program]()
  - [Assumptions and trusted components]()
  - [Identifying a project's TCB]()
  - [Memory safety is conditional on verification](./memory-safety.md)

- [Project setup and development]()
  - [Working with crates]()
  - [Invoking Verus code from Rust]()
  - [Documentation with Rustdoc]()



# Reference

- [Supported and unsupported Rust features](./features.md)
- [Verus syntax overview](syntax.md)
- [Modes]()
  - [Function modes]()
  - [Variable modes](./reference-var-modes.md)
- [Spec expressions]()
  - [Rust subset]()
  - [Arithmetic]()
  - [Spec equality ==]()
  - [Extensional equality `=~=` and `=~~=`]()
  - [&&& and |||]()
  - [Chained operators](./reference-chained-op.md)
  - [Implication (`==>`, `<==`, and `<==>`)](./reference-implication.md)
  - [`forall`, `exists`]()
  - [`choose`]()
  - [Function expressions]()
  - [Trigger annotations]()
  - [The view function `@`](./reference-at-sign.md)
  - [Spec index operator `[]`](./reference-spec-index.md)
- [Proof features]()
  - [assert and assume]()
  - [assert ... by](./reference-assert-by.md)
  - [assert forall ... by](./reference-assert-forall-by.md)
  - [assert ... by(bit_vector)](./reference-assert-by-bit-vector.md)
  - [assert ... by(nonlinear_arith)]()
  - [assert ... by(compute) / by(compute_only)]()
  - [reveal]()
  - [fuel]()
- [Function specifications]()
  - [requires / ensures]()
  - [opens_invariants](./reference-opens-invariants.md)
  - [recommends]()
- [Loop specifications]()
  - [invariant]()
  - [invariant_except_break / ensures]()
- [Recursion and termination]()
  - [decreases ...]()
  - [decreases ... when ...]()
  - [decreases ... via ...]()
  - [Datatype ordering]()
  - [Cyclic definitions]()
- [Misc. Rust features]()
  - [Statics](./static.md)
- [Command line]()
  - [--record](./reference-flag-record.md)
- [Planned future work]()

================
File: ./guide/src/quants.md
================

# Quantifiers

Suppose that we want to specify that all the elements of a sequence are even.
If the sequence has a small, fixed size,
we could write a specification for every element separately:

```rust
{{#include ../../../rust_verify/example/guide/quants.rs:quants_finite}}
```

Clearly, though, this won't scale well to larger sequences or sequences of unknown length.

We could write a recursive specification:

```rust
{{#include ../../../rust_verify/example/guide/quants.rs:quants_recursion}}
```

However, using a recursive definition will lead to many proofs by induction,
which can require a lot of programmer effort to write.

Fortunately, Verus and SMT solvers support the
[universal and existential quantifiers](https://en.wikipedia.org/wiki/Quantifier_(logic))
`forall` and `exists`,
which we can think of as infinite conjunctions or disjunctions:

```
(forall|i: int| f(i)) = ... f(-2) && f(-1) && f(0) && f(1) && f(2) && ...
(exists|i: int| f(i)) = ... f(-2) || f(-1) || f(0) || f(1) || f(2) || ...
```

With this, it's much more convenient to write a specification about all elements of a sequence:

```rust
{{#include ../../../rust_verify/example/guide/quants.rs:quants_use_forall}}
```

Although quantifiers are very powerful, they require some care,
because the SMT solver's reasoning about quantifiers is incomplete.
This isn't a deficiency in the SMT solver's implementation,
but rather a deeper issue:
it's an undecidable problem to figure out whether a formula
with quantifiers, functions, and arithmetic is valid or not,
so there's no complete algorithm that the SMT solver could implement.
Instead, the SMT solver uses an incomplete strategy based on *triggers*,
which instantiates quantifiers when expressions match trigger patterns.

This chapter will describe how to use `forall` and `exists`,
how triggers work,
and some related topics on `choose` expressions and closures.

================
File: ./guide/src/spec_functions.md
================

# spec functions

Let's start with a simple `spec` function that computes the minimum of two integers:

```rust
{{#include ../../../rust_verify/example/guide/modes.rs:spec_fun1}}
```

Unlike `exec` functions,
the bodies of `spec` functions are visible to other functions in the same module,
so the `test` function can see inside the `min` function,
which allows the assertions in `test` to succeed.

Across modules, the bodies of `spec` functions can be made public to other modules
or kept private to the current module.
The body is public if the function is marked `open`,
allowing assertions about the function's body to succeed in other modules:

```rust
{{#include ../../../rust_verify/example/guide/modes.rs:spec_fun_mod1}}
```

By contrast, if the function is marked `closed`,
then other modules cannot see the function's body,
even if they can see the function's declaration. By contrast,
functions within the same module can view a `closed spec fn`'s body. 
In other words, `pub` makes the declaration public,
while `open` and `closed` make the body public or private.
All `pub` `spec` functions must be marked either `open` or `closed`;
Verus will complain if the function lacks this annotation.

```rust
{{#include ../../../rust_verify/example/guide/modes.rs:spec_fun_mod2}}
```

In the example above with `min` being `closed`,
the module `M2` can still talk about the function `min`,
proving, for example, that `min(10, 20)` equals itself
(because everything equals itself, regardless of what's in it's body).
On the other hand, the assertion that `min(10, 20) == 10` fails,
because `M2` cannot see `min`'s body and therefore doesn't know that `min`
computes the minimum of two numbers:

```
error: assertion failed
   |
   |         assert(min(10, 20) == 10); // FAILS
   |                ^^^^^^^^^^^^^^^^^ assertion failed
```

After the call to `lemma_min`, the assertion that `min(10, 20) <= 10` succeeds because `lemma_min` exposes `min(x,y) <= x` as a post-condition. `lemma_min` can prove because this postcondition because it can see the body of `min` despite `min` being `closed`, as `lemma_min` and `min` are in the same module.

You can think of `pub open spec` functions as defining abbreviations
and `pub closed spec` functions as defining abstractions.
Both can be useful, depending on the situation.

`spec` functions may be called from other `spec` functions
and from specifications inside `exec` functions,
such as preconditions and postconditions.
For example, we can define the minimum of three numbers, `min3`,
in terms of the mininum of two numbers.
We can then define an `exec` function, `compute_min3`,
that uses imperative code with mutable updates to compute
the minimum of 3 numbers,
and defines its postcondition in terms of the `spec` function `min3`:

```rust
{{#include ../../../rust_verify/example/guide/modes.rs:spec_fun3}}
```

The difference between `min3` and `compute_min3` highlights some differences
between `spec` code and `exec` code.
While `exec` code may use imperative language features like mutation,
`spec` code is restricted to purely functional mathematical code.
On the other hand, `spec` code is allowed to use `int` and `nat`,
while `exec` code is restricted to compilable types like `u64`.

================
File: ./guide/src/break.md
================

# Loops with break

Loops can exit early using `return` or `break`.
Suppose, for example, we want to remove the requirement
`triangle(n as nat) < 0x1_0000_0000` from the `loop_triangle` function,
and instead check for overflow at run-time.
The following version of the function uses `return` to return
the special value `0xffff_ffff` in case overflow is detected at run-time:

```rust
{{#include ../../../rust_verify/example/guide/recursion.rs:loop_return}}
```

Another way to exit early from a loop is with a `break` inside the loop body.
However, `break` complicates the specification of a loop slightly.
For simple `while` loops without a `break`,
Verus knows that the loop condition (e.g. `idx < n`)
must be false after exiting the loop.
If there is a `break`, though, the loop condition is not necessarily false
after the loop, because the `break` might cause the loop to exit even when
the loop condition is true.
To deal with this, `while` loops with a `break`,
as well as Rust `loop` expressions (loops with no condition),
must explicitly specify what is true after the loop exit using `ensures` clauses,
as shown in the following code.
Furthermore, invariants that don't hold after a `break`
must be marked as `invariant_except_break` rather than `invariant`:

```rust
{{#include ../../../rust_verify/example/guide/recursion.rs:loop_break}}
```

================
File: ./guide/src/recursion_loops.md
================

# Recursion and loops

Suppose we want to compute the nth 
[triangular number](https://en.wikipedia.org/wiki/Triangular_number):

```
triangle(n) = 0 + 1 + 2 + ... + (n - 1) + n
```

We can express this as a simple recursive funciton:

```rust
{{#include ../../../rust_verify/example/guide/recursion.rs:spec}}
```

This chapter discusses how to define and use recursive functions,
including writing `decreases` clauses and using fuel.
It then explores a series of verified implementations of `triangle`,
starting with a basic recursive implementation and ending with a while loop.

================
File: ./guide/src/assert_by.md
================

# Hiding local proofs with `assert(...) by { ... }`

## Motivation

Sometimes, in a long function, you need to establish a fact `F` that requires
a modest-size proof `P`. Typically, you do this by `...; P; assert(F); ...`.
But doing this comes with a risk: the facts `P` introduces can be used not
only for proving `F` but also for proving the entire rest of the
function. This gives the SMT solver much more to think about when proving things beyond
`assert(F)`, which is especially problematic when these additional facts are
universally quantified. This can make the solver take longer, and even time out, on
the rest of the function.

## Enter `assert(...) by { ... }`

Saying `assert(F) by {P}` restricts the context that `P` affects, so that
it's used to establish `F` and nothing else. After the closing brace at the
end of `{ P }`, all facts that it established except for `F` are removed from
the proof context.

## Underlying mechanism

The way this works internally is as follows. The solver is given the facts following
from `P` as a premise when proving `F` but isn't given them for the rest of
the proof. For instance, suppose `lemma_A` establishes fact `A` and `lemma_B`
establishes fact `B`. Then
```
lemma_A();
assert(F) by { lemma_B(); };
assert(G);
```
is encoded to the solver as something like `(A && B ==> F) && (A ==> G)`. If `B` is an expansive fact
to think about, like `forall|i: int| b(i)`, the solver won't be able to think about it
when trying to establish `G`.

## Difference from auxiliary lemmas

Another way to isolate the proof of `F` from the local context is to put the
proof `P` in a separate lemma and invoke that lemma. To do this, the proof
writer has to think about what parts of the context (like fact `A` in the
example above) are necessary to establish `F`, and put those as `requires`
clauses in the lemma. The developer may then also need to pass other variables
to the lemma that are mentioned in those required facts. This can be done, but
can be a lot of work. Using `assert(F) by { P }` obviates all this work. It
also makes the proof more compact by removing the need to have a separate
lemma with its own signature.

================
File: ./guide/src/profiling.md
================

# Quantifier Profiling

Sometimes the verification of a Verus function will time out, meaning that the solver couldn't 
determine whether all of the proof obligations have been satisfied.  Or verification might 
succeed but take longer than we would like.  One common cause for both of these phenomena
is [quantifiers](quants.md).  If quantifiers (and their associated triggers) are
written too liberally (i.e., they trigger too often), then the SMT solver may generate too many
facts to sort through efficiently.  To determine if this is the case for your Verus code, you
can use the built-in quantifier profiler.

As a concrete example, suppose we have the following three functions defined:

```rust
{{#include ../../../rust_verify/example/trigger_loops.rs:def_f_g}}
```

and we use them in the following proof code:

```rust
{{#include ../../../rust_verify/example/trigger_loops.rs:trigger_forever2}}
```

Notice that we have three quantifiers in the `requires` clause; the first will
trigger on `g(x)`, which will be useful for proving the assertion about `g(4)`.
The second quantifier triggers on both `f(x, y)` and `h(x, y)` and says that
they're equal.  The last quantifier is manually triggered on `f(x, y)`, but it
then introduces two more expressions that have a similar shape, namely `f(x +
1, 2 * y)` and `f(2 * x, y + x)`.  Each of these has new arguments to `f`, so
this will cause quantifier 3 to trigger again, creating an infinite cycle of
instantations.  Notice that each such instantiation will also cause quantifier
2 to trigger as well.

If we run Verus on this example, it will quickly time out.  When this happens, you
can run Verus with the `--profile` option to launch the profiler.  We strongly
recommend combining that option with `--rlimit 1`, so that you don't generate too
much profiling data (the more you generate, the longer the analysis takes).  With
`--profile`, if verification times out, the profiler automatically launches.
If you want to profile a function that is verifying successfully but slowly, you 
can use the `--profile-all` option.  You may want to combine this with the 
`--verify-function` option to target the function you're interested in.

If we run the profiler on the example above, we'll see something along the lines of:

```
error: function body check: Resource limit (rlimit) exceeded
  --> rust_verify/example/trigger_loops.rs:64:1
   |
64 | fn trigger_forever2() {
   | ^^^^^^^^^^^^^^^^^^^^^

Analyzing prover log...
[00:00:39] ████████████████████████████████████████████████████████████████████████████████ 1153/1153K lines
... analysis complete

note: Observed 27,184 total instantiations of user-level quantifiers

note: Cost * Instantiations: 5391549700 (Instantiated 13,591 times - 49% of the total, cost 396700) top 1 of 3 user-level quantifiers.
  --> rust_verify/example/trigger_loops.rs:68:78
   |
68 |    forall|x: nat, y: nat| f(x + 1, 2 * y) && f(2 * x, y + x) || f(y, x) ==> #[trigger] f(x, y),
   |    -------------------------------------------------------------------------^^^^^^^^^^^^^^^^^^ Triggers selected for this quantifier

note: Cost * Instantiations: 1037237938 (Instantiated 13,591 times - 49% of the total, cost 76318) top 2 of 3 user-level quantifiers.
  --> rust_verify/example/trigger_loops.rs:67:28
   |
67 |    forall|x: nat, y: nat| h(x, y) == f(x, y),
   |    -----------------------^^^^^^^----^^^^^^^ Triggers selected for this quantifier

note: Cost * Instantiations: 16 (Instantiated 2 times - 0% of the total, cost 8) top 3 of 3 user-level quantifiers.
  --> rust_verify/example/trigger_loops.rs:66:20
   |
66 |    forall|x: nat| g(x),
   |    ---------------^^^^ Triggers selected for this quantifier

error: aborting due to previous error
```

The profiler measures two aspects of quantifier performance.  First, it collects a basic count of how
many times each quantifier is instantiated.  Second, it attempts to calculate a "cost" for each 
quantifier.  The cost of a quantifier is the sum of cost of its instantiations.  The cost of an instantiation `i`
is roughly `1 + sum_{(i, n) \in edges} cost(n) / in-degree(n)` where each `n` is an instantiation caused 
by instantiation `i`.  In other words, instantiation `i` produced a term that caused the solver to create
another instantiation (of the same or a different quantifier) `n`.  This heuristic attempts to place more
weight on quantifiers whose instantiations themselves cause other expensive instantiations.  By default,
the profiler will sort by the product of these two metrics.

In the example above, we see that the top quantifier is quantifer 3 in the Verus code, which is indeed the 
troublemaker.  The use of the cost metric elevates it above quantifier 2, which had the same number of 
instantiations but is really an "innocent bystander" in this scenario.  And both of these quantifiers
are instantiated vastly more than quantifier 3, indicating that quantifier 3 is not the source of the 
problem.  If all of the quantifiers have a small number of instantiations, that may be a sign that 
quantifier instantiation is not the underlying source of the solver's poor performance.


================
File: ./guide/src/const.md
================

# const declarations

`const` declarations can either be marked `spec` or left without a mode:

```rust
{{#include ../../../rust_verify/example/guide/modes.rs:const1}}
```

A `spec const` is like `spec` function with no arguments.
It is always ghost and cannot be used as an `exec` value.

By contrast, a `const` without a mode is dual-use:
it is usable as both an `exec` value and a `spec` value.
Therefore, the `const` definition is restricted to obey the rules
for both `exec` code and `spec` code.
For example, as with `exec` code, its type must be compilable (e.g. `u8`, not `int`),
and, as with `spec` code, it cannot call any `exec` or `proof` functions.

================
File: ./guide/src/spec_lib.md
================

# Specification libraries: Seq, Set, Map

The Verus libraries contain types `Seq<T>`, `Set<T>`, and `Map<Key, Value>`
for representing sequences, sets, and maps in specifications.
In contrast to executable Rust collection datatypes in
[std::collections](https://doc.rust-lang.org/std/collections/),
the `Seq`, `Set` and `Map` types
represent collections of arbitrary size.
For example, while the `len()` method of
[`std::collections::HashSet`](https://doc.rust-lang.org/std/collections/hash_set/struct.HashSet.html)
returns a length of type `usize`,
which is bounded,
the `len()` methods of `Seq` and `Set` return
lengths of type `nat`, which is unbounded.
Furthermore, `Set` and `Map` can represent infinite sets and maps.
(Sequences, on the other hand, are always finite.)
This allows specifications to talk about collections that
are larger than could be contained in the physical memory of a computer.

## Constructing and using Seq, Set, Map

The `seq!`, `set!`, and `map!` macros construct values of type `Seq`, `Set`, and `Map`
with particular contents:

```rust
{{#include ../../../rust_verify/example/guide/lib_examples.rs:macro}}
```

The macros above can only construct finite sequences, sets, and maps.
There are also functions `Seq::new`, `Set::new`, and `Map::new`,
which can allocate both finite values and (for sets and maps) infinite values:

```rust
{{#include ../../../rust_verify/example/guide/lib_examples.rs:new}}
```

Each `Map<Key, Value>` value has a domain of type `Set<Key>` given by `.dom()`.
In the `test_map2` example above, `m`'s domain is the finite set `{0, 10, 20, 30, 40}`,
while `m_infinite`'s domain is the infinite set `{..., -20, 10, 0, 10, 20, ...}`.

For more operations, including sequence contenation (`.add` or `+`),
sequence update,
sequence subrange,
set union (`.union` or `+`),
set intersection (`.intersect`),
etc.,
see:

- [seq.rs](https://github.com/verus-lang/verus/tree/main/source/vstd/seq.rs)
- [seq_lib.rs](https://github.com/verus-lang/verus/tree/main/source/vstd/seq_lib.rs)
- [set.rs](https://github.com/verus-lang/verus/tree/main/source/vstd/set.rs)
- [set_lib.rs](https://github.com/verus-lang/verus/tree/main/source/vstd/set_lib.rs)
- [map.rs](https://github.com/verus-lang/verus/tree/main/source/vstd/map.rs)

See also the [API documentation](https://verus-lang.github.io/verus/verusdoc/vstd/index.html).

## Proving properties of Seq, Set, Map

The SMT solver will prove some properties about Seq, Set, and Map automatically,
as shown in the examples above.
However, some other properties may require calling lemmas in the library
or may require proofs by induction.

If two collections (`Seq`, `Set`, or `Map`) have the same elements,
Verus considers them to be equal.
This is known as equality via [extensionality](https://en.wikipedia.org/wiki/Extensionality).
However, the SMT solver will in general not automatically recognize that
the two collections are equal
if the collections were constructed in different ways.
For example, the following 3 sequences are equal,
but asserting equality fails:

```rust
{{#include ../../../rust_verify/example/guide/lib_examples.rs:test_eq_fail}}
```

To convince the SMT solver that `s1`, `s2`, and `s3` are equal,
we have to explicitly assert the equality via the *extensional* equality operator `=~=`,
rather than just the ordinary equality operator `==`.
Using `=~=` forces the SMT solver
to check that all the elements of the collections are equal,
which it would not ordinarily do.
Once we've explicitly proven equality via extensionality,
we can then successfully assert `==`:

```rust
{{#include ../../../rust_verify/example/guide/lib_examples.rs:test_eq}}
```

(See the [Equality via extensionality](extensional_equality.md) section for more details.)

Proofs about set cardinality (`Set::len`) and set finiteness (`Set::finite`)
often require inductive proofs.
For example, the exact cardinality of the intersection of two sets
depends on which elements the two sets have in common.
If the two sets are disjoint,
the intersection's cardinality will be 0,
but otherwise, the intersections's cardinality will be some non-zero value.
Let's try to prove that the intersection's cardinality is no larger than
either of the two sets' cardinalities.
Without loss of generality, we can just prove that
the intersection's cardinality is no larger than the first set's cardinality:
`s1.intersect(s2).len() <= s1.len()`.

The proof (which is found in [set_lib.rs](https://github.com/verus-lang/verus/tree/main/source/vstd/set_lib.rs))
is by induction on the size of the set `s1`.
In the induction step, we need to make `s1` smaller,
which means we need to remove an element from it.
The two methods `.choose` and `.remove` allow us to choose
an arbitrary element from `s1` and remove it:

```rust
let a = s1.choose();
... s1.remove(a) ...
```

Based on this, we expect an inductive proof to look something like the following,
where the inductive step removes `s1.choose()`:

```rust
{{#include ../../../rust_verify/example/guide/lib_examples.rs:lemma_len_intersect_fail}}
```

Unfortunately, Verus fails to verify this proof.
Therefore, we'll need to fill in the base case and induction case with some more detail.
Before adding this detail to the code,
let's think about what a fully explicit proof might look like if we wrote it out by hand:

```rust
{{#include ../../../rust_verify/example/guide/lib_examples.rs:lemma_len_intersect_sketch}}
```

For such a simple property, this is a surprisingly long proof!
Fortunately, the SMT solver can automatically prove most of the steps written above.
What it will not automatically prove, though, is any step requiring equality via extensionality,
as discussed earlier.
The two crucial steps requiring equality via extensionality are:
- "Therefore, s1.intersect(s2) is also empty."
- Replacing `(s1 - {a}).intersect(s2)` with `s1.intersect(s2) - {a}`

For these, we need to explicitly invoke `=~=`:

```rust
{{#include ../../../rust_verify/example/guide/lib_examples.rs:lemma_len_intersect}}
```

With this, Verus and the SMT solver successfully complete the proof.
However, Verus and the SMT solver aren't the only audience for this proof.
Anyone maintaining this code might want to know why we invoked `=~=`,
and we probably shouldn't force them to work out the entire hand-written proof above
to rediscover this.
So although it's not strictly necessary,
it's probably polite to wrap the assertions in `assert...by` to indicate
the purpose of the `=~=`:

```rust
{{#include ../../../rust_verify/example/guide/lib_examples.rs:lemma_len_intersect_commented}}
```

---

================
File: ./guide/src/ide_support.md
================

# IDE Support for Verus

Verus currently has IDE support for VS Code, and Emacs. Here, we describe the steps for using Verus with both these editors.

For VS Code, we require verus-analyzer, our Verus-specific fork of rust-analyzer. For Emacs, we have stand-alone support for Verus.

We describe the steps to get started with [VS Code](#quickstart-vs-code) and [Emacs](#quickstart-emacs) below.

## Quickstart VS Code
The steps below walk you through compiling a Verus-specific version of rust-analyzer and using it in VS Code. It provides Verus syntax support and several IDE functionalities.

For more details and latest updates, please check out the [README for verus-analyzer](https://github.com/verus-lang/verus-analyzer)
### 1. Compile binary

1. Clone the repository: `git clone https://github.com/verus-lang/verus-analyzer.git`  
2. `cd verus-analyzer`
3. Compile the rust-analyzer binary: `cargo xtask dist`
4. Unzip the generated file (e.g., `gunzip ./dist/verus-analyzer-x86_64-apple-darwin.gz`)
5. Make it executable (e.g., `chmod +x ./dist/verus-analyzer-x86_64-apple-darwin`)



### 2. VS Code
Before starting, please install the original rust-analyzer extension in VS Code's extensions tab.

#### 2.1. Adding a separate [VS Code Workspace](https://code.visualstudio.com/docs/editor/workspaces)
Suppose you have a new project with `cargo new`. After you open this project in VS Code, use `File > Save Workspace As...` to generate `{project_name}.code-workspace` file. The file will look similar to this. 

```json
{
	"folders": [
		{
			"path": "."
		}
	],
	"settings": {}
}
```


#### 2.2. Adding settings variables
We will modify the "settings" section of the `.code-workspace` file. To be specific, we will add two entries in the "settings" section of the file. These are `rust-analyzer.server.path` and `rust-analyzer.checkOnSave`.

- `rust-analyzer.server.path` should be set to the path of the verus-analyzer binary produced in step 1 above (e.g., the full path to `./dist/rust-analyzer-x86_64-apple-darwin`)
- `rust-analyzer.checkOnSave` to disable `cargo check`.

For example, the "settings" in the `.code-workspace` file could look the following:
```json
"settings": {
        "rust-analyzer.server.path": "ABSOLUTE-PATH-TO-THE-VERUS-ANALYZER-BINARY",
        "rust-analyzer.checkOnSave": false,
}
```

When you modify and save this file, VS Code will ask you if you want to reload the rust-analyzer server. It will replace the rust-analyzer binary with this custom one.

By opening this workspace, the rust-analyzer plugin will use the custom binary. If you open your project without that workspace setting(e.g., open this project by "open folder"), it will use the original rust-analyzer binary.



## Quickstart Emacs
We support for Verus programming in Emacs through [verus-mode.el](https://github.com/verus-lang/verus-mode.el), a major mode that supports syntax highlighting, verification-on-save, jump-to-definition, and more.

To use verus-mode, the setup can be as simple as configuring `.emacs` to (i) set `verus-home` to the path to Verus, and then (ii) load up `verus-mode`.

For example, if you use `use-package`, you can clone [verus-mode.el](https://github.com/verus-lang/verus-mode.el) into a location that Emacs can load from, and add the following snippet:
```
(use-package verus-mode
  :init
  (setq verus-home "PATH_TO_VERUS_DIR"))   ; Path to where you've cloned https://github.com/verus-lang/verus
```

Depending on your specific Emacs setup, your exact installation process for verus-mode.el could vary. Detailed installation steps for various Emacs setups are documented in the [Install section on verus-mode.el's README](https://github.com/verus-lang/verus-mode.el#install).

For more details on latest features, key-bindings, and troubleshooting tips, do check out the [README for verus-mode.el](https://github.com/verus-lang/verus-mode.el/blob/main/README.md).

================
File: ./guide/src/recursion.md
================

# Recursive functions, decreases, fuel

Recursive functions are functions that call themselves.
In order to ensure soundness, a recursive `spec` function must terminate on all inputs ---
infinite recursive calls aren't allowed.
To see why termination is important, consider the following nonterminating function definition:

```rust
{{#include ../../../rust_verify/example/guide/recursion.rs:bogus}}
```

Verus rejects this definition because the recursive call loops infinitely, never terminating.
If Verus accepted the definion, then you could very easily prove false,
because, for example, the definition insists that `bogus(3) == bogus(3) + 1`,
which implies that `0 == 1`, which is false:

```rust
{{#include ../../../rust_verify/example/guide/recursion.rs:exploit_bogus}}
```

To help prove termination,
Verus requires that each recursive `spec` function definition contain a `decreases` clause:

```rust
{{#include ../../../rust_verify/example/guide/recursion.rs:spec}}
```

Each recursive call must decrease the expression in the `decreases` clause by at least 1.
Furthermore, the call cannot cause the expression to decrease below 0.
With these restrictions, the expression in the `decreases` clause serves as an upper bound on the
depth of calls that `triangle` can make to itself, ensuring termination.

# Fuel and reasoning about recursive functions

Given the definition of `triangle` above, we can make some assertions about it:

```rust
{{#include ../../../rust_verify/example/guide/recursion.rs:lacks_fuel}}
```

The first assertion, about `triangle(0)`, succeeds.
But somewhat surprisingly, the assertion `assert(triangle(10) == 55)` fails,
despite the fact that `triangle(10)` really is
[equal to 55](https://en.wikipedia.org/wiki/Triangular_number).
We've just encountered a limitation of automated reasoning:
SMT solvers cannot automatically prove all true facts about all recursive functions.

For nonrecursive functions,
an SMT solver can reason about the functions simply by inlining them.
For example, if we have a call `min(a + 1, 5)` to the [`min` function](spec_functions.md):

```rust
{{#include ../../../rust_verify/example/guide/recursion.rs:min}}
```

the SMT solver can replace `min(a + 1, 5)` with:

```
    if a + 1 <= 5 {
        a + 1
    } else {
        5
    }
```

which eliminates the call.
However, this strategy doesn't completely work with recursive functions,
because inlining the function produces another expression with a call to the same function:

```
triangle(x) = if x == 0 { 0 } else { x + triangle(x - 1) }
```

Naively, the solver could keep inlining again and again,
producing more and more expressions,
and this strategy would never terminate:

```
triangle(x) = if x == 0 { 0 } else { x + triangle(x - 1) }
triangle(x) = if x == 0 { 0 } else { x + (if x - 1 == 0 { 0 } else { x - 1 + triangle(x - 2) }) }
triangle(x) = if x == 0 { 0 } else { x + (if x - 1 == 0 { 0 } else { x - 1 + (if x - 2 == 0 { 0 } else { x - 2 + triangle(x - 3) }) }) }
```

To avoid this infinite inlining,
Verus limits the number of recursive calls that any given call can spawn in the SMT solver.
This limit is called the *fuel*;
each nested recursive inlining consumes one unit of fuel.
By default, the fuel is 1, which is just enough for `assert(triangle(0) == 0)` to succeed
but not enough for `assert(triangle(10) == 55)` to succeed.
To increase the fuel to a larger amount,
we can use the `reveal_with_fuel` directive:

```rust
{{#include ../../../rust_verify/example/guide/recursion.rs:fuel}}
```

Here, 11 units of fuel is enough to inline the 11 calls
`triangle(0)`, ..., `triangle(10)`.
Note that even if we only wanted to supply 1 unit of fuel,
we could still prove `assert(triangle(10) == 55)` through a long series of assertions:

```rust
{{#include ../../../rust_verify/example/guide/recursion.rs:step_by_step}}
```

This works because 1 unit of fuel is enough to prove `assert(triangle(0) == 0)`,
and then once we know that `triangle(0) == 0`,
we only need to inline `triangle(1)` once to get:

```
triangle(1) = if 1 == 0 { 0 } else { 1 + triangle(0) }
```

Now the SMT solver can use the previously computed `triangle(0)` to simplify this to:

```
triangle(1) = if 1 == 0 { 0 } else { 1 + 0 }
```

and then produce `triangle(1) == 1`.
Likewise, the SMT solver can then use 1 unit of fuel to rewrite `triangle(2)`
in terms of `triangle(1)`, proving `triangle(2) == 3`, and so on.
However, it's probably best to avoid long series of assertions if you can,
and instead write a proof that makes it clear why the SMT proof fails by default
(not enough fuel) and fixes exactly that problem:

```rust
{{#include ../../../rust_verify/example/guide/recursion.rs:fuel_by}}
```

================
File: ./guide/src/operators.md
================

# Expressions and operators for specifications

To make specifications easier to read and write,
Verus supports syntactic sugar for various arithmetic and boolean operations in ghost code.
For example, you can write:

```
forall|i: int, j: int| 0 <= i <= j < len ==> f(i, j)
```

This is equivalent to:

```
forall|i: int, j: int| !(0 <= i && i <= j && j < len) || f(i, j)
```

# Chained inequalities

In ghost code, you can chain together multiple `<=`, `<`, `>=`, and `>` operations,
writing `0 <= i <= j < len` as a shorthand for `0 <= i && i <= j && j < len`, for example.

(If any of the expressions are complex expressions,
as in `0 <= f(x + 1, 3 * y) < n`,
for efficiency's sake,
Verus will automatically create a temporary variable for the complex expressions,
as in `{let tmp = f(x + 1, 3 * y); 0 <= tmp < n}`,
rather than duplicating the expressions.)

# Boolean operators

For boolean expressions `b1`, ..., `bn`,
Verus supports the following abbreviations:

| Expression                                                            | Meaning                                             | Name        |
|-----------------------------------------------------------------------|-----------------------------------------------------|-------------|
| b1 ==> b2                                                             | !b1 &#124;&#124; b2                                 | implies     |
| b1 <== b2                                                             | b1 &#124;&#124; !b2                                 | explies     |
| b1 <==> b2                                                            | b1 == b2                                            | equivalent  |
| &&& b1 &&& b2 ... &&& bn                                              | b1 && b2 && ... && bn                               | prefix-and  |
| &#124;&#124;&#124; b1 &#124;&#124;&#124; b2 ... &#124;&#124;&#124; bn | b1 &#124;&#124; b2 &#124;&#124; ... &#124;&#124; bn | prefix-or   |

These abbreviations have lower precedence than
[most other Rust expressions](https://doc.rust-lang.org/reference/expressions.html),
so that, for example, `a ==> b && c` means `a ==> (b && c)`:

| Operator                 | Associativity         |
|--------------------------|-----------------------|
| * / %                    | left                  |
| + -                      | left                  |
| << >>                    | left                  |
| &                        | left                  |
| ^                        | left                  |
| &#124;                   | left                  |
| === !== == != <= < >= >  | requires parentheses  |
| &&                       | left                  |
| &#124;&#124;             | left                  |
| ==>                      | right                 |
| <==                      | left                  |
| <==>                     | requires parentheses  |
| ..                       | left                  |
| =                        | right                 |
| closures, forall, exists | right                 |
| &&&                      | left                  |
| &#124;&#124;&#124;       | left                  |

# The `is` operator, and the "arrow" field access

If you define an enum,

```rust
enum ThisOrThat {
    This(nat),
    That { v: int },
}
```

you can then use (in specification code) the syntax `t is This` or `t is That`
which will be true if `t` is a value of the relevant enum variant.

If, in addition, all the fields have distinct names, like in the example above
you can then access the fields with `t->v` or `t->0` (for positional fields note
that these are supported if only one variant has "tuple like" fields).

If field in different variants have the same name, you can still use
the `->` arrow syntax by also specifying the field, for example, for:

```rust
enum ThisOrThat {
    This { t: int },
    That { t: int },
}
```

you can use `v->This_t` or `v->That_t`.


# `matches` with `&&&`, `==>`, and `&&`

For more complex cases, and where you need an enum where multiple variants have
fields of the same name, you can use the `t matches That { v: a }` syntax, which
will result in a boolean representing whether `t` matches the provided pattern.
You can also follow it up with `==>` and `&&` and subsequent expressions (that bind at least as tightly)
will have access to the bound variables in the parttern (`a` in this example).

For example, for that enum, you can say;

```rust
proof fn uses_arrow_matches_1(t: ThisOrThat)
    requires
        t is That ==> t->v == 3,
        t is This ==> t->0 == 4,
{
    assert(t matches ThisOrThat::This(k) ==> k == 4);
    assert(t matches ThisOrThat::That { v } ==> v == 3);
}
```

The "t matches `pattern`" syntax is also valid as an expression of a `&&&` chain, e.g.

```rust
proof fn test1(t: ThisOrThat)
    requires ({
        &&& t matches ThisOrThat::That { v: a }
        &&& a > 3
        &&& a < 5
    })
{
    // ...
}
```
================
File: ./guide/src/memory-safety.md
================

# Memory safety is conditional on verification

Let's briefly compare and contrast the philosophies of Rust and Verus with regards to
memory safety. Memory safety, here, refers to a program being free of any
_undefined behavior (UB)_ in its memory access.
Both Rust and Verus _rely_ on memory safety being upheld; in turn,
they both do a great deal to _enforce_ it. However, they enforce it in different ways.

Rust's enforcement of memory safety is built around a contract between "safe" and
"unsafe" code.  The [first chapter of the Rustonomicon](https://doc.rust-lang.org/nomicon/safe-unsafe-meaning.html)
summarizes the philosophy. In short: any "safe" code (i.e., code free of the `unsafe` keyword) 
must be memory safe, enforced by Rust itself via its type-checker and borrow-checker,
regardless of user error. However, if any code uses `unsafe`, it is the responsibility
of the programmer to ensure that the program is memory safe---and if the programmer fails to
do so, then the behavior of the program is undefined (by definition).

In practice, of course, most code _does_ use `unsafe`, albeit only indirectly.
Most code relies on low-level utilities that can only be implemented with unsafe code,
including many from the standard library (e.g., `Arc`, `RefCell`, and so on), but also
from user-provided crates. In any case, the Rust philosophy is that the providers of these
low-level utilities should meet a standard of "unsafe encapsulation."
A programmer interacting using the library only through its safe API (and also not using
`unsafe` code anywhere else) should not be able to exhibit undefined behavior,
_not even by writing buggy code or using the API is an unintended way_.
As such, the library implementors need to code defensively against all possible ways the
client might use the safe API.
When they are successful in this, the clients once again gain the guarantee that they
cannot invoke UB without `unsafe` code.

By contrast, Verus does not have an "unsafe/safe" distinction, nor does it have a notion
of unsafe encapsulation. This is because it verifies _both_ memory safety and other
forms of correctness through [Verus specifications](./requires_ensures.md).

### Example

Consider, for example, the [index operation in Rust's standard `Vec` container](https://doc.rust-lang.org/std/vec/struct.Vec.html#method.index).
If the client calls this function with an index that is not in-range for the vector's
length, then it is likely a bug on the part of the client. However, the index operation
is part of the safe API, and therefore it must be robust to such things, and it can never
attempt to read out-of-bounds memory. Therefore, the implementation of this operation has
to do a bounds check (panicking if the bounds check fails).

On the other hand, consider this (possible) implementation of `index` for Verus's
`Vec` collection:

```rust,ignore
impl<A> Vec<A> {
    #[verifier::external_body]
    pub fn index(&self, i: usize) -> (r: &A)
        requires
            i < self.len(),
        ensures
            *r === self[i as int],
    {
        unsafe { self.vec.get_unchecked(i) }
    }
}
```

Unlike Rust's `index`, this implementation has no bounds checks, and it exhibits UB if called
for a value of `i` that is out-of-bounds. Therefore, as ordinary Rust, it would not meet
the standards of unsafe encapsulation.

However, due to its `requires` clause,
Verus enforces that any call to this function _will_ satisfy the contract and be in-bounds.
Therefore, UB cannot occur in a _verified_ Verus program, but type-checking alone is not
sufficient to ensure this.

### Conclusion

Rust's concept of unsafe encapsulation means that programmers writing in safe Rust can be sure
that their programs will be memory safe as long as they type-check and pass the borrow-checker, 
even if their code otherwise has bugs.

In Verus, there is no staggered notion of correctness. If the program verifies, then it is
memory safe, and it will execute according to all its specifications.
If the program fails to verify, then all bets are off.

(TODO remark on implications for calling Verus code from ordinary rust code)

================
File: ./guide/src/getting_started.md
================

# Getting Started

To get started with Verus, use `git clone` to fetch the Verus source code from
the [Verus GitHub page](https://github.com/verus-lang/verus),
and then follow the directions on
the [Verus GitHub page](https://github.com/verus-lang/verus/blob/main/INSTALL.md)
to build Verus.

Let's try running Verus on the following sample Rust program,
found at [getting_started.rs](https://github.com/verus-lang/verus/tree/main/source/rust_verify/example/guide/getting_started.rs):

```rust
{{#include ../../../rust_verify/example/guide/getting_started.rs}}
```

To run Verus on this code, change to the `source` directory and type the following in Unix:

```
./target-verus/release/verus rust_verify/example/guide/getting_started.rs
```

or the following in Windows:

```
.\target-verus\release\verus.exe rust_verify\example\guide\getting_started.rs
```

You should see the following output:

```
note: verifying root module

verification results:: 1 verified, 0 errors
```

This indicates that Verus successfully verified 1 function (the `main` function).
If you want, you can try editing the `rust_verify/example/guide/getting_started.rs` file
to see a verification failure.
For example, if you add the following line to `main`:

```
    assert(forall|i: int, j: int| min(i, j) == min(i, i));
```

you will see an error message:

```
note: verifying root module

error: assertion failed
  --> example/guide/getting_started.rs:19:12
   |
19 |     assert(forall|i: int, j: int| min(i, j) == min(i, i));
   |            ^^^^^^ assertion failed

error: aborting due to previous error

verification results:: 0 verified, 1 errors
```

## Using Verus in Rust files

Verus uses a macro named `verus!` to extend Rust's syntax with verification-related features
such as preconditions, postconditions, assertions, `forall`, `exists`, etc.
Therefore, each file in a crate will typically contain the following declarations:

```rust
use vstd::prelude::*;

verus! {
```

In the remainder of this guide, we will omit these declarations from the examples to avoid clutter.
However, remember that any example code should be placed inside the `verus! { ... }` block,
and that the file should use `vstd::prelude::*;`.

## Compilation

The instructions above verify a Rust file without compiling it.
To both verify and compile a Rust file, add the `--compile` command-line option.
For example:

```
./target-verus/release/verus --compile rust_verify/example/guide/getting_started.rs
```

This will generate an executable for `getting_started.rs`.
(However, in this example, the executable won't do anything interesting,
because the `main` function contains no executable code ---
it contains only statically-checked assertions,
which are erased before compilation.)

================
File: ./guide/src/spec_closures.md
================

# Spec Closures

Verus supports anonymous functions (known as "closures" in Rust) in ghost code.
For example, the following code from earlier in [this chapter](spec_lib.md)
uses an anonymous function `|i: int| 10 * i`
to initialize a sequence with the values 0, 10, 20, 30, 40:

```rust
{{#include ../../../rust_verify/example/guide/lib_examples.rs:new0}}
```

The anonymous function `|i: int| 10 * i` has type `spec_fn(int) -> int`
and has mode `spec`.
Because it has mode `spec`,
the anonymous function is subject to the [same restrictions](modes.md) as named `spec` functions.
(For example, it can call other `spec` functions but not `proof` functions or `exec` functions.)

Note that in contrast to standard executable
[Rust closures](https://doc.rust-lang.org/book/ch13-01-closures.html),
where `Fn`, `FnOnce`, and `FnMut` are traits,
`spec_fn(int) -> int` is a type, not a trait.
Therefore, ghost code can return a spec closure directly,
using a return value of type `spec_fn(t1, ..., tn) -> tret`,
without having to use 
[dyn or impl](https://doc.rust-lang.org/book/ch19-05-advanced-functions-and-closures.html#returning-closures),
as with standard executable Rust closures.
For example, the `spec` function `adder`, shown below,
can return an anonymous function that adds `x` to `y`:

```rust
{{#include ../../../rust_verify/example/guide/lib_examples.rs:ret_spec_fn}}
```

================
File: ./guide/src/reference-opens-invariants.md
================

# opens_invariants

The `opens_invariants` clause may be applied to any `proof` or `exec` function.

This indicates the set of _names_ of tracked invariants that may be opened by the function.
At this time, it has only two forms.  See [the documentation for `open_local_invariant`](https://verus-lang.github.io/verus/verusdoc/vstd/macro.open_local_invariant.html#avoiding-reentrancy) for more information about why Verus enforces these restrictions.

```
fn example()
    opens_invariants any
{
    // Any invariant may be opened here
}
```

or:

```
fn example()
    opens_invariants none
{
    // No invariant may be opened here
}
```

### Defaults

For `exec` functions, the default is `opens_invariants any`.

For `proof` functions, the default is `opens_invariants none`.

================
File: ./guide/src/spec_vs_proof.md
================

# spec functions vs. proof functions

Now that we've seen both `spec` functions and `proof` functions,
let's take a longer look at the differences between them.
We can summarize the differences in the following table
(including `exec` functions in the table for reference):

|                              | spec function     | proof function   | exec function    |
|------------------------------|-------------------|------------------|------------------|
| compiled or ghost            | ghost             | ghost            | compiled         |
| code style                   | purely functional | mutation allowed | mutation allowed |
| can call `spec` functions    | yes               | yes              | yes              |
| can call `proof` functions   | no                | yes              | yes              |
| can call `exec` functions    | no                | no               | yes              |
| body visibility              | may be visible    | never visible    | never visible    |
| body                         | body optional     | body mandatory   | body mandatory   |
| determinism                  | deterministic     | nondeterministic | nondeterministic |
| preconditions/postconditions | recommends        | requires/ensures | requires/ensures |

As described in the [spec functions](spec_functions.md) section,
`spec` functions make their bodies visible to other functions in their module
and may optionally make their bodies visible to other modules as well.
`spec` functions can also omit their bodies entirely:

```
spec fn f(i: int) -> int;
```

Such an [uninterpreted function](https://microsoft.github.io/z3guide/docs/logic/Uninterpreted-functions-and-constants)
can be useful in libraries that define an abstract, uninterpreted function along with trusted axioms
about the function.

## Determinism

`spec` functions are deterministic:
given the same arguments, they always return the same result.
Code can take advantage of this determinism even when a function's body
is not visible.
For example, the assertion `x1 == x2` succeeds in the code below,
because both `x1` and `x2` equal `s(10)`,
and `s(10)` always produces the same result, because `s` is a `spec` function:

```rust
{{#include ../../../rust_verify/example/guide/modes.rs:determinism}}
```

By contrast, the proof function `p` is, in principle,
allowed to return different results each time it is called,
so the assertion `p1 == p2` fails.
(Nondeterminism is common for `exec` functions
that perform input-output operations or work with random numbers.
In practice, it would be unusual for a `proof` function to behave nondeterministically,
but it is allowed.)

## recommends

`exec` functions and `proof` functions can have `requires` and `ensures` clauses.
By contrast, `spec` functions cannot have `requires` and `ensures` clauses.
This is similar to the way [Boogie](https://github.com/boogie-org/boogie) works,
but differs from other systems like [Dafny](https://github.com/dafny-lang/dafny)
and [F*](https://github.com/FStarLang/FStar).
The reason for disallowing requires and ensures is to keep Verus's specification language
close to the SMT solver's mathematical language in order to use the SMT solver as efficiently
as possible (see the [Verus Overview](overview.md)).

Nevertheless, it's sometimes useful to have some sort of preconditions on `spec` functions
to help catch mistakes in specifications early or to catch accidental misuses of `spec` functions.
Therefore, `spec` functions may contain `recommends` clauses
that are similar to `requires` clauses,
but represent just lightweight recommendations rather than hard requirements.
For example, for the following function,
callers are under no obligation to obey the `i > 0` recommendation:

```rust
{{#include ../../../rust_verify/example/guide/modes.rs:recommends1}}
```

It's perfectly legal for `test1` to call `f(0)`, and no error or warning will be generated for `g`
(in fact, Verus will not check the recommendation at all).
However, *if* there's a verification error in a function,
Verus will automatically rerun the verification with recommendation checking turned on,
in hopes that any recommendation failures will help diagnose the verification failure.
For example, in the following:

```rust
{{#include ../../../rust_verify/example/guide/modes.rs:recommends2}}
```

Verus print the failed assertion as an error and then prints the failed recommendation as a note:

```
error: assertion failed
    |
    |     assert(f(0) <= f(1)); // FAILS
    |            ^^^^^^^^^^^^ assertion failed

note: recommendation not met
    |
    |     recommends i > 0
    |                ----- recommendation not met
...
    |     assert(f(0) <= f(1)); // FAILS
    |            ^^^^^^^^^^^^
```

If the note isn't helpful, programmers are free to ignore it.

By default, Verus does not perform `recommends` checking on calls from `spec` functions:

```rust
{{#include ../../../rust_verify/example/guide/modes.rs:recommends3}}
```

However, you can write `spec(checked)` to request `recommends` checking,
which will cause Verus to generate warnings for `recommends` violations:

```rust
{{#include ../../../rust_verify/example/guide/modes.rs:recommends4}}
```

This is particularly useful for specifications that are part of the "trusted computing base"
that describes the interface to external, unverified components.

================
File: ./guide/src/requires_ensures.md
================

# Preconditions (requires clauses)

Let's start with a small example.
Suppose we want to verify a function `octuple` that multiplies a number by 8:

```rust
{{#include ../../../rust_verify/example/guide/requires_ensures_edit.rs:init}}
```

If we ask Verus to verify this code, Verus immediately reports errors about `octuple`:

```
error: possible arithmetic underflow/overflow
   |
   |     let x2 = x1 + x1;
   |              ^^^^^^^
```

Here, Verus cannot prove that the result of `x1 + x1` fits in an 8-bit `i8` value,
which allows values in the range `-128`...`127`.
If `x1` were `100`, for example, `x1 + x1` would be `200`, which is larger than `127`.
We need to make sure that when `octuple` is called, the argument `x1` is not too large.
We can do this by adding *preconditions* (also known as "`requires` clauses")
to `octuple` specifying which values for `x1` are allowed.
In Verus, preconditions are written with a `requires` followed by zero or more boolean expressions
separated by commas:

```rust
{{#include ../../../rust_verify/example/guide/requires_ensures_edit.rs:pre1}}
```

The two preconditions above say that x1 must be at least `-64` and less than `64`,
so that `x1 + x1` will fit in the range `-128`...`127`.
This fixes the error about `x1 + x1`, but we still get an error about `x2 + x2`:

```
error: possible arithmetic underflow/overflow
   |
   |     let x4 = x2 + x2;
   |              ^^^^^^^
```

If we want `x1 + x1`, `x2 + x2`, and `x4 + x4` to all succeed, we need a tighter bound on `x1`:

```rust
{{#include ../../../rust_verify/example/guide/requires_ensures_edit.rs:pre2}}
```

This time, verification is successful.

Now suppose we try to call `octuple` with a value that does not satisfy `octuple`'s precondition:

```rust
{{#include ../../../rust_verify/example/guide/requires_ensures_edit.rs:pre3}}
```

For this call, Verus reports an error, since `20` is not less than `16`:

```
error: precondition not satisfied
   |
   |         x1 < 16,
   |         ------- failed precondition
...
   |     let n = octuple(20);
   |             ^^^^^^^^^^^
```

If we pass `10` instead of `20`, verification succeeds:

```rust
{{#include ../../../rust_verify/example/guide/requires_ensures_edit.rs:pre4}}
```

# Postconditions (ensures clauses)

Suppose we want to verify properties about the value returned from `octuple`.
For example, we might want to assert that the value returned from `octuple`
is 8 times as large as the argument passed to `octuple`.
Let's try putting an assertion in `main` that the result of calling `octuple(10)` is `80`:

```rust
{{#include ../../../rust_verify/example/guide/requires_ensures_edit.rs:post1}}
```

Although `octuple(10)` really does return `80`,
Verus nevertheless reports an error:

```
error: assertion failed
   |
   |     assert(n == 80);
   |            ^^^^^^^ assertion failed
```

The error occurs because, even though `octuple` multiplies its argument by `8`,
`octuple` doesn't publicize this fact to the other functions in the program.
To do this, we can add postconditions (`ensures` clauses) to `octuple` specifying
some properties of `octuple`'s return value:

```rust
{{#include ../../../rust_verify/example/guide/requires_ensures_edit.rs:post2}}
```

To write a property about the return value, we need to give a name to the return value.
The Verus syntax for this is `-> (name: return_type)`.  In the example above,
saying `-> (x8: i8)` allows the postcondition `x8 == 8 * x1` to use the name `x8`
for `octuple`'s return value.

Preconditions and postconditions establish a modular verification protocol between functions.
When `main` calls `octuple`, Verus checks that the arguments in the call satisfy `octuple`'s
preconditions.
When Verus verifies the body of the `octuple` function,
it can assume that the preconditions are satisfied,
without having to know anything about the exact arguments passed in by `main`.
Likewise, when Verus verifies the body of the `main` function,
it can assume that `octuple` satisfies its postconditions,
without having to know anything about the body of `octuple`.
In this way, Verus can verify each function independently.
This *modular verification* approach breaks verification into small, manageable pieces,
which makes verification more efficient than if Verus tried to verify
all of a program's functions together simultaneously.
Nevertheless, writing preconditions and postconditions requires significant programmer effort ---
if you want to verify a large program with a lot of functions,
you'll probably spend substantial time writing preconditions and postconditions for the functions.

# assert and assume

While `requires` and `ensures` connect functions together,
`assert` makes a local, private request to the SMT solver to prove a certain fact.
(Note: `assert(...)` should not be confused with the Rust `assert!(...)` macro ---
the former is statically checked using the SMT solver, while the latter is checked at run-time.)

`assert` has an evil twin named `assume`, which asks the SMT solver to
simply accept some boolean expression as a fact without proof.
While `assert` is harmless and won't cause any unsoundness in a proof,
assume can easily enable a "proof" of a fact that isn't true.
In fact, by writing `assume(false)`, you can prove anything you want:

```rust
assume(false);
assert(2 + 2 == 5); // succeeds
```

Verus programmers often use `assert` and `assume` to help develop and debug proofs.
They may add temporary `assert`s to determine which facts the SMT solver can prove
and which it can't,
and they may add temporary `assume`s to see which additional assumptions are necessary
for the SMT solver to complete a proof,
or as a placeholder for parts of the proof that haven't yet been written.
As the proof evolves, the programmer replaces `assume`s with `assert`s,
and may eventually remove the `assert`s.
A complete proof may contain `assert`s, but should not contain any `assume`s.

(In some situations, `assert` can help the SMT solver complete a proof,
by giving the SMT hints about how to manipulate `forall` and `exists` expressions; see TODO.
There are also special forms of `assert`, such as `assert(...) by(bit_vector)`,
to help prove properties about bit vectors, nonlinear integer arithmetic,
`forall` expressions, etc.  These are covered in section TODO.)

# Executable code and ghost code

Let's put everything from this section together into a final version of our example program:

```rust
{{#include ../../../rust_verify/example/guide/requires_ensures.rs}}
```

Here, we've made a few final adjustments.
First, we've combined the two preconditions `-16 <= x1` and `x1 < 16`
into a single preconditon `-16 <= x1 < 16`,
since Verus lets us chain multiple inequalities together in a single expression
(equivalently, we could have also written `-16 <= x1 && x1 < 16`).
Second, we've added a function `print_two_digit_number` to print the result of `octuple`.
Unlike `main` and `octuple`, we ask Verus not to verify `print_two_digit_number`.
We do this by marking it `#[verifier::external_body]`,
so that Verus pays attention to the function's preconditions and postconditions but ignores
the function's body.
This is common in projects using Verus:
you may want to verify some of it (perhaps the program's core algorithms),
but leave other aspects, such as input-output operations, unverified.
More generally, since verifying all the software in the world is still infeasible,
there will be some boundary between verified code and unverified code,
and `#[verifier::external_body]` can be used to mark this boundary.

We can now compile the program above using the `--compile` option to Verus:

```
./tools/rust-verify.sh --compile rust_verify/example/guide/requires_ensures.rs
```

This will produce an executable that prints a message when run:

```
The answer is 80
```

Note that the generated executable does not contain the `requires`, `ensures`, and `assert` code,
since these are only needed during static verification,
not during run-time execution.
We refer to `requires`, `ensures`, `assert`, and `assume` as *ghost code*,
in contast to the *executable code* that actually gets compiled.
Verus erases all ghost code before compilation so that it imposes no run-time overhead.

================
File: ./guide/src/reference-chained-op.md
================

# Chained operators

In spec code, equality and inequality operators can be chained. For example,
`a <= b < c`
is equivalent to
`a <= b && b < c`.

Chained inequalities support `<`, `<=`, `>`, `>=`, and `==`, and support sequences of chained
operators of arbitrary length.

================
File: ./guide/src/exec_funs_as_values.md
================

# Passing functions as values

In Rust, functions may be passed by value using the `FnOnce`, `FnMut`, and `Fn` traits.
Just like for normal functions, Verus supports reasoning about the preconditions
and postconditions of such functions.

### Reasoning about preconditions and postconditions

Verus allows you to reason about the preconditions and postconditions of function values
via two builtin spec functions: `call_requires` and `call_ensures`.

 * `call_requires(f, args)` represents the precondition.
    It takes two arguments: the function object and arguments
    as a tuple. If it returns true, then it is possible to call `f` with the given args.
 * `call_ensures(f, args, output)` represents the postcondition.
    It takes takes _three_ arguments: the function object, arguments, and return vaue.
    It represents the valid input-output pairs for `f`.

The `vstd` library also [provides aliases](https://verus-lang.github.io/verus/verusdoc/vstd/pervasive/trait.FnWithRequiresEnsures.html), `f.requires(args)` and `f.ensures(args, output)`.
These mean the same thing as `call_requires` and `call_ensures`.

As with any normal call, Verus demands that the precondition be satisfied 
when you call a function object.
This is demonstrated by the following example:

```rust
{{#include ../../../rust_verify/example/guide/higher_order_fns.rs:example1}}
```

As we can see, `test` calls `higher_order_fn`, passing in `double`.
The `higher_order_fn` then calls the argument with `50`. This should be allowed,
according to the `requires` clause of `double`; however, `higher_order_fn` does not have
the information to know this is correct.
Verus gives an error:

```
error: Call to non-static function fails to satisfy `callee.requires(args)`
  --> vec_map.rs:25:5
   |
25 |     f(50)
   |     ^^^^^
```

To fix this, we can add a precondition to `higher_order_fn` that gives information on
the precondition of `f`:

```rust
{{#include ../../../rust_verify/example/guide/higher_order_fns.rs:example2}}
```

The `(50,)` looks a little funky. This is a 1-tuple.
The `call_requires` and `call_ensures` always take tuple arguments for the "args".
If `f` takes 0 arguments, then `call_requires` takes a unit tuple;
if `f` takes 2 arguments, then it takes a pair; etc.
Here, `f` takes 1 argument, so it takes a 1-tuple, which can be constructed by using
the trailing comma, as in `(50,)`.

Verus now accepts this code, as the precondition of `higher_order_fn` now guarantees that
`f` accepts the input of `50`.

We can go further and allow `higher_order_fn` to reason about the _output_ value of `f`:

```rust
{{#include ../../../rust_verify/example/guide/higher_order_fns.rs:example3}}
```

Observe that the precondition of `higher_order_fn` places a constraint on the postcondition
of `f`.
As a result, `higher_order_fn` learns information about the return value of `f(50)`.
Specifically, it learns that `call_ensures(f, (50,), ret)` holds, which by `higher_order_fn`'s
precondition, implies that `ret % 2 == 0`.

### An important note

The above examples show the idiomatic way to constrain the preconditions and postconditions
of a function argument. Observe that `call_requires` is used in a _positive_ position,
i.e., "`call_requires` holds for this value".
Meanwhile `call_ensures` is used in a _negative_ position, i.e., on the left hand side
of an implication: "if `call_ensures` holds for a given value, this is satisfies this particular constraint".

It is very common to need a guarantee that `f(args)` will return one specific value,
say `expected_return_value`.
In this situation, it can be tempting to write,

```rust
requires call_ensures(f, args, expected_return_value),
```

as your constraint. However, **this is almost never what you actually want**,
and in fact, Verus may not even let you prove it.
The proposition `call_ensures(f, args, expected_return_value)`
says that `expected_return_value` is a _possible_ return value of `f(args)`;
however, it says nothing about _other_ possible return values.
In general, `f` may be deterministic! Just because `expected_return_value` is one possible return
value does not mean it is only one.

When faced with this situation, **what you really want is to write**:

```rust
requires forall |ret| call_ensures(f, args, ret) ==> ret == expected_return_value
```

This is the proposition that you really want, i.e., "_if_ `f(args)` returns a value `ret`,
then that value is equal to `expected_return_value`".

Of course, this is flipped around when you write a postcondition, as we'll see in the
next example.

### Example: `vec_map`

Let's take what we learned and write a simple function, `vec_map`, which applies a given
function to each element of a vector and returns a new vector.

The key challenge is to determine the right specfication to use.

The signature we want is:

```rust
{{#include ../../../rust_verify/example/guide/higher_order_fns.rs:vec_map_signature}}
```

First, what do we need to **require**? We need to require that it's okay to call `f`
with any element of the vector as input.

```rust
{{#include ../../../rust_verify/example/guide/higher_order_fns.rs:vec_map_requires}}
```

Next, what ought we to **ensure**? Naturally, we want the returned vector to have the same
length as the input. Furthermore, we want to guarantee that any element in the output
vector is a possible output when the provided function `f` is called on the corresponding
element from the input vector.

```rust
{{#include ../../../rust_verify/example/guide/higher_order_fns.rs:vec_map_ensures}}
```

Now that we have a specification, the implementation and loop invariant should
fall into place:

```rust
{{#include ../../../rust_verify/example/guide/higher_order_fns.rs:vec_map}}
```

Finally, we can try it out with an example:

```rust
{{#include ../../../rust_verify/example/guide/higher_order_fns.rs:vec_map_example}}
```

### Conclusion

In this chapter, we learned how to write higher-order functions with higher-order specifications,
i.e., specifications that constrain the specifications of functions that are passed
around as values.

All of the examples from this chapter passed functions by referring to them directly by name,
e.g., passing the function `double` by writing `double`.
In Rust, a more common way to work with higher-order functions is to pass _closures_.
In the next chapter, we'll learn how to use closures.

================
File: ./guide/src/interior_mutability.md
================

# Interior Mutability

The [Interior Mutability pattern](https://doc.rust-lang.org/book/ch15-05-interior-mutability.html)
is a particular Rust pattern wherein the user is able to manipulate the contents of a value
accessed via a shared borrow `&`. (Though `&` is often referred to as "immutable borrow,"
we will call it a "shared borrow" here, to avoid confusion.)
Two common Rust types illustrating interior mutability are
[`Cell` and `RefCell`](https://doc.rust-lang.org/std/cell/).
Here, we will overview the equivalent concepts in Verus.

### Mutating stuff that can't mutate

To understand the key challenge in verifying these interior mutability patterns,
recall an important fact of Verus's SMT encoding. Verus assumes that any value of type `&T`,
for any type `T`, can never change. However, we also know that the contents of a
`&Cell<V>` might change. After all, that's the whole point of the `Cell<T>` type!

The inescapable conclusion, then, is that
_the value taken by a `Cell<T>` in Verus' SMT encoding must not depend on the cell's contents_.
Instead, the SMT "value" of a `Cell<T>` is nothing more than a unique identifier for the Cell.
In some regards, it may help to think of `Cell<T>` as similar to a pointer `T*`.
The value of the `Cell<T>` is _only_ its identifier (its "pointer address") rather than
its contents ("the thing pointed to be a pointer"). Of course, it's _not_ a pointer, but
from the perspective of the encoding, it might as well be.

Note one immediate ramification of this property:
[Verus' pure equality `===`](./equality.md) on `Cell` types cannot possibly
give the same results as Rust's standard `==` (`eq`) on `Cell` types.
Rust's `==` function actually compares the contents of the cells.
But pure equality, `===`, which must depend on the SMT encoding values,
cannot possibly depend on the contents!
Instead, `===` compares two cells as equal only if they are _the same cell_.

So, with these challenges in mind, how _do_ we handle interior mutability in Verus?

There are a few different approaches we can take.

 * When retrieving a value from the interior of a Cell-like data structure, we can model
   this as non-deterministically receiving a value of the given type.
   At first, this might seem like it gives us too little to work with for verifying
   correctness properties. However, we can impose additional structure by specifying
   _data invariants_ to restrict the space of possible values.

 * Track the exact value using `tracked ghost` code.

More sophisticated data structures---especially concurrent ones---often require a careful
balance of both approaches. We'll introduce both here.

### Data Invariants with `InvCell`.

Suppose we have an expensive computation and we want to memoize its value. The first time
we need to compute the value, we perform the computation and store its value for whenever
it's needed later. To do this, we'll use a `Cell`, whose interior is intialized to `None`
to store the computed value.
The memoized compute function will then:

 * Read the value in the `Cell`.
   * If it's `None`, then the value hasn't been computed yet.
     Compute the value, store it for later, then return it.
   * If it's `Some(x)`, then the value has already been computed,
     so return it immediately.

Crucially, the correctness of this approach doesn't actually depend on being able to
predict which of these cases any invocation will take. (It might be a different story if
we were attempting to prove a bound on the time the program will take.)
All we need to know is that it will take _one_ of these cases.
Therefore, we can verify this code by using a cell with a data invariant:

 * _Invariant:_ the value stored in the interior of the cell is either `None` or `Some(x)`,
   where `x` is the expected result of the computation.

Concretely, the above can be implemented in Verus using
[`InvCell`](https://verus-lang.github.io/verus/verusdoc/vstd/cell/struct.InvCell.html),
provided by Verus' standard library, which provides a data-invariant-based specification.
When constructing a new `InvCell<T>`, the user specifies a data invariant: some boolean predicate
over the type `T` which tells the cell what values are allowed to be stored.
Then, the `InvCell` only has to impose the restriction that whenever the user writes to the cell,
the value `val` being written has to satisfy the predicate, `cell.inv(val)`.
In exchange, though, whenever the user _reads_ from the cell, they know the value they
receive satisfies `cell.inv(val)`.

Here's an example using an `InvCell` to implement a memoized function:

```rust
{{#include ../../../rust_verify/example/guide/interior_mutability.rs:inv_cell_example}}
```

### Tracked ghost state with `PCell`.

(TODO finish writing this chapter)



================
File: ./guide/src/induction.md
================

# Recursive exec and proof functions, proofs by induction

The previous section introduced a specification for triangle numbers.
Given that, let's try a series of executable implementations of triangle numbers,
starting with a simple recursive implementation:

```rust
{{#include ../../../rust_verify/example/guide/recursion.rs:rec_fail}}
```

We immediately run into one small practical difficulty:
the implementation needs to use a finite-width integer to hold the result,
and this integer may overflow:

```
error: possible arithmetic underflow/overflow
   |
   |         n + rec_triangle(n - 1) // FAILS: possible overflow
   |         ^^^^^^^^^^^^^^^^^^^^^^^
```

Indeed, we can't expect the implementation to work if the result
won't fit in the finite-width integer type,
so it makes sense to add a precondition saying
that the result must fit,
which for a `u32` result means `triangle(n) < 0x1_0000_0000`:

```rust
{{#include ../../../rust_verify/example/guide/recursion.rs:rec}}
```

This time, verification succeeds.
It's worth pausing for a few minutes, though, to understand *why* the verification succeeds.
For example, an execution of `rec_triangle(10)`
performs 10 separate additions, each of which could potentially overflow.
How does Verus know that *none* of these 10 additions will overflow,
given just the initial precondition `triangle(10) < 0x1_0000_0000`?

The answer is that each instance of `triangle(n)` for `n != 0`
makes a recursive call to `triangle(n - 1)`,
and this recursive call must satisfy the precondition `triangle(n - 1) < 0x1_0000_0000`.
Let's look at how this is proved.
If we know `triangle(n) < 0x1_0000_0000` from `rec_triangle`'s precondition
and we use 1 unit of fuel to inline the definition of `triangle` once,
we get:

```
triangle(n) < 0x1_0000_0000
triangle(n) = if n == 0 { 0 } else { n + triangle(n - 1) }
```

In the case where `n != 0`, this simplifies to:

```
triangle(n) < 0x1_0000_0000
triangle(n) = n + triangle(n - 1)
```

From this, we conclude `n + triangle(n - 1) < 0x1_0000_0000`,
which means that `triangle(n - 1) < 0x1_0000_0000`,
since `0 <= n`, since `n` has type `u32`, which is nonnegative.

Intuitively, you can imagine that as `rec_triangle` executes,
proofs about `triangle(n) < 0x1_0000_0000` gets passed down the stack to the recursive calls,
proving `triangle(10) < 0x1_0000_0000` in the first call,
then `triangle(9) < 0x1_0000_0000` in the second call,
`triangle(8) < 0x1_0000_0000` in the third call,
and so on.
(Of course, the proofs don't actually exist at run-time ---
they are purely static and are erased before compilation ---
but this is still a reasonable way to think about it.)

## Towards an imperative implementation: mutation and tail recursion

The recursive implementation presented above is easy to write and verify,
but it's not very efficient, since it requires a lot of stack space for the recursion.
Let's take a couple small steps towards a more efficient, imperative implementation
based on while loops.
First, to prepare for the mutable variables that we'll use in while loops,
let's switch `sum` from being a return value to being a mutably updated variable:

```rust
{{#include ../../../rust_verify/example/guide/recursion.rs:mut}}
```

From the verification's point of view, this doesn't change anything significant.
Internally, when performing verification,
Verus simply represents the final value of `*sum` as a return value,
making the verification of `mut_triangle` essentially the same as
the verification of `rec_triangle`.

Next, let's try to eliminate the excessive stack usage by making the function
[tail recursive](https://en.wikipedia.org/wiki/Tail_call).
We do this by introducing and index variable `idx` that counts up from `0` to `n`,
just as a while loop would do:

```rust
{{#include ../../../rust_verify/example/guide/recursion.rs:tail_fail}}
```

In the preconditions and postconditions,
the expression `*old(sum)` refers to the initial value of `*sum`,
at the entry to the function,
while `*sum` refers to the final value, at the exit from the function.
The precondition `*old(sum) == triangle(idx as nat)` specifies that
as `tail_triangle` executes more and more recursive calls,
`sum` accumulates the sum `0 + 1 + ... + idx`.
Each recursive call increases `idx` by 1 until `idx` reaches `n`,
at which point `sum` equals `0 + 1 + ... + n` and the function simply returns `sum` unmodified.

When we try to verify `tail_triangle`, though, Verus reports an error about possible overflow:

```
error: possible arithmetic underflow/overflow
    |
    |         *sum = *sum + idx;
    |                ^^^^^^^^^^
```

This may seem perplexing at first:
why doesn't the precondition `triangle(n as nat) < 0x1_0000_0000`
automatically take care of the overflow,
as it did for `rec_triangle` and `mut_triangle`?

The problem is that we've reversed the order of the addition and the recursive call.
`rec_triangle` and `mut_triangle` made the recursive call first,
and then performed the addition.
This allowed them to prove all the necessary
facts about overflow first in the series of recursive calls
(e.g. proving `triangle(10) < 0x1_0000_0000`, `triangle(9) < 0x1_0000_0000`,
..., `triangle(0) < 0x1_0000_0000`.)
before doing the arithmetic that depends on these facts.
But `tail_triangle` tries to perform the arithmetic first,
before the recursion,
so it never has a chance to develop these facts from the original
`triangle(n) < 0x1_0000_0000` assumption.

## Proofs by induction

In the example of computing `triangle(10)`,
we need to know `triangle(0) < 0x1_0000_0000`,
then `triangle(1) < 0x1_0000_0000`,
and so on, but we only know `triangle(10) < 0x1_0000_0000` to start with.
If we somehow knew that
`triangle(0) <= triangle(10)`,
`triangle(1) <= triangle(10)`,
and so on,
then we could derive what we want from `triangle(10) < 0x1_0000_0000`.
What we need is a *lemma* that proves the if `i <= j`,
then `triangle(i) <= triangle(j)`.
In other words, we need to prove that `triangle` is monotonic.

We can use a `proof` function to implement this lemma:

```rust
{{#include ../../../rust_verify/example/guide/recursion.rs:mono}}
```

The proof is by induction on j,
where the base case of the induction is `i == j`
and the induction step relates `j - 1` to `j`.
In Verus, the induction step is implemented as a recursive call from the proof to itself
(in this example, this recursive call is line `triangle_is_monotonic(i, (j - 1) as nat)`).

As with recursive `spec` functions,
recursive `proof` functions must terminate and need a `decreases` clause.
Otherwise, it would be easy to prove `false`,
as in the following non-terminating "proof":

```rust
{{#include ../../../rust_verify/example/guide/recursion.rs:circular}}
```

We can use the `triangle_is_monotonic` lemma to complete the verification of `tail_triangle`:

```rust
{{#include ../../../rust_verify/example/guide/recursion.rs:tail}}
```

Intuitively, we can think of the call from `tail_triangle` to `triangle_is_monotonic`
as performing a similar recursive proof that `rec_triangle` and `mut_triangle`
performed as they proved their `triangle(n) < 0x1_0000_0000` preconditions
in their recursive calls.
In going from `rec_triangle` and `mut_triangle` to `tail_triangle`,
we've just shifted this recursive reasoning from the executable code into a separate recursive lemma.

================
File: ./guide/src/specs.md
================

# Basic specifications

Verus programs contain *specifications* to describe the
intended behavior of the code.
These specifications include preconditions, postconditions, assertions, and loop invariants.
Specifications are one form of *ghost code* --- code that appears in the Rust source code for verification's sake,
but does not appear in the compiled executable.

This chapter will walk through some basic examples of preconditions, postconditions,
and assertions, showing the syntax for writing these specifications
and discussing integer arithmetic and equality in specifications.

================
File: ./guide/src/assert_by_compute.md
================

# Proofs by Computation

## Motivation
Some proofs should be "obvious" by simply computing on values.  For example,
given a function `pow(base, exp)` defining exponentiation, we would like it to
be straightforward and deterministic to prove that `pow(2, 8) == 256`.
However, in general, to keep recursive functions like `pow` from overwhelming
the SMT solver with too many unrollings, Verus defaults to only unrolling such
definitions once.  Hence, to make the assertion above go through, the developer
needs to carefully adjust the amount of "fuel" provided to unroll `pow`.  Even
with such adjustment, we have observed cases where Z3 does "the wrong thing",
e.g., it does not unroll the definitions enough, or it refuses to simplify
non-linear operations on statically known constants.  As a result, seemingly
simple proofs like the one above don't always go through as expected.

## Enter Proof by Computation

Verus allows the developer to perform such proofs via computation, i.e.,
by running an internal interpreter over the asserted fact.  The developer
can specify the desired computation using `assert(e) by (compute)` (for some
expression `e`).  Continuing the example above, the developer could
write:

```rust
{{#include ../../../rust_verify/example/guide/assert_by_compute.rs:pow_concrete}}
```

In Assertion 1, Verus will internally reduce the left-hand side to 256 by repeatedly evaluating
`pow` and then simplify the entire expression to `true`.

When encoded to the SMT solver, the result will be (approximately):
```
assert(true);
assume(pow(2, 8) == 256);
```
In other words, in the encoding, we assert whatever remains after
simplification and then assume the original expression.  Hence, even if
simplification only partially succeeds, Z3 may still be able to complete the
proof.  Furthermore, because we assume the original expression, it is still
available to trigger other ambient knowledge or contribute to subsequent facts.
Hence Assertion 2 will succeed, since Z3 will unfold the definition of `pow`
once and then use the previously established fact that `pow(2,8) == 256`.

If you want to ensure that the entire proof completes through computation and
leaves no additional work for Z3, then you can use `assert(e) by
(compute_only)` as shown in Assertion 3.  Such an assertion will fail unless
the interpreter succeeds in reducing the expression completely down to `true`.
This can be useful for ensuring the stability of your proof, since it does not
rely on any Z3 heuristics.

Important note: An assertion using proof by computation does not inherit any context
from its environment.  Hence, this example:

```rust
{{#include ../../../rust_verify/example/guide/assert_by_compute.rs:let_fails}}
```

will fail, since `x` will be treated symbolically, and hence the assertion will
not simplify all the way down to `true`.  This can be remedied either
by using `assert(e) by (compute)` and allowing Z3 to finish the proof, or by moving 
the `let` into the assertion, e.g., as:

```rust
{{#include ../../../rust_verify/example/guide/assert_by_compute.rs:let_passes}}
```

While proofs by computation are most useful for concrete values, the interpreter
also supports symbolic values, and hence it can complete certain proofs 
symbolically.  For example, given variables `a, b, c, d`, the following succeeds:

```rust
{{#include ../../../rust_verify/example/guide/assert_by_compute.rs:seq_example}}
```

To prevent infinite interpretation loops (which can arise even when the code is
proven to terminate, since the termination proof only applies to concrete
inputs, whereas the interpreter may encounter symbolic values), Verus limits
the time it will spend interpreting any given proof by computation.
Specifically, the time limit is the number of seconds specified via the
`--rlimit` command-line option.

By default, the interpreter does not cache function call results based on the 
value of the arguments passed to the function.  Experiments showed this typically
hurts performance, since it entails traversing the (large) AST nodes representing
the arguments.  However, some examples need such caching to succceed (e.g., computing
with the naive definition of Fibonacci).  Such functions can be annotated with
`#[verifier::memoize]`, which will cause their results to be cached during computation.

## Current Limitations

0. As mentioned above, the expression given to a proof by computation is
   interpreted in isolation from any surrounding context.
1. The expression passed to a proof-by-computation assertion must be in spec mode,
   which means it cannot be used on proof or exec mode functions.
2. The interpreter is recursive, so a deeply nested expression (or
   series of function calls) may cause Verus to exceed the process'
   stack space.

## See Also

1. The [test suite](https://github.com/verus-lang/verus/blob/main/source/rust_verify_test/tests/assert_by_compute.rs) has a variety of small examples.
2. We also have several [more complex examples](https://github.com/verus-lang/verus/blob/main/source/rust_verify/example/assert_by_compute.rs).

================
File: ./guide/src/exists.md
================

# exists and choose

`exists` expressions are the dual of `forall` expressions.
While `forall|i: int| f(i)` means that `f(i)` is true for all `i`,
`exists|i: int| f(i)` means that `f(i)` is true for at least one `i`.
To prove `exists|i: int| f(i)`,
an SMT solver has to find one value for `i` such that `f(i)` is true.
This value is called a *witness* for `exists|i: int| f(i)`.
As with `forall` expressions, proofs about `exists` expressions are based on triggers.
Specifically, to prove an `exists` expression,
the SMT solver uses the `exists` expression's trigger to try to find a witness.

In the following example, the trigger is `is_even(i)`:

```rust
{{#include ../../../rust_verify/example/guide/quants.rs:test_exists_succeeds}}
```

There are three expressions that match the trigger:
`is_even(4)`, `is_even(5)`, and `is_even(6)`.
Two of them, `is_even(4)` and `is_even(6)` are possible witnesses
for `exists|i: int| #[trigger] is_even(i)`.
Based on these, the assertion succeeds, using either `i = 4` or `i = 6` as a witness.

By contrast, the same assertion fails in the following code,
since no expressions matching `is_even(i)` are around:

```rust
{{#include ../../../rust_verify/example/guide/quants.rs:test_exists_fails}}
```

## choose

The proofs above try to prove that an `exists` expression is true.
Suppose, though, that we already know that an `exists` expression is true,
perhaps because we assume it as a function precondition.
This means that some witness to the `exists` expression must exist.
If we want to get the witness, we can use a `choose` expression.

A `choose` expression `choose|i: int| f(i)` implements
the Hilbert choice operator
(sometimes known as [epsilon](https://en.wikipedia.org/wiki/Epsilon_calculus)):
it chooses some value `i` that satisfies `f(i)` if such a value exists.
Otherwise, it picks an arbitrary value for `i`.

The following example assumes `exists|i: int| f(i)` as a precondition.
Based on this, the SMT solver knows that there is at least one witness `i`
that makes `f(i)` true,
and `choose` picks one of these witnesses arbitrarily:

```rust
{{#include ../../../rust_verify/example/guide/quants.rs:test_choose_succeeds}}
```

If, on the other hand, we don't know `exists|i: int| f(i)`,
then `choose` just returns an arbitrary value that might not satisfy `f(i)`
(as discussed in [ghost vs exec code](./ghost_vs_exec.md),
ghost code can create an arbitrary value of any type):

```rust
{{#include ../../../rust_verify/example/guide/quants.rs:test_choose_fails}}
```

Regardless of whether we know `exists|i: int| f(i)` or not,
the `choose|i: int| f(i)` expression always returns the same value:

```rust
{{#include ../../../rust_verify/example/guide/quants.rs:test_choose_same}}
```

You can also choose multiple values together,
collecting the values in a tuple:

```rust
{{#include ../../../rust_verify/example/guide/quants.rs:test_choose_succeeds2}}
```

In this example, the SMT solver can prove
`exists|i: int, j: int| less_than(i, j)`
because the expression `less_than(3, 7)` matches the
automatically chosen trigger `less_than(i, j)` when `i = 3` and `j = 7`,
so that `i = 3, j = 7` serves as a witness.

TODO: `(x, y)` should not require the type annotation `: (int, int)`

================
File: ./guide/src/exec_closures.md
================

# Exec closures

In the previous sections, we discussed how Verus uses closure syntax `|x| { ... }`
as part of various `spec`-mode features (mathematical functions, quantifiers).
Verus also supports closures as they are used in ordinary Rust, that is,
to define anonymous, _executable_ functions that may be passed around and called.



## Closure Contexts and function traits: `FnOnce`, `FnMut`, and `Fn`

One of the most challenging aspects of closures, in general, is that closures
can capture variables from the surrounding context.
Rust resolves this challenge through its hierarcy of function traits:
`FnOnce`, `FnMut`, and `Fn`.
The declaration of the closure and the details of its context capture determine
which traits it has. In turn,
the traits determine what capabilities the caller has: Can they call it more than
once? Can they call it in parallel?

See [the Rust documentation](https://doc.rust-lang.org/book/ch13-01-closures.html#moving-captured-values-out-of-closures-and-the-fn-traits) for a more detailed introduction.

In brief, the traits provide the following capabilities to callers and
restrictions on the context capture:

|          | Caller capability                            | Capturing                               |
|----------|----------------------------------------------|-----------------------------------------|
| `FnOnce` | May call once                                | May move variables from the context     |
| `FnMut`  | May call multiple times via `&mut` reference | May borrow _mutably_ from the context   |
| `Fn`     | May call multiple times via `&` reference    | May borrow _immutably_ from the context |

Verus does not yet support borrowing mutably from the context,
though it does handle moving and immutable borrows easily.
Therefore, Verus has better support for `Fn` and `FnOnce`---it does not yet take advantage of the
capturing capabilities supported by Rust's `FnMut`.



================
File: ./guide/src/binary_search.md
================

# Example: binary search

Let's see how `forall` and `exists` work in a larger example.
The following code searches for a value `k` in a sorted sequence
and returns the index `r` where `k` resides.

```rust
{{#include ../../../rust_verify/example/guide/quants.rs:binary_search}}
```

The precondition `exists|i: int| 0 <= i < v.len() && k == v[i]`
specifies that `k` is somewhere in the sequence,
so that the search is guaranteed to find it.
The automatically inferred trigger for this `exists` expression is `v[i]`.
The `main` function satisfies this with the witness `i = 3` so that `30 == v[3]`:

```
assert(v[3] == 30); // needed to trigger exists|i: int| ... k == v[i]
let r = binary_search(&v, 30);
```

The search proceeds by keeping two indices `i1` and `i2` that
narrow in on `k` from both sides,
so that the index containing `k` remains between `i1` and `i2`
throughout the search:

```
exists|i: int| i1 <= i <= i2 && k == v[i]
```

In order for the loop to exit, the loop condition `i1 != i2` must be false,
which means that `i1` and `i2` must be equal.
In this case, the `i` in the `exists` expression above must be equal to `i1` and `i2`,
so we know `k == v[i1]`,
so that we can return the result `i1`.

## Proving that the loop invariant is maintained

In each loop iteration, we can assume that the loop invariants hold before the iteration,
and we have to prove that the loop invariants hold after the iteration.
Let's look in more detail at the proof of the invariant
`exists|i: int| i1 <= i <= i2 && k == v[i]`,
focusing on how the SMT solver handles the `forall` and `exists` quantifiers.

The key steps are:
- Knowing `exists|i: int| ... k == v[i]` gives us a witness `i_witness`
  such that `k == v[i_witness]`.
- The witness `i_witness` from the current iteration's
  `exists|i: int| ...` serves as the witness for the next iteration's
  `exists|i: int| ...`.
- The comparison `*v.index(ix) < k` tells us whether `v[ix] < k` or `v[ix] >= k`.
- The expressions `v[i_witness]` and `v[ix]` match the trigger `v[i], v[j]` trigger
  in the expression `forall|i: int, j: int| ... v[i] <= v[j]`.

We'll now walk through these steps in more detail.
(Feel free to [skip ahead](./binary_search.md#helping-the-automation-succeed) if this is too boring ---
as the next subsection discusses,
the whole point is that the SMT solver takes care of the boring details automatically
if we set things up right.)

There are two cases to consider, one where the `if` condition `*v.index(ix) < k` is true and one
where `*v.index(ix) < k` is false.
We'll just look at the former, where `v[ik] < k`.

We assume the loop invariant at the beginning of the loop iteration:

```
exists|i: int| i1 <= i <= i2 && k == v[i]
```

This tells us that there is some witness `i_witness` such that:

```
i1 <= i_witness <= i2 && k == v[i_witness]
```

In the case where `*v.index(ix) < k` is true, we execute `i1 = ix + 1`:

```rust
let ix = i1 + (i2 - i1) / 2;
if *v.index(ix) < k {
    i1 = ix + 1;
} else {
```

Since the new value of `i1` is `ix + 1`,
we'll need to prove the loop invariant with `ix + 1` substituted for `i1`:

```
exists|i: int| ix + 1 <= i <= i2 && k == v[i]
```

To prove an `exists` expression, the SMT solver needs to match the expression's trigger.
The automatically chosen trigger for this expression is `v[i]`,
so the SMT solver looks for expressions of the form `v[...]`.
It finds `v[i_witness]` from the previous loop invariant (shown above).
It also finds `v[ix]` from the call `v.index(ix)` in the expression `*v.index(ix) < k`.
Based on these, it attempts to prove `ix + 1 <= i <= i2 && k == v[i]`
with `i = i_witness` or `i = ix`:

```
ix + 1 <= i_witness <= i2 && k == v[i_witness]
ix + 1 <= ix <= i2 && k == v[ix]
```

The `i = ix` case is a dead end, because `ix + 1 <= ix` is never true.
The `i = i_witness` case is more promising.
We already know `i_witness <= i2` and `k == v[i_witness]`
from our assumptions about `i_witness` at the beginning of the loop iteration.
We just need to prove `ix + 1 <= i_witness`.
We can simplify this to `ix < i_witness`.

#### Proving ix < i_witness

To prove `ix < i_witness`, we now turn to the `forall` loop invariant:

```
forall|i: int, j: int| 0 <= i <= j < v.len() ==> v[i] <= v[j],
```

In order to instantiate this, the SMT solver again relies on triggers.
In this `forall`, expression, the trigger is `v[i], v[j]`,
so again the SMT solver looks for terms of the form `v[...]`
and finds `v[i_witness]` and `v[ix]`.
There are four different possible assignments of `i_witness` and `ix` to `i` and `j`.

```
0 <= i_witness <= i_witness < v.len() ==> v[i_witness] <= v[i_witness]
0 <= i_witness <= ix < v.len() ==> v[i_witness] <= v[ix]
0 <= ix <= i_witness < v.len() ==> v[ix] <= v[i_witness]
0 <= ix <= ix < v.len() ==> v[ix] <= v[ix]
```

Out of these, the second one is most useful:

```
0 <= i_witness <= ix < v.len() ==> v[i_witness] <= v[ix]
```

We already know `k == v[i_witness]`, so this becomes:

```
0 <= i_witness <= ix < v.len() ==> k <= v[ix]
```

The right-hand side of the `==>` says `k <= v[ix]`,
which contradicts our assumption that `v[ik] < k` in the case where `*v.index(ix) < k`.
This means that the left-hand side of the `==>` must be false:

```
!(0 <= i_witness <= ix < v.len())
```

The SMT solver knows that `0 <= i_witness` and `ix < v.len()`,
so it narrows this down to:

```
!(i_witness <= ix)
```

This tells us that `ix < i_witness`, which is what we want.

## Helping the automation succeed

As seen in the previous section,
proving the loop invariant requires a long chain of reasoning.
Fortunately, the SMT solver performs all of these steps automatically.
In fact, this is a particularly fortunate example,
because Verus automatically chooses the triggers as well,
and these triggers happen to be just what the SMT solver needs to complete the proof.

In general, though, how we express the preconditions, postconditions,
and loop invariants has a big influence on whether Verus and the SMT solver
succeed automatically.
Suppose, for example, that we had written the sortedness condition
(in the precondition and loop invariant) as:

```
forall|i: int| 0 <= i < v.len() - 1 ==> #[trigger] v[i] <= v[i + 1]
```

instead of:

```
forall|i: int, j: int| 0 <= i <= j < v.len() ==> v[i] <= v[j]
```

As discussed in a [previous section](./multitriggers.md),
the trigger `v[i]` in combination with `v[i] <= v[i + 1]` leads to a matching loop,
which can send the SMT solver into an infinite loop.
This is, in fact, exactly what happens:

```
error: while loop: Resource limit (rlimit) exceeded; consider rerunning with --profile for more details
    |
    | /     while i1 != i2
    | |         invariant
    | |             i2 < v.len(),
    | |             exists|i: int| i1 <= i <= i2 && k == v[i],
      |
    | |         }
    | |     }
    | |_____^
```

Even if the SMT solver had avoided the infinite loop, though,
it's hard to see how it could have succeeded automatically.
As discussed above, a crucial step involves instantiating
`i = i_witness` and `j = ix` to learn something about `v[i_witness] <= v[ix]`.
This simply isn't a possible instantiation when there's only one variable `i`
in the `forall` expression.
Learning something about `v[i_witness] <= v[ix]` would require chaining together
an arbitrarily long sequence of `v[i] <= v[i + 1]` steps to get from
`i_witness` to `i_witness + 1` to `i_witness + 2` all the way to `ix`.
This would require a separate proof by induction.
Intuitively, the expression `v[i] <= v[j]`
is better suited than `v[i] <= v[i + 1]`
to an algorithm like binary search that takes large steps from one index to another,
because `i` and `j` can be arbitrarily far apart,
whereas `i` and `i + 1` are only one element apart.

When the SMT automation fails, it's often tempting to immediately start adding `assert`s,
lemmas, proofs by induction, etc., until the proof succeeds.
Given enough manual effort, we could probably finish a proof of binary search with the problematic
`v[i] <= v[i + 1]` definition of sortedness.
But this would be a mistake;
it's better to structure the definitions in a way that helps the automation succeed
without so much manual effort.
If you find yourself writing a long manual proof,
it's worth stepping back and figuring out why the automation is failing;
maybe a change of definitions can fix the failure in the automation.

After all, if your car breaks down, it's usually better to fix the car than to push it.

================
File: ./guide/src/reference-at-sign.md
================

# The view function `@`

The expression `expr@` is a shorthand for `expr.view()`. The `view()` function is a Verus
convention for the abstraction of an exec-mode object, usually [defined by the `View` trait](https://verus-lang.github.io/verus/verusdoc/vstd/view/trait.View.html).
However, the expansion of the `@` syntax is purely syntactic, so it does not necessarily
correspond to the trait function.

================
File: ./guide/src/nonlinear.md
================

# Integers: Nonlinear Arithmetic and Bit Manipulation

Some properties about integers are very difficult (or expensive) to reason about fully automatically.
To tackle these properties, Verus offers several dedicated proof strategies.

One such property is **nonlinear arithmetic**,
which involves equations that multiply, divide, or take the remainder of integer variables 
(e.g., `x * (y * z) == (x * y) * z`).  As discussed earlier in this guide, determining the truth of such formulas
is undecideable in general, meaning that general-purpose SMT solvers like Z3 can only make a best-effort attempt
to solve them.  These attempts rely on heuristics that can be unpredictable.  Hence, by default, Verus 
disables Z3's nonlinear arithmetic heuristics.  When you need to prove such properties, Verus offers the two dedicated
proof strategies described below.  First, the `integer_ring` feature can reliably prove a limited subset of nonlinear properties.  For properties
outside that subset, Verus offers a way to invoke Z3's nonlinear heuristics in a way that will hopefully provide
better reliability.

## 1. Proving General Properties with Z3 
To prove a nonlinear formula that cannot be solved using `integer_ring` feature,
you can selectively turn on Z3's nonlinear reasoning heuristics.
As described below, you can do this either inline in the midst of a larger
function, or in a dedicated proof function.

### Inline Proofs with `assert(...) by(nonlinear_arith)`
To prove a nonlinear property in the midst of a larger function,
you can write `assert(...) by(nonlinear_arith)`.  This creates
a separate Z3 query just to prove the asserted property,
and for this query, Z3 runs with its nonlinear heuristics enabled.
The query does not include ambient facts (e.g., knowledge that stems
from the surrounding function's `requires` clause
or from preceding variable assignments) other than each variable's type invariants
(e.g., the fact that a `nat` is non-negative).  To include additional
context in the query, you can specify it in a `requires` clause for the `assert`,
as shown below.
```rust
{{#include ../../../rust_verify/example/guide/nonlinear_bitvec.rs:bound_checking}}
```

### Modular Proofs with `proof fn ... by(nonlinear_arith)`
You can also use `by(nonlinear_arith)` in a proof function's signature. By including `by(nonlinear_arith)`, the query for this function runs with nonlinear arithmetic reasoning enabled.



## 2. Proving Ring-based Properties with Singular

While general nonlinear formulas cannot be solved consistently, certain
sub-classes of nonlinear formulas can be.  For example, nonlinear formulas that
consist of a series of congruence relations (i.e., equalities modulo some
divisor `n`).  As a simple example, we might like to show that `a % n == b % n
==> (a * c) % n == (b * c) % n`.

Verus offers a deterministic proof strategy to discharge such obligations.
As shown below, to use this strategy, you must state the desired property
as a proof function annotated with `by(integer_ring)`.


Verus will then discharge the proof obligation using a dedicated algebra solver
called [Singular](https://www.singular.uni-kl.de/).  As hinted at by the
annotation, this proof technique is only complete (i.e., guaranteed to succeed)
for properties that are true for all
[rings](https://en.wikipedia.org/wiki/Ring_(mathematics)).   Formulas that rely
specifically on properties of the integers may not be solved successfully.

Using this proof technique requires a bit of additional configuration of your Verus installation.

### Setup

1. Install Singular
    - To use Singular's standard library, you need more than just the Singular executable binary. 
      Hence, when possible, we strongly recommend using your system's package manager.  Here are 
      some suggested steps for different platforms.
        - Mac: `brew install Singular` and set the `VERUS_SINGULAR_PATH` environment variable when running Verus. (e.g. `VERUS_SINGULAR_PATH=/usr/local/bin/Singular`). For more options, see Singular's [OS X installation guide](https://www.singular.uni-kl.de/index.php/singular-download/install-os-x.html). 

        - Debian-based Linux: `apt-get install singular` and set the `VERUS_SINGULAR_PATH` environment variable when running Verus. (e.g. `VERUS_SINGULAR_PATH=/usr/bin/Singular`). For more options, see Singular's [Linux installation guide](https://www.singular.uni-kl.de/index.php/singular-download/install-linuxunix.html).

        - Windows: See Singular's [Windows installation guide](https://www.singular.uni-kl.de/index.php/singular-download/install-windows.html).

2. Compiling Verus with Singular Support
    - The `integer_ring` functionality is conditionally compiled when the `singular` feature is set.
      To add this feature, add the `--features singular` flag when you invoke `vargo build` to compile Verus.




### Details/Limitations
- This can be used only with **int** parameters.
- Formulas that involve inequalities are not supported.   
- Division is not supported.
- Function calls in the formulas are treated as uninterpreted functions.  If a function definition is important for the proof, you should unfold the definition of the function in the proof function's `requires` clause.
- When using an `integer_ring` lemma, the divisor of a modulus operator (`%`) must not be zero. If a divisor can be zero in the ensures clause of the `integer_ring` lemma, the facts in the ensures clause will not be available in the callsite.

To understand what `integer_ring` can or cannot do, it is important to understand how it
handles the modulus operator, `%`. Since `integer_ring` does not understand inequalities,
it cannot perform reasoning that requires that `0 <= (a % b) < b`.
As a result, Singular's results might be confusing if you think of `%` primarily
as the programming language operator.

For example, suppose you use `a % b == x` as a precondition.
Encoded in Singular, this will become `a % b == x % b`, or in more traditional "mathematical"
language, `a ≡ x (mod b)`. This does _not_ imply that `x` is in the range `[0, b)`,
it only implies that `a` and `x` are in the same equivalence class mod b.
In other words, `a % b == x` implies `a ≡ x (mod b)`, but not vice versa.

For the same reason, you cannot ask the `integer_ring` solver to prove a postcondition
of the form `a % b == x`, unless `x` is 0. The `integer_ring` solver can prove
that `a ≡ x (mod b)`, equivalently `(a - x) % b == 0`, but this does _not_ imply
that `a % b == x`.

Let's look at a specific example to understand the limitation.

```rust
proof fn foo(a: int, b: int, c: int, d: int, x: int, y: int) by(integer_ring)
    requires
        a % b == x,
        c % d == y
    ensures
        x == y,
{
}
```

This theorem statement appears to be trivial, and indeed, Verus would solve it easily
using its default proof strategy. 
However, `integer_ring` will not solve it. On failure, Verus prints information about
the Singular query, which we can inspect to understand why (this is cleaned up a bit):

```
ring ring_R=integer, (a, b, c, d, x, y, tmp_0, tmp_1, tmp_2), dp;
    ideal ideal_I =
      (a - (b * tmp_0)) - x,
      (c - (d * tmp_1)) - y;
    ideal ideal_G = groebner(ideal_I);
    reduce(x - y, ideal_G);
    quit;
```

We can see here that `a % b` is translated to `a - b * tmp_0`,
while `c % d` is translated to `c - d * tmp_1`.
Again, since there is no constraint that `a - b * tmp_0` or `c - d * tmp_1`
is bounded, it is not possible to conclude 
that `a - b * tmp_0 == c - d * tmp_1` after this simplification has taken place.

## 3. Combining `integer_ring` and `nonlinear_arith`.

As explained above, the `integer_ring` feature has several limitations, it is not possible to get an arbitary nonlinear property only with the `integer_ring` feature. Instead, it is a common pattern to have a `by(nonlinear_arith)` function as a main lemma for the desired property, and use `integer_ring` lemma as a helper lemma.

To work around the lack of support for inequalities and division, you can often write a helper proof discharged with `integer_ring` and use it to prove properties that are not directly supported by `integer_ring`. Furthermore, you can also add additional variables to the formulas. For example, to work around division, one can introduce `c` where `b = a * c`, instead of `b/a`.

#### Example 1: `integer_ring` as a helper lemma to provide facts on modular arithmetic
In the `lemma_mod_difference_equal` function below, we have four inequalities inside the requires clauses, which cannot be encoded into `integer_ring`. In the ensures clause, we want to prove `y % d - x % d == y - x`. The helper lemma `lemma_mod_difference_equal_helper` simply provides that `y % d - x % d` is equal to `(y - x)` modulo `d`. The rest of the proof is done by `by(nonlinear_arith)`.

```rust
pub proof fn lemma_mod_difference_equal_helper(x: int, y:int, d:int, small_x:int, small_y:int, tmp1:int, tmp2:int) by(integer_ring)
    requires
        small_x == x % d,
        small_y == y % d,
        tmp1 == (small_y - small_x) % d,
        tmp2 == (y - x) % d,
    ensures
        (tmp1 - tmp2) % d == 0
{}
pub proof fn lemma_mod_difference_equal(x: int, y: int, d: int) by(nonlinear_arith)
    requires
        d > 0,
        x <= y,
        x % d <= y % d,
        y - x < d
    ensures
        y % d - x % d == y - x
{
    let small_x = x % d;
    let small_y = y % d;
    let tmp1 = (small_y - small_x) % d;
    let tmp2 = (y - x) % d;
    lemma_mod_difference_equal_helper(x,y,d, small_x, small_y, tmp1, tmp2);
}
```

In the `lemma_mod_between` function below, we want to prove that `x % d <= z % d < y % d`. However, `integer_ring` only supports equalities, so we cannot prove `lemma_mod_between` directly. Instead, we provide facts that can help assist the proof. The helper lemma provides 1) `x % d - y % d == x - y  (mod d)` and 2) ` y % d - z % d == y - z  (mod d)`. The rest of the proof is done via `by(nonlinear_arith)`.

```rust
pub proof fn lemma_mod_between_helper(x: int, y: int, d: int, small_x:int, small_y:int, tmp1:int) by(integer_ring)
    requires
        small_x == x % d,
        small_y == y % d,
        tmp1 == (small_x - small_y) % d,
    ensures
        (tmp1 - (x-y)) % d == 0
{}

// note that below two facts are from the helper function, and the rest are done by `by(nonlinear_arith)`.
// x % d - y % d == x - y  (mod d)
// y % d - z % d == y - z  (mod d)
pub proof fn lemma_mod_between(d: int, x: int, y: int, z: int) by(nonlinear_arith)
    requires
        d > 0,
        x % d < y % d,
        y - x <= d,
        x <= z < y
    ensures
        x % d <= z % d < y % d
{
    let small_x = x % d;
    let small_y = y % d;
    let small_z = z % d;
    let tmp1 = (small_x - small_z) % d;
    lemma_mod_between_helper(x,z,d, small_x, small_z, tmp1);

    let tmp2 = (small_z - small_y) % d;
    lemma_mod_between_helper(z,y,d, small_z, small_y, tmp2);    
}
```


#### Example 2: Proving properties on bounded integers with the help of `integer_ring`

Since `integer_ring` proofs only support `int`, you need to include explicit bounds when you want to prove properties about bounded integers. For example, as shown below, in order to use the proof `lemma_mod_after_mul` on `u32`s, `lemma_mod_after_mul_u32` must ensure that all arguments are within the proper bounds before passing them to `lemma_mod_after_mul`.  

If a necessary bound (e.g., `m > 0`) is not included, Verus will fail to verify the proof.

```rust
proof fn lemma_mod_after_mul(x: int, y: int, z: int, m: int) by (integer_ring)
    requires (x-y) % m == 0
    ensures (x*z - y*z) % m == 0
{}

proof fn lemma_mod_after_mul_u32(x: u32, y: u32 , z: u32, m: u32)   
    requires
        m > 0,
        (x-y) % (m as int) == 0,
        x >= y,
        x <= 0xffff,
        y <= 0xffff,
        z <= 0xffff,
        m <= 0xffff,
    ensures (x*z - y*z) % (m as int) == 0
{ 
  lemma_mod_after_mul(x as int, y as int, z as int, m as int);
  // rest of proof body omitted for space
}
```

The desired property for `nat` can be proved similarly.

The next example is similar, but note that we introduce several additional variables(`ab`, `bc`, and `abc`) to help with the integer_ring proof.

```rust
pub proof fn multiple_offsed_mod_gt_0_helper(a: int, b: int, c: int, ac: int, bc: int, abc: int) by (integer_ring)
    requires
        ac == a % c,
        bc == b % c,
        abc == (a - b) % c,
    ensures (ac - bc - abc) % c == 0
{}

pub proof fn multiple_offsed_mod_gt_0(a: nat, b: nat, c: nat) by (nonlinear_arith) 
    requires
        a > b,
        c > 0,
        b % c == 0,
        a % c > 0,
    ensures (a - b) % (c as int) > 0
{
    multiple_offsed_mod_gt_0_helper(
      a as int, 
      b as int, 
      c as int, 
      (a % c) as int, 
      (b % c) as int, 
      ((a - b) % (c as int)) as int
    );
}
```

More `integer_ring` examples can be found in [this folder](https://github.com/verus-lang/verus/tree/main/source/rust_verify/example/integer_ring), and this [testcase file](https://github.com/verus-lang/verus/blob/main/source/rust_verify_test/tests/integer_ring.rs).

### Examining the encoding
Singular queries will be logged to the directory specified with `--log-dir` (which defaults to `.verus-log`) in a separate file with a `.singular` suffix. You can directly run Singular on this file. For example, `Singular .verus-log/root.singular --q`. 
The output is `0` when Singular successsfully verifies the query.

================
File: ./guide/src/broadcast_proof.md
================

# Adding Ambient Facts to the Proof Environment with `broadcast`

In a typical Verus project,
a developer might prove a fact 
(e.g., that reversing a sequence preserves its length)
in a proof function, e.g.,
```rust
pub proof fn seq_reverse_len<A>(s: Seq<A>)
    ensures
        reverse(s).len() == s.len(), 
{
  ...
}
```
To make use of this fact, the developer must explicitly invoke the proof function,
e.g.,
```rust
fn example(s: Seq<bool>) {
  let t = reverse(s);
  // assert(t.len() == s.len()); // FAILS
  seq_reverse(s);                // Adds the proof's fact to the proof environment
  assert(t.len() == s.len());    // SUCCEEDS
}
```
However, in some cases, a proof fact is so useful that a developer always
wants it to be in scope, without manually invoking the corresponding proof.
For example, the fact that an empty sequence's length is zero is so "obvious"
that most programmers will expect Verus to always know it.
This feature should be used with caution, however, as every extra ambient
fact slows the prover's overall performance.

Suppose that after considering the impact on the solver's performance, the
programmer decides to make the above fact about `reverse` ambient.  To do so,
they can add the `broadcast` modifier in the
definition of `seq_reverse_len`: `pub broadcast proof fn seq_reverse_len<A>(s: Seq<A>)`.
The effect is to introduce the following
quantified fact to the proof environment:
```rust
forall |s| reverse(s).len() == s.len()
```
Because this introduces a quantifier, Verus will typically ask you to
explicitly choose a trigger, e.g., by adding a `#[trigger]` annotation.
Hence, the final version of our example might look like this:
```rust
pub broadcast proof fn seq_reverse_len<A>(s: Seq<A>)
    ensures
        #[trigger] reverse(s).len() == s.len(), 
{
  ...
}
```

To bring this ambient lemma into scope, for a specific proof, or for an entire
module, you can use `broadcast use seq_reverse_len;`.

Some of these broadcast-ed lemmas are available in the verus standard library `vstd`,
some as part of broadcast "groups", which combine a number of properties into a single
group name, which can be brought into scope with `broadcast use broadcast_group_name;`.
We are working on extending the discoverablility of these groups in the standard library
documentation: they currently appear as regular functions.
================
File: ./guide/src/features.md
================

# Supported Rust Features

Quick reference for supported Rust features. Note that this list does not include all _Verus_ features, as Verus has many spec/proof features without any standard Rust equivalent---this list only concerns Rust features. See [the guide](./modes.md) for more information about Verus' distinction between executable Rust code, specification code, and proof code.

Note that Verus is in active development. If a feature is unsupported, it might be genuinely hard, or it might just be low priority. See the [github issues](https://github.com/verus-lang/verus/issues) or [discussions](https://github.com/verus-lang/verus/discussions) for information on planned features.

**Last Updated: 2023-12-11**

<div class="table-wrapper"><table>
  <thead><tr><th colspan="2"><strong>Items</strong></th></tr></thead>
  <tbody>
  <tr>
    <td>Functions, methods, associated functions</td>
    <td>Supported</td>
  </tr>
  <tr>
    <td>Structs</td>
    <td>Supported</td>
  </tr>
  <tr>
    <td>Enums</td>
    <td>Supported</td>
  </tr>
  <tr>
    <td>Const functions</td>
    <td>Partially supported</td>
  </tr>
  <tr>
    <td>Async functions</td>
    <td>Not supported</td>
  </tr>
  <tr>
    <td>Macros</td>
    <td>Supported</td>
  </tr>
  <tr>
    <td>Type aliases</td>
    <td>Supported</td>
  </tr>
  <tr>
    <td>Const items</td>
    <td>Partially supported</td>
  </tr>
  <tr>
    <td>Static items</td>
    <td><a href="static.html">Partially supported</a></td>
  </tr>
  <tr>
    <td>Unions</td>
    <td>Not supported</td>
  </tr>
  </tbody>
  <thead><tr><th colspan="2"><strong>Struct/enum definitions</strong></th></tr></thead>
  <tbody>
  <tr>
    <td>Type parameters</td>
    <td>Supported</td>
  </tr>
  <tr>
    <td>Where clauses</td>
    <td>Supported</td>
  </tr>
  <tr>
    <td>Lifetime parameters</td>
    <td>Supported</td>
  </tr>
  <tr>
    <td>Const generics</td>
    <td>Not supported</td>
  </tr>
  <tr>
    <td>Custom discriminants</td>
    <td>Not supported</td>
  </tr>
  <tr>
    <td>public / private fields</td>
    <td>Partially supported</td>
  </tr>
  </tbody>
  <thead><tr><th colspan="2"><strong>Expressions and Statements</strong></th></tr></thead>
  <tbody>
  <tr>
    <td>Variables, assignment, mut variables</td>
    <td>Supported</td>
  </tr>
  <tr>
    <td>If, else</td>
    <td>Supported</td>
  </tr>
  <tr>
    <td>patterns, match, if-let, match guards</td>
    <td>Supported</td>
  </tr>
  <tr>
    <td>Block expressions</td>
    <td>Supported</td>
  </tr>
  <tr>
    <td>Items</td>
    <td>Not supported</td>
  </tr>
  <tr>
    <td><code>loop</code>, <code>while</code></td>
    <td><a href="while.html">Supported</a></td>
  </tr>
  <tr>
    <td><code>for</code></td>
    <td>Not supported</td>
  </tr>
  <tr>
    <td><code>?</code></td>
    <td>Not supported</td>
  </tr>
  <tr>
    <td>Async blocks</td>
    <td>Not supported</td>
  </tr>
  <tr>
    <td>await</td>
    <td>Not supported</td>
  </tr>
  <tr>
    <td>Unsafe blocks</td>
    <td>Not supported</td>
  </tr>
  <tr>
    <td><code>&</code></td>
    <td>Supported</td>
  </tr>
  <tr>
    <td><code>&mut</code>, place expressions</td>
    <td>Partially supported</td>
  </tr>
  <tr>
    <td><code>==</code>, <code>!=</code></td>
    <td>Supported, for certain types</td>
  </tr>
  <tr>
    <td>Type cast (<code>as</code>)</td>
    <td>Partially supported</td>
  </tr>
  <tr>
    <td>Compound assigments (<code>+=</code>, etc.)</td>
    <td>Supported</td>
  </tr>
  <tr>
    <td>Array expressions</td>
    <td>Partially supported (no fill expressions)</td>
  </tr>
  <tr>
    <td>Range expressions</td>
    <td>Not supported</td>
  </tr>
  <tr>
    <td>Index expressions</td>
    <td>Not supported</td>
  </tr>
  <tr>
    <td>Tuple expressions</td>
    <td>Supported</td>
  </tr>
  <tr>
    <td>Struct/enum constructors</td>
    <td>Supported</td>
  </tr>
  <tr>
    <td>Field access</td>
    <td>Supported</td>
  </tr>
  <tr>
    <td>Function and method calls</td>
    <td>Supported</td>
  </tr>
  <tr>
    <td>Closures</td>
    <td>Supported</td>
  </tr>
  <tr>
    <td>Labels, break, continue</td>
    <td><a href="break.html">Supported</a></td>
  </tr>
  <tr>
    <td>Return statements</td>
    <td>Supported</td>
  </tr>
  </tbody>
  <thead><tr><th colspan="2"><strong>Integer arithmetic</strong></th></tr></thead>
  <tbody>
  <tr>
    <td>Arithmetic for unsigned</td>
    <td><a href="integers.html">Supported</a></td>
  </tr>
  <tr>
    <td>Arithmetic for signed (<code>+</code>, <code>-</code>, <code>*</code>)</td>
    <td><a href="integers.html">Supported</a></td>
  </tr>
  <tr>
    <td>Arithmetic for signed (<code>/</code>, <code>%</code>)</td>
    <td>Not supported</td>
  </tr>
  <tr>
    <td>Bitwise operations (<code>&</code>, <code>|</code>, <code>!</code>, <code>&gt;&gt;</code>, <code>&lt;&lt;</code>)</td>
    <td>Supported</td>
  </tr>
  <tr>
    <td>Arch-dependent types (<code>usize</code>, <code>isize</code>)</td>
    <td>Supported</td>
  </tr>
  </tbody>
  <thead><tr><th colspan="2"><strong>Types and standard library functionality</strong></th></tr></thead>
  <tbody>
  <tr>
    <td>Integer types</td>
    <td>Supported</td>
  </tr>
  <tr>
    <td><code>bool</code></td>
    <td>Supported</td>
  </tr>
  <tr>
    <td>Strings</td>
    <td>Supported (<a href="https://verus-lang.github.io/verus/verusdoc/vstd/string/index.html">vstd equivalent</a>)</td>
  </tr>
  <tr>
    <td>Vec</td>
    <td>Supported (<a href="https://verus-lang.github.io/verus/verusdoc/vstd/vec/struct.Vec.html">vstd equivalent</a>)</td>
  </tr>
  <tr>
    <td>Option / Result</td>
    <td>Supported (<a href="https://verus-lang.github.io/verus/verusdoc/vstd/option/enum.Option.html">vstd equivalent</a>)</td>
  </tr>
  <tr>
    <td>Floating point</td>
    <td>Not supported</td>
  </tr>
  <tr>
    <td>Slices</td>
    <td>Supported</td>
  </tr>
  <tr>
    <td>Arrays</td>
    <td>Supported</td>
  </tr>
  <tr>
    <td>Pointers</td>
    <td>Partially supported</td>
  </tr>
  <tr>
    <td>References (<code>&</code>)</td>
    <td>Supported</td>
  </tr>
  <tr>
    <td>Mutable references (<code>&mut</code>)</td>
    <td>Partially supported</td>
  </tr>
  <tr>
    <td>Never type</td>
    <td>Not supported</td>
  </tr>
  <tr>
    <td>Function pointer types</td>
    <td>Not supported</td>
  </tr>
  <tr>
    <td>Closure types</td>
    <td>Supported</td>
  </tr>
  <tr>
    <td>Trait objects (dyn)</td>
    <td>Not supported</td>
  </tr>
  <tr>
    <td>impl types</td>
    <td>Partially supported</td>
  </tr>
  <tr>
    <td>Cell, RefCell</td>
    <td>Not supported (see <a href="https://verus-lang.github.io/verus/verusdoc/vstd/cell/index.html">vstd alternatives</a>)</td>
  </tr>
  <tr>
    <td>Iterators</td>
    <td>Not supported</td>
  </tr>
  <tr>
    <td><code>HashMap</code></td>
    <td>Not supported</td>
  </tr>
  <tr>
    <td>Smart pointers (<code>Box</code>, <code>Rc</code>, <code>Arc</code>)</td>
    <td>Supported</td>
  </tr>
  <tr>
    <td><code>Pin</code></td>
    <td>Not supported</td>
  </tr>
  <tr>
    <td>Hardware intrinsics</td>
    <td>Not supported</td>
  </tr>
  <tr>
    <td>Printing, I/O</td>
    <td>Not supported</td>
  </tr>
  <tr>
    <td>Panic-unwinding</td>
    <td>Not supported</td>
  </tr>
  </tbody>
  <thead><tr><th colspan="2"><strong>Traits</strong></th></tr></thead>
  <tbody>
  <tr>
    <td>User-defined traits</td>
    <td>Supported</td>
  </tr>
  <tr>
    <td>Traits with type arguments</td>
    <td>Partially supported</td>
  </tr>
  <tr>
    <td>Associated types</td>
    <td>Not supported</td>
  </tr>
  <tr>
    <td><code>Clone</code></td>
    <td>Supported</td>
  </tr>
  <tr>
    <td>Marker traits (<code>Copy</code>, <code>Send</code>, <code>Sync</code>)</td>
    <td>Supported</td>
  </tr>
  <tr>
    <td>Standard traits (<code>Hash</code>, <code>Debug</code>)</td>
    <td>Not supported</td>
  </tr>
  <tr>
    <td>User-defined destructors (<code>Drop</code>)</td>
    <td>Not supported</td>
  </tr>
  <tr>
    <td><code>Sized</code> (<code>size_of</code>, <code>align_of</code>)</td>
    <td>Supported</td>
  </tr>
  <tr>
    <td><code>Deref</code>, <code>DerefMut</code></td>
    <td>Not supported</td>
  </tr>
  </tbody>
  <thead><tr><th colspan="2"><strong>Multi-threading</strong></th></tr></thead>
  <tbody>
  <tr>
    <td><code>Mutex</code>, <code>RwLock</code> (from standard library)</td>
    <td>Not supported </td>
  </tr>
  <tr>
    <td>Verified lock implementations</td>
    <td>Supported </td>
  </tr>
  <tr>
    <td>Atomics</td>
    <td>Supported (<a href="https://verus-lang.github.io/verus/verusdoc/vstd/atomic_ghost/index.html">vstd equivalent</a>)</td>
  </tr>
  <tr>
    <td>spawn and join</td>
    <td><a href="https://verus-lang.github.io/verus/verusdoc/vstd/thread/index.html">Supported</a></td>
  </tr>
  <tr>
    <td>Interior mutability</td>
    <td><a href="interior_mutability.html">Supported</a></td>
  </tr>
  </tbody>
  <thead><tr><th colspan="2"><strong>Unsafe</strong></th></tr></thead>
  <tbody>
  <tr>
    <td>Raw pointers</td>
    <td><a href="https://verus-lang.github.io/verus/verusdoc/vstd/ptr/struct.PPtr.html">Supported (only pointers from global allocator)</a></td>
  </tr>
  <tr>
    <td>Transmute</td>
    <td>Not supported</td>
  </tr>
  <tr>
    <td>Unions</td>
    <td>Not supported</td>
  </tr>
  <tr>
    <td><cod>UnsafeCell</code></td>
    <td>Supported (<a href="https://verus-lang.github.io/verus/verusdoc/vstd/cell/struct.PCell.html">vstd equivalent</a>)</td>
  </tr>
  </tbody>
  <thead><tr><th colspan="2"><strong>Crates and code organization</strong></th></tr></thead>
  <tr>
    <td>Multi-crate projects</td>
    <td>Partially supported</td>
  </tr>
  <tr>
    <td>Verified crate + unverified crates</td>
    <td>Partially supported</td>
  </tr>
  <tr>
    <td>Modules</td>
    <td>Supported</td>
  </tr>
  <tr>
    <td>rustdoc</td>
    <td>Supported</td>
  </tr>
</table></div>

================
File: ./guide/src/pervasive.md
================

# Basic libraries

This chapter introduces some of Verus's built-in libraries for sequences, sets, maps, and vectors.
The libraries are currently located in a collection of modules
in the [vstd](https://github.com/verus-lang/verus/tree/main/source/vstd/) directory:
- [vstd::seq](https://github.com/verus-lang/verus/tree/main/source/vstd/seq.rs)
- [vstd::seq_lib](https://github.com/verus-lang/verus/tree/main/source/vstd/seq_lib.rs)
- [vstd::set](https://github.com/verus-lang/verus/tree/main/source/vstd/set.rs)
- [vstd::set_lib](https://github.com/verus-lang/verus/tree/main/source/vstd/set_lib.rs)
- [vstd::map](https://github.com/verus-lang/verus/tree/main/source/vstd/map.rs)
- [vstd::vec](https://github.com/verus-lang/verus/tree/main/source/vstd/vec.rs)

For more information,
see the [API documentation](https://verus-lang.github.io/verus/verusdoc/vstd/index.html).

As an example, the [following code](https://github.com/verus-lang/verus/tree/main/source/rust_verify/example/guide/vstd_example.rs)
uses the `vstd::seq` module:

```rust
{{#include ../../../rust_verify/example/guide/vstd_example.rs}}
```

For convenience, the `vstd::prelude` module includes `builtin_macros`, `builtin`,
as well as types from `seq`, `set`, `map`, `option`, `result`, and `string`:

```rust
use vstd::prelude::*;

verus! {

fn main() {
    proof {
        let s: Seq<int> = seq![0, 10, 20, 30, 40];
        assert(s.len() == 5);
        assert(s[2] == 20);
        assert(s[3] == 30);
    }
}

} // verus!
```

# Some syntactic sugar: spec_index and view

In ghost code, Verus supports two pieces of syntactic sugar that are used by the libraries:
- `[...]` is an abbreviation for `.spec_index(...)`.
  This is used, for example, to get an element from a sequence: `s[3]` means `s.spec_index(3)`.
- `@` is an abbreviation for `.view()`.
  This is commonly used to get a `spec` value
  that represents the abstract contents of a concrete `exec` object.
  For example, for an `exec` vector `v` of type `Vec<T>`, the value `v@` is a `spec` sequence
  of type `Seq<T>` containing the elements of `v`.

================
File: ./guide/src/smt_failures.md
================

# SMT solving and automation

Sometimes an assertion will fail even though it's true. At a high level, Verus
works by generating formulas called "verification conditions" from a program's
assertions and specifications (`requires` and `ensures` clauses); if these
verification conditions are always true, then all of the assertions and
specifications hold. The verification conditions are checked by an SMT solver
(Z3), and therefore Verus is limited by Z3's ability to prove generated
verification conditions.

This section walks through the reasons why a proof might fail.

The first reason why a proof might fail is that the statement is wrong! If
there is a bug in a specification or assertion, then we hope that Z3 will not
manage to prove it. We won't talk too much about this case in this document,
but it's important to keep this in mind when debugging proofs.

The core reason for verification failures is that proving the verification
conditions from Verus is an _undecidable_ task: there is no algorithm that can
prove general formulas true. In practice Z3 is good at proving even complex
formulas are true, but there are some features that lead to inconclusive
verification results.

**Quantifiers:** Proving theorems with quantifiers (`exists` and `forall`) is
in general undecidable. For Verus, we rely on Z3's pattern-based instantiation
of quantifiers ("triggers") to use and prove formulas with quantifiers. See the
section on [forall and triggers](forall.md) for more details.

**Opaque and closed functions:** Verification conditions by default hide the
bodies of opaque and closed functions; revealing those bodies might make
verification succeed, but Verus intentionally leaves this to the user to
improve performance and allow hiding where desired.

**Inductive invariants:** Reasoning about recursion (loops, recursive lemmas)
requires an inductive invariant, which Z3 cannot in general come up with.

**Extensional equality assertions:** If a theorem requires extensional equality
(eg, between sequences, maps, or spec functions), this typically requires
additional assertions in the proof. The key challenge is that there are many
possible sequence expressions (for example) in a program that Z3 could attempt
to prove are equal. For performance reasons Z3 cannot attempt to prove all
pairs of expressions equal, both because there are too many (including the
infinitely many _not_ in the program at all) and because each proof involves
quantifiers and is reasonably expensive. The result is that a proof may start
working if you add an equality assertion: the assertion explicitly asks Z3 to
prove and use an equality.
See [extensional equality](extensional_equality.md) for how to use the
extensional equality operators `=~=` and `=~~=`.

**Incomplete axioms:** The standard library includes datatypes like `Map` and
`Seq` that are implemented using axioms that describe their expected
properties. These axioms might be incomplete; there may be a property that you
intuitively expect a map or sequence to satisfy but which isn't implied by the
axioms, or which is implied but requires a proof by induction.
If you think this is the case, please open an issue or a pull request adding
the missing axiom.

**Slow proofs:** Z3 may be able to find a proof but it would simply take too
long. We limit how long Z3 runs (using its resource limit or "rlimit" feature
so that this limit is independent of how fast the computer is), and consider it
a failure if Z3 runs into this limit. The philosophy of Verus is that it's
better to improve solver performance than rely on a slow proof. [Improving SMT
performance]() talks more about what you can do to diagnose and fix poor
verification performance.

================
File: ./guide/src/multitriggers.md
================

# Multiple variables, multiple triggers, matching loops

Suppose we have a `forall` expression with more than one variable, `i` and `j`:

```rust
{{#include ../../../rust_verify/example/guide/quants.rs:test_distinct1}}
```

The `forall` expression shown above says that every element of `s` is distinct.
(Note: we could have written
`0 <= i < s.len() && 0 <= j < s.len() && i != j`
instead of
`0 <= i < j < s.len()`,
but the latter is more concise and is just as general:
given any two distinct integers, we can let `i` be the smaller one
and `j` be the larger one so that `i < j`.)

In the example above, the trigger `is_distinct(s[i], s[j])`
contains both the variables `i` and `j`,
and the expression `is_distinct(s[2], s[4])` matches the trigger with `i = 2, j = 4`:

```
0 <= 2 < 4 < s.len() ==> is_distinct(s[2], s[4])
```

Instead of using a function call `is_distinct(s[i], s[j])`,
we could just write `s[i] != s[j]` directly.
However, in this case, we cannot use the expression `s[i] != s[j]` as a trigger,
because, as discussed in the [previous section](./forall.md),
triggers cannot contain equalities and disequalities like `!=`.
However, a trigger does not need to be just a single expression.
It can be split across multiple expressions,
as in the following code, which defines the trigger to be the pair of expressions
`s[i]`, `s[j]`:

```rust
{{#include ../../../rust_verify/example/guide/quants.rs:test_distinct2}}
```

Verus also supports an alternate, equivalent syntax `#![trigger ...]`,
where the `#![trigger ...]` immediately follows the `forall|...|`,
in case we prefer to write the pair `s[i]`, `s[j]` directly:

```rust
{{#include ../../../rust_verify/example/guide/quants.rs:test_distinct3}}
```

When the trigger is the pair `s[i]`, `s[j]`,
there are four matches: `i = 2, j = 2` and `i = 2, j = 4` and `i = 4, j = 2` and `i = 4, j = 4`:

```
0 <= 2 < 2 < s.len() ==> s[2] != s[2]
0 <= 2 < 4 < s.len() ==> s[2] != s[4]
0 <= 4 < 2 < s.len() ==> s[4] != s[2]
0 <= 4 < 4 < s.len() ==> s[4] != s[4]
```

The `i = 2, j = 4` instantiation proves s[2] != s[4],
which is equivalent to s[4] != s[2].
The other instantiations are dead ends, since `2 < 2`, `4 < 2`, and `4 < 4` all fail.

A trigger must mention each of the quantifier variables `i` and `j` at least once.
Otherwise, Verus will complain:

```rust
{{#include ../../../rust_verify/example/guide/quants.rs:test_distinct_fail1}}
```
```
error: trigger does not cover variable i
    |
    | / ...   forall|i: int, j: int|
    | | ...       0 <= i < j < s.len() ==> s[i] != #[trigger] s[j], // error: trigger fails to ment...
    | |__________________________________________________________^
```

In order to match a trigger with multiple expressions,
the SMT solver has to find matches for *all* the expressions in the trigger.
Therefore,
you can always make a trigger more restrictive by adding more expressions to the trigger.
For example, we could gratuitously add a third expression `is_even(i)`
to the trigger, which would cause the match to fail,
since no expression matches `is_even(i)`:

```rust
{{#include ../../../rust_verify/example/guide/quants.rs:test_distinct_fail2}}
```

To make this example succeed, we'd have to mention `is_even(2)` explicitly:
```rust
    assert(is_even(2));
    assert(s[4] != s[2]); // succeeds; we've matched s[2], s[4], is_even(2)
```

# Multiple triggers

In all the examples so far,
each quantifier contained exactly one trigger
(although the trigger sometimes contained more than one expression).
It's also possible, although rarer,
to specify multiple triggers for a quantifier.
The SMT solver will instantiate the quantifier if *any* of the triggers match.
Thus, adding more triggers leads to *more* quantifier instantiations.
(This stands in contrast to adding *expressions* to a trigger:
adding more expressions to a trigger makes a trigger more restrictive
and leads to *fewer* quantifier instantiations.)

The following example specifies both `#![trigger a[i], b[j]]` and `#![trigger a[i], c[j]]`
as triggers, since neither is obviously better than the other:

```rust
{{#include ../../../rust_verify/example/guide/quants.rs:test_multitriggers}}
```

(Note: to specify multiple triggers, you must use the `#![trigger ...]` syntax
rather than the `#[trigger]` syntax.)

If the quantifier had only mentioned the single trigger `#![trigger a[i], b[j]]`,
then the assertion above would have failed, because `a[2] != c[4]` doesn't mention `b`.
A single trigger `#![trigger a[i], b[j], c[j]]` would be even more restrictive,
requiring both `b` and `c` to appear, so the assertion would still fail.

In the example above, you can omit the explicit triggers and
Verus will automatically infer exactly the two triggers
`#![trigger a[i], b[j]]` and `#![trigger a[i], c[j]]`.
However, in most cases, Verus deliberately avoids inferring more than one trigger,
because multiple triggers lead to more quantifier instantiations,
which potentially slows down the SMT solver.
One trigger is usually enough.

As an example of where one trigger is safer than multiple triggers,
consider an assertion that says that updating element `j`
of sequence `s` leaves element `i` unaffected:

```rust
{{#include ../../../rust_verify/example/guide/quants.rs:seq_update_different}}
```

There are actually two possible triggers for this:

```
#![trigger s.update(j, a)[i]]
#![trigger s.update(j, a), s[i]]
```

However, Verus selects only the first one and rejects the second,
in order to avoid too many quantifier instantiations:

```
note: automatically chose triggers for this expression:
    |
    |       assert(forall|i: int, j: int|
    |  ____________^
    | |         0 <= i < s.len() && 0 <= j < s.len() && i != j ==> s.update(j, a)[i] === s[i]
    | |_____________________________________________________________________________________^

note:   trigger 1 of 1:
   --> .\rust_verify\example\guide\quants.rs:243:60
    |
    |         0 <= i < s.len() && 0 <= j < s.len() && i != j ==> s.update(j, a)[i] === s[i]
    |                                                            ^^^^^^^^^^^^^^^^^
```

(Note: you can use the `--triggers` command-line option to print the message above.)

# Matching loops: what they are and to avoid them

Suppose we want to specify that a sequence is sorted.
We can write this in a similar way to the earlier `forall` expression
about sequence distinctness,
writing `s[i] <= s[j]` in place of `s[i] != s[j]`:

```rust
{{#include ../../../rust_verify/example/guide/quants.rs:test_sorted_good}}
```

In Verus, this is the best way to express sortedness,
because the trigger `s[i], s[j]` works very well.
However, there is an alternate approach.
Instead of quantifying over both `i` and `j`,
we could try to quantify over just a single variable `i`,
and then compare `s[i]` to `s[i + 1]`:

```rust
{{#include ../../../rust_verify/example/guide/quants.rs:test_sorted_bad1}}
```

However, Verus complains that it couldn't find any good triggers:

```
error: Could not automatically infer triggers for this quantifer.  Use #[trigger] annotations to manually mark trigger terms instead.
    |
    | /         forall|i: int|
    | |             0 <= i < s.len() - 1 ==> s[i] <= s[i + 1],
    | |_____________________________________________________^
```

Verus considers the expressions `0 <= i`, `i < s.len() - 1`, `s[i]`, and `s[i + 1]`
as candidates for a trigger.
However, all of these except `s[i]` contain integer arithmetic, which is not allowed in triggers.
The remaining candidate, `s[i]`, looks reasonable at first glance.
Verus nevertheless rejects it, though, because it potentially leads to an infinite *matching loop*.
Triggers are the way to program the SMT solver's quantifier instantiations,
and if we're not careful, we can program infinite loops.
Let's look at how this can happen.
Suppose that we insist on using `s[i]` as a trigger:

```
forall|i: int|
    0 <= i < s.len() - 1 ==> #[trigger] s[i] <= s[i + 1],
```

(TODO: Verus should print a warning about a potential matching loop here.)

This would, in fact, succeed in verifying the assertion `s[2] <= s[4]`,
but not necessarily in a good way.
The SMT solver would match on `i = 2` and `i = 4`.
For `i = 2`, we'd get:

```
0 <= 2 < s.len() - 1 ==> s[2] <= s[3]
```

This creates a new expression `s[3]`, which the SMT can then match on with `i = 3`:

```
0 <= 3 < s.len() - 1 ==> s[3] <= s[4]
```

This tells us `s[2] <= s[3]` and `s[3] <= s[4]`,
which is sufficient to prove `s[2] <= s[4]`.
The problem is that the instantiations don't necessarily stop here.
Given `s[4]`, we can match with `i = 4`, which creates `s[5]`,
which leads to matching with `i = 5`, and so on:

```
0 <= 4 < s.len() - 1 ==> s[4] <= s[5]
0 <= 5 < s.len() - 1 ==> s[5] <= s[6]
0 <= 6 < s.len() - 1 ==> s[6] <= s[7]
...
```

In principle, the SMT solver could loop forever with `i = 6`, `i = 7`, and so on.
In practice, the SMT solver imposes a cutoff on quantifier instantiations which often
(but not always) halts the infinite loops.
But even if the SMT solver halts the loop,
this is still an inefficient process,
and matching loops should be avoided.
(For an example of a matching loop that causes the SMT solver to use an infinite
amount of time and memory, see [this section](./profiling.md).)

================
File: ./guide/src/modes.md
================

# Specification code, proof code, executable code

Verus classifies code into three *modes*: `spec`, `proof`, and `exec`,
where:
- `spec` code describes properties about programs
- `proof` code proves that programs satisfy properties
- `exec` code is ordinary Rust code that can be compiled and run

Both `spec` code and `proof` code are forms of ghost code,
so we can organize the three modes in a hierarchy:
- code
    - ghost code
        - `spec` code
        - `proof` code
    - `exec` code

Every function in Verus is either a `spec` function, a `proof` function, or an `exec` function:

```rust
{{#include ../../../rust_verify/example/guide/modes.rs:fun_modes}}
```

`exec` is the default function annotation, so it is usually omitted:

```rust
{{#include ../../../rust_verify/example/guide/modes.rs:fun_modes2}}
```

The rest of this chapter will discuss these three modes in more detail.
As you read, you can keep in mind the following relationships between
the three modes:

|                        | spec code      | proof code       | exec code        |
|------------------------|----------------|------------------|------------------|
| can contain `spec` code, call `spec` functions   | yes            | yes              | yes              |
| can contain `proof` code, call `proof` functions | no             | yes              | yes              |
| can contain `exec` code, call `exec` functions   | no             | no               | yes              |

================
File: ./guide/src/proof_functions.md
================

# proof functions

Consider the `pub closed spec` `min` function from the previous section.
This defined an abstract `min` function without revealing the internal
definition of `min` to other modules.
However, an abstract function definition is useless unless we can say something about the function.
For this, we can use a `proof` function.
In general, `proof` functions will reveal or prove properties about specifications.
In this example, we'll define a `proof` function named `lemma_min` that
reveals properties about `min` without revealing the exact definition of `min`.
Specifically, `lemma_min` reveals that `min(x, y)` equals either `x` or `y` and
is no larger than `x` and `y`:

```rust
{{#include ../../../rust_verify/example/guide/modes.rs:spec_fun_proof}}
```

Like `exec` functions, `proof` functions may have `requires` and `ensures` clauses.
Unlike `exec` functions, `proof` functions are ghost and are not compiled to executable code.
In the example above, the `lemma_min(10, 20)` function is used to help the function `test` in module `M2`
prove an assertion about `min(10, 20)`, even when `M2` cannot see the internal definition of `min`
because `min` is `closed`.
On the other hand, the assertion about `min(100, 200)` still fails
unless `test` also calls `lemma_min(100, 200)`.

# proof blocks

Ultimately, the purpose of `spec` functions and `proof` functions is to help prove
properties about executable code in `exec` functions.
In fact, `exec` functions can contain pieces of `proof` code in *proof blocks*,
written with `proof { ... }`.
Just like a `proof` function contains `proof` code,
a `proof` block in an `exec` function contains `proof` code
and can use all of the ghost code features that `proof` functions can use,
such as the `int` and `nat` types.

Consider an [earlier example](integers.md#integer-constants) that introduced
variables inside an assertion:

```rust
{{#include ../../../rust_verify/example/guide/integers.rs:test_consts_infer}}
```

We can write this in a more natural style using a proof block:

```rust
{{#include ../../../rust_verify/example/guide/modes.rs:spec_fun_proof_block1}}
```

Here, the `proof` code inside the `proof` block can create local variables
of type `int` and `nat`,
which can then be used in a subsequent assertion.
The entire `proof` block is ghost code, so all of it, including its local variables,
will be erased before compilation to executable code.

Proof blocks can call `proof` functions.
In fact, any calls from an `exec` function to a `proof` function
must appear inside `proof` code such as a `proof` block,
rather than being called directly from the `exec` function's `exec` code.
This helps clarify which code is executable and which code is ghost,
both for the compiler and for programmers reading the code.
In the exec function `test` shown below,
a `proof` block is used to call `lemma_min`,
allowing subsequent assertions about `min` to succeed.

```rust
{{#include ../../../rust_verify/example/guide/modes.rs:spec_fun_proof_block2}}
```

# assert-by

Notice that in the previous example,
the information that `test` gains about `min`
is not confined to the `proof` block,
but instead propagates past the end of the `proof` block
to help prove the subsequent assertions.
This is often useful,
particularly when the `proof` block helps
prove preconditions to subsequent calls to `exec` functions,
which must appear outside the `proof` block.

However, sometimes we only need to prove information for a specific purpose,
and it clarifies the structure of the code if we limit the scope
of the information gained.
For this reason,
Verus supports `assert(...) by { ... }` expressions,
which allows `proof` code inside the `by { ... }` block whose sole purpose
is to prove the asserted expression in the `assert(...)`.
Any additional information gained in the `proof` code is limited to the scope of the block
and does not propagate outside the `assert(...) by { ... }` expression.

In the example below,
the `proof` code in the block calls both `lemma_min(10, 20)` and `lemma_min(100, 200)`.
The first call is used to prove `min(10, 20) == 10` in the `assert(...) by { ... }` expression.
Once this is proven, the subsequent assertion `assert(min(10, 20) == 10);` succeeds.
However, the assertion `assert(min(100, 200) == 100);` fails,
because the information gained by the `lemma_min(100, 200)` call
does not propagate outside the block that contains the call.

```rust
{{#include ../../../rust_verify/example/guide/modes.rs:assert_by}}
```

================
File: ./guide/src/develop_proofs.md
================

# Using assert and assume to develop proofs

The previous section started with an outline of proof:

```rust
{{#include ../../../rust_verify/example/guide/lib_examples.rs:lemma_len_intersect_fail}}
```

and then filled in the crucial missing steps to complete the proof.
It didn't say, though,
how you might go about discovering which crucial steps are missing.
In practice, it takes some experimentation to fill in this kind of proof.

This section will walk through a typical process of developing a proof,
using the proof outline above as a starting point.
The process will consist of a series of queries to Verus and the SMT solver,
using `assert` and `assume` to ask questions,
and using the answers to narrow in on the cause of the verification failure.

If we run the proof above, Verus reports an error:

```
error: postcondition not satisfied
   |
   |           s1.intersect(s2).len() <= s1.len(),
   |           ---------------------------------- failed this postcondition
```

This raises a couple questions:
- Why is this postcondition failing?
- If this postcondition succeeded, would the verification of the whole function succeed?

Let's check the second question first.  We can simply assume the postcondition and see what happens:

```rust
pub proof fn lemma_len_intersect<A>(s1: Set<A>, s2: Set<A>)
    ...
{
    if s1.is_empty() {
    } else {
        let a = s1.choose();
        lemma_len_intersect::<A>(s1.remove(a), s2);
    }
    assume(s1.intersect(s2).len() <= s1.len());
}
```

In this case, verification succeeds:

```
verification results:: verified: 1 errors: 0
```

There are two paths through the code, one when `s1.is_empty()` and one when `!s1.empty()`.
The failure could lie along either path, or both.
Let's prepare to work on each branch of the `if`/`else` separately
by moving a separate copy the `assume` into each branch:

```rust
{
    if s1.is_empty() {
        assume(s1.intersect(s2).len() <= s1.len());
    } else {
        let a = s1.choose();
        lemma_len_intersect::<A>(s1.remove(a), s2);
        assume(s1.intersect(s2).len() <= s1.len());
    }
}
```
```
verification results:: verified: 1 errors: 0
```

Next, let's change the first `assume` to an `assert` to see if it succeeds in the `if` branch:

```rust
{
    if s1.is_empty() {
        assert(s1.intersect(s2).len() <= s1.len());
    } else {
        let a = s1.choose();
        lemma_len_intersect::<A>(s1.remove(a), s2);
        assume(s1.intersect(s2).len() <= s1.len());
    }
}
```

```
error: assertion failed
   |
   |         assert(s1.intersect(s2).len() <= s1.len());
   |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ assertion failed
```

In the `s1.is_empty()` case, we expect `s1.len() == 0` (an empty set has cardinality 0).
We can double-check this with a quick assertion:

```rust
{
    if s1.is_empty() {
        assert(s1.len() == 0);
        assume(s1.intersect(s2).len() <= s1.len());
    } else {
        ...
    }
}
```
```
verification results:: verified: 1 errors: 0
```

So what we need is `s1.intersect(s2).len() <= 0`.
If this were true, we'd satisfy the postcondition here:

```rust
{
    if s1.is_empty() {
        assume(s1.intersect(s2).len() <= 0);
        assert(s1.intersect(s2).len() <= s1.len());
    } else {
        ...
    }
}
```
```
verification results:: verified: 1 errors: 0
```

Since set cardinality is a `nat`, the only way it can be `<= 0` is if it's equal to `0`:

```rust
{
    if s1.is_empty() {
        assume(s1.intersect(s2).len() == 0);
        assert(s1.intersect(s2).len() <= s1.len());
    } else {
        ...
    }
}
```
```
verification results:: verified: 1 errors: 0
```

and the only way it can be `0` is if the set is the empty set:

```rust
{
    if s1.is_empty() {
        assume(s1.intersect(s2) === Set::empty());
        assert(s1.intersect(s2).len() == 0);
        assert(s1.intersect(s2).len() <= s1.len());
    } else {
        ...
    }
}
```
```
verification results:: verified: 1 errors: 0
```

If we change the `assume` to an `assert`, the assertion fails:

```rust
{
    if s1.is_empty() {
        assert(s1.intersect(s2) === Set::empty());
        assert(s1.intersect(s2).len() == 0);
        assert(s1.intersect(s2).len() <= s1.len());
    } else {
        ...
    }
}
```
```
error: assertion failed
   |
   |         assert(s1.intersect(s2) === Set::empty());
   |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ assertion failed
```

So we've narrowed in on the problem:
the intersection of the empty set `s1` with another set should equal the empty set,
but the verifier doesn't see this automatically.
And from the previous section's discussion of equality, we can guess why:
the SMT solver doesn't always automatically prove equalities between collections,
but instead requires us to assert the equality using extensionality.
So we can add the extensionality assertion:

```rust
{
    if s1.is_empty() {
        assert(s1.intersect(s2) =~= Set::empty());
        assert(s1.intersect(s2) === Set::empty());
        assert(s1.intersect(s2).len() == 0);
        assert(s1.intersect(s2).len() <= s1.len());
    } else {
        ...
    }
}
```
```
verification results:: verified: 1 errors: 0
```

It works!  We've now verified the `s1.is_empty()` case,
and we can turn our attention to the `!s1.is_empty()` case:

```rust
{
    if s1.is_empty() {
        ...
    } else {
        let a = s1.choose();
        lemma_len_intersect::<A>(s1.remove(a), s2);
        assume(s1.intersect(s2).len() <= s1.len());
    }
}
```

Changing this `assume` to an `assert` fails,
so we've got work to do in this case as well:

```rust
{
    if s1.is_empty() {
        ...
    } else {
        let a = s1.choose();
        lemma_len_intersect::<A>(s1.remove(a), s2);
        assert(s1.intersect(s2).len() <= s1.len());
    }
}
```
```
error: assertion failed
   |
   |         assert(s1.intersect(s2).len() <= s1.len());
   |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ assertion failed
```

Fortunately, the recursive call `lemma_len_intersect::<A>(s1.remove(a), s2)` succeeded,
so we have some information from the postcondition of this call.
Let's write this out explictly so we can examine it more closely,
substituting `s1.remove(a)` for `s1`:

```rust
{
    if s1.is_empty() {
        ...
    } else {
        let a = s1.choose();
        lemma_len_intersect::<A>(s1.remove(a), s2);
        assert(s1.remove(a).intersect(s2).len() <= s1.remove(a).len());

        assume(s1.intersect(s2).len() <= s1.len());
    }
}
```
```
verification results:: verified: 1 errors: 0
```

Let's compare what we know above `s1.remove(a)` with what we're trying to prove about `s1`:

```rust
        assert(s1.remove(a).intersect(s2).len() <= s1.remove(a).len()); // WE KNOW THIS

        assume(s1          .intersect(s2).len() <= s1          .len()); // WE WANT THIS
```

Is there any way we can make what we know look more like what we want?
For example, how does `s1.remove(a).len()` relate to `s1.len()`?
The value `a` is an element of `s1`, so if we remove it from `s1`,
it should decrease the cardinality by 1:

```rust
{
    if s1.is_empty() {
        ...
    } else {
        let a = s1.choose();
        lemma_len_intersect::<A>(s1.remove(a), s2);
        assert(s1.remove(a).intersect(s2).len() <= s1.remove(a).len());
        assert(s1.remove(a).len() == s1.len() - 1);

        assume(s1.intersect(s2).len() <= s1.len());
    }
}
```
```
verification results:: verified: 1 errors: 0
```

So we can simplify a bit:

```rust
{
    if s1.is_empty() {
        ...
    } else {
        let a = s1.choose();
        lemma_len_intersect::<A>(s1.remove(a), s2);
        assert(s1.remove(a).intersect(s2).len() <= s1.remove(a).len());
        assert(s1.remove(a).intersect(s2).len() <= s1.len() - 1);
        assert(s1.remove(a).intersect(s2).len() + 1 <= s1.len());

        assume(s1.intersect(s2).len() <= s1.len());
    }
}
```
```
verification results:: verified: 1 errors: 0
```

Now the missing piece is the relation between `s1.remove(a).intersect(s2).len() + 1`
and `s1.intersect(s2).len()`:

```rust
{
    if s1.is_empty() {
        ...
    } else {
        let a = s1.choose();
        lemma_len_intersect::<A>(s1.remove(a), s2);
        assert(s1.remove(a).intersect(s2).len() <= s1.remove(a).len());
        assert(s1.remove(a).intersect(s2).len() <= s1.len() - 1);
        assert(s1.remove(a).intersect(s2).len() + 1 <= s1.len());

        assume(s1.intersect(s2).len() <= s1.remove(a).intersect(s2).len() + 1);

        assert(s1.intersect(s2).len() <= s1.len());
    }
}
```
```
verification results:: verified: 1 errors: 0
```

If we can prove the assumption `s1.intersect(s2).len() <= s1.remove(a).intersect(s2).len() + 1`,
we'll be done:

```rust
        assume(s1          .intersect(s2).len()
            <= s1.remove(a).intersect(s2).len() + 1);
```

Is there anyway we can make `s1.remove(a).intersect(s2)` look more like `s1.intersect(s2)`
so that it's easier to prove this inequality?
If we switched the order from `s1.remove(a).intersect(s2)` to `s1.intersect(s2).remove(a)`,
then the subexpression `s1.intersect(s2)` would match:

```rust
        assume(s1.intersect(s2)          .len()
            <= s1.intersect(s2).remove(a).len() + 1);
```

so let's try that:

```rust
{
    if s1.is_empty() {
        ...
    } else {
        let a = s1.choose();
        lemma_len_intersect::<A>(s1.remove(a), s2);
        assert(s1.remove(a).intersect(s2).len() <= s1.remove(a).len());
        assert(s1.remove(a).intersect(s2).len() <= s1.len() - 1);
        assert(s1.remove(a).intersect(s2).len() + 1 <= s1.len());

        assert(s1.intersect(s2).len() <= s1.intersect(s2).remove(a).len() + 1);
        assert(s1.intersect(s2).len() <= s1.remove(a).intersect(s2).len() + 1);

        assert(s1.intersect(s2).len() <= s1.len());
    }
}
```
```
error: assertion failed
   |
   |         assert(s1.intersect(s2).len() <= s1.remove(a).intersect(s2).len() + 1);
   |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ assertion failed
```

One of these assertion succeeds and the other fails.
The only difference between the successful assertion
and the failing assertion is the order of `intersect` and `remove`
in `s1.intersect(s2).remove(a)` and `s1.remove(a).intersect(s2)`,
so all we need to finish the proof is for `s1.intersect(s2).remove(a)`
to be equal to `s1.remove(a).intersect(s2)`:

```rust
{
    if s1.is_empty() {
        ...
    } else {
        let a = s1.choose();
        lemma_len_intersect::<A>(s1.remove(a), s2);
        assert(s1.remove(a).intersect(s2).len() <= s1.remove(a).len());
        assert(s1.remove(a).intersect(s2).len() <= s1.len() - 1);
        assert(s1.remove(a).intersect(s2).len() + 1 <= s1.len());

        assert(s1.intersect(s2).len() <= s1.intersect(s2).remove(a).len() + 1);
        assume(s1.intersect(s2).remove(a) === s1.remove(a).intersect(s2));
        assert(s1.intersect(s2).len() <= s1.remove(a).intersect(s2).len() + 1);

        assert(s1.intersect(s2).len() <= s1.len());
    }
}
```
```
verification results:: verified: 1 errors: 0
```

Again, we found ourselves needing to know the equality of two collections.
And again, the first thing to try is to assert extensional equality:

```rust
{
    if s1.is_empty() {
        ...
    } else {
        let a = s1.choose();
        lemma_len_intersect::<A>(s1.remove(a), s2);
        assert(s1.remove(a).intersect(s2).len() <= s1.remove(a).len());
        assert(s1.remove(a).intersect(s2).len() <= s1.len() - 1);
        assert(s1.remove(a).intersect(s2).len() + 1 <= s1.len());

        assert(s1.intersect(s2).len() <= s1.intersect(s2).remove(a).len() + 1);
        assert(s1.intersect(s2).remove(a) =~= s1.remove(a).intersect(s2));
        assert(s1.intersect(s2).remove(a) === s1.remove(a).intersect(s2));
        assert(s1.intersect(s2).len() <= s1.remove(a).intersect(s2).len() + 1);

        assert(s1.intersect(s2).len() <= s1.len());
    }
}
```
```
verification results:: verified: 1 errors: 0
```

It works!
Now we've eliminated all the `assume`s, so we've completed the verification:

```rust
pub proof fn lemma_len_intersect<A>(s1: Set<A>, s2: Set<A>)
    requires
        s1.finite(),
    ensures
        s1.intersect(s2).len() <= s1.len(),
    decreases
        s1.len(),
{
    if s1.is_empty() {
        assert(s1.intersect(s2) =~= Set::empty());
        assert(s1.intersect(s2) === Set::empty());
        assert(s1.intersect(s2).len() == 0);
        assert(s1.intersect(s2).len() <= s1.len());
    } else {
        let a = s1.choose();
        lemma_len_intersect::<A>(s1.remove(a), s2);
        assert(s1.remove(a).intersect(s2).len() <= s1.remove(a).len());
        assert(s1.remove(a).intersect(s2).len() <= s1.len() - 1);
        assert(s1.remove(a).intersect(s2).len() + 1 <= s1.len());

        assert(s1.intersect(s2).len() <= s1.intersect(s2).remove(a).len() + 1);
        assert(s1.intersect(s2).remove(a) =~= s1.remove(a).intersect(s2));
        assert(s1.intersect(s2).remove(a) === s1.remove(a).intersect(s2));
        assert(s1.intersect(s2).len() <= s1.remove(a).intersect(s2).len() + 1);

        assert(s1.intersect(s2).len() <= s1.len());
    }
}
```
```
verification results:: verified: 1 errors: 0
```

The code above contains a lot of unnecessary `assert`s, though,
so it's worth spending a few minutes cleaning the code up
for sake of anyone who has to maintain the code in the future.
We want to clear out unnecessary code so there's less code to maintain,
but keep enough information so
someone maintaining the code can still understand the code.
The right amount of information is a matter of taste,
but we can try to strike a reasonable balance between conciseness and informativeness:

```rust
{{#include ../../../rust_verify/example/guide/lib_examples.rs:lemma_len_intersect_commented}}
```

================
File: ./guide/src/reference-spec-index.md
================

# Spec index operator []

In spec expressions, the index operator is treated differently than
in exec expressions, where it corresponds to the [usual Rust index operator](https://doc.rust-lang.org/std/ops/trait.Index.html).

Specifically, in a spec expression, the expression `expr[i]` is a shorthand for
`expr.spec_index(i)`. This is a purely syntactic transformation, and there is no
particular trait.

For example:

 * [`spec_index` for a Seq](https://verus-lang.github.io/verus/verusdoc/vstd/seq/struct.Seq.html#method.spec_index)
 * [`spec_index` for a Map](https://verus-lang.github.io/verus/verusdoc/vstd/map/struct.Map.html#method.spec_index)
 * [`spec_index` for a slice](https://verus-lang.github.io/verus/verusdoc/vstd/slice/trait.SliceAdditionalSpecFns.html#tymethod.spec_index)

================
File: ./guide/src/integers.md
================

# Integer types

Rust supports various
[fixed-bit-width integer types](https://doc.rust-lang.org/book/ch03-02-data-types.html#integer-types):

- `u8`, `u16`, `u32`, `u64`, `u128`, `usize`
- `i8`, `i16`, `i32`, `i64`, `i128`, `isize`

To these, Verus adds two more integer types to represent arbitrarily large integers in specifications:

- int
- nat

The type `int` is the most fundamental type for reasoning about integer arithmetic in Verus.
It represents [all mathematical integers](https://en.wikipedia.org/wiki/Integer),
both positive and negative.
The SMT solver contains direct support for reasoning about values of type `int`.

Internally, Verus uses `int` to represent the other integer types,
adding mathematical constraints to limit the range of the integers.
For example, a value of the type `nat` of [natural numbers](https://en.wikipedia.org/wiki/Natural_number) 
is a mathematical integer constrained to be greater than or equal to `0`.
Rust's fixed-bit-width integer types have both a lower and upper bound;
a `u8` value is an integer constrained to be greater than or equal to `0` and less than 256:

```rust
{{#include ../../../rust_verify/example/guide/integers.rs:test_u8}}
```

(The bounds of `usize` and `isize` are platform dependent.
By default, Verus assumes that these types may be either 32 bits or 64 bits wide,
but this can be configured with the directive:

```rust
global size_of usize == 8;
```

(This would set the size of `usize` to 8 bytes, and add a static assertion to check it matches the target.)

# Using integer types in specifications

Since there are 14 different integer types (counting `int`, `nat`, `u8`...`usize`, and `i8`...`isize`),
it's not always obvious which type to use when writing a specification.
Our advice is to be as general as possible by default:
- Use `int` by default, since this is the most general type and is supported most efficiently by the SMT solver.
  - Example: the Verus [sequence library](https://github.com/verus-lang/verus/blob/main/source/vstd/seq.rs)
    uses `int` for most operations, such as indexing into a sequence.
  - Note: as discussed below, most arithmetic operations in specifications produce values of type `int`,
    so it is usually most convenient to write specifications in terms of `int`.
- Use `nat` for return values and datatype fields where the 0 lower bound is likely to provide useful information,
  such as lengths of sequences.
  - Example: the Verus [`Seq::len()` function](https://github.com/verus-lang/verus/blob/main/source/vstd/seq.rs)
    returns a `nat` to represent the length of a sequence.
  - The type `nat` is also handy for proving that recursive definitions terminate;
    you might to define a recursive `factorial` function to take a parameter of type `nat`,
    if you don't want to provide a definition of `factorial` for negative integers.
- Use fixed-width integer types for fixed-with values such as bytes.
  - Example: the bytes of a network packet can be represented with type `Seq<u8>`, an arbitrary-length sequence of 8-bit values.

Note that `int` and `nat` are usable only in ghost code;
they cannot be compiled to executable code.
For example, the following will not work:

```rust
fn main() {
    let i: int = 5; // FAILS: executable variable `i` cannot have type `int`, which is ghost-only
}
```

# Integer constants

As in ordinary Rust, integer constants in Verus can include their type as a suffix
(e.g. `7u8` or `7u32` or `7int`) to precisely specify the type of the constant:

```rust
{{#include ../../../rust_verify/example/guide/integers.rs:test_consts}}
```

Usually, but not always, Verus and Rust will be able to infer types for integer constants,
so that you can omit the suffixes unless the Rust type checker complains about not being able to infer the type:

```rust
{{#include ../../../rust_verify/example/guide/integers.rs:test_consts_infer}}
```

Note that the values `0`, `u`, `i`, `n`, and `4` in the expression `0 <= u < i < n < 4`
are allowed to all have different types ---
you can use `<=`, `<`, `>=`, `>`, `==`, and `!=` to compare values of different integer types inside ghost code
(e.g. comparing a `u8` to an `int` in `u < i`).

Constants with the suffix `int` and `nat` can be arbitrarily large:

```rust
{{#include ../../../rust_verify/example/guide/integers.rs:test_consts_large}}
```

# Integer coercions using "as"

As in ordinary rust, the `as` operator coerces one integer type to another.
In ghost code, you can use `as int` or `as nat` to coerce to `int` or `nat`:

```rust
{{#include ../../../rust_verify/example/guide/integers.rs:test_coerce}}
```

You can use `as` to coerce a value `v` to a type `t` even if `v` is too small or too large to fit in `t`.
However, if the value `v` is outside the bounds of type t,
then the expression `v as t` will produce some arbitrary value of type `t`:

```rust
{{#include ../../../rust_verify/example/guide/integers.rs:test_coerce_fail}}
```

This produces an error for the assertion, along with a hint that the value in the `as` coercion might have been out of range:

```
error: assertion failed
   |
   |     assert(u == v); // FAILS, because u has type u8 and therefore cannot be equal to 257
   |            ^^^^^^ assertion failed

note: recommendation not met: value may be out of range of the target type (use `#[verifier::truncate]` on the cast to silence this warning)
   |
   |     let u: u8 = v as u8;
   |                 ^
```

# Integer arithmetic

Integer arithmetic behaves differently in ghost code than in executable code.
In particular, in ghost code, the `+`, `-`, and `*` operations generate results of type `int`,
so that the arithmetic operations cannot underflow or overflow.
For example, in the following code, the executable operation `let sum1: u8 = x + y`
might overflow, producing a value greater than `255` that does not fit inside the result value of type `u8`:

```rust
{{#include ../../../rust_verify/example/guide/integers.rs:test_sum}}
```

For overflows in executable code, Verus reports an error:

```
error: possible arithmetic underflow/overflow
   |
   |     let sum1: u8 = x + y; // FAILS: possible overflow
   |                    ^^^^^
```

By contrast, the ghost operation `let sum2: int = x + y` will produce a value of type `int` in the range `0`...`510`,
even though the inputs `x` and `y` have type `u8`:

```rust
{{#include ../../../rust_verify/example/guide/integers.rs:test_sum2}}
```

Since `+` does not overflow in ghost code, we can easily write specifications *about* overflow.
For example, to make sure that the executable `x + y` doesn't overflow,
we simply write `requires x + y < 256`, relying on the fact that `x + y` is widened to type `int`
in the `requires` clause:

```rust
{{#include ../../../rust_verify/example/guide/integers.rs:test_sum3}}
```

Also note that the inputs need not have the same type;
you can add, subtract, or multiply one integer type with another:

```rust
{{#include ../../../rust_verify/example/guide/integers.rs:test_sum_mixed}}
```

If you don't want to widen the results of addition, subtraction, or multiplication to type `int`,
Verus also includes functions `add(a, b)`, `sub(a, b)`, and `mul(a, b)` that return the input type
(both `a` and `b` must have the same type), returning an arbitrary value of that type in case of overflow or underflow:

```rust
{{#include ../../../rust_verify/example/guide/integers.rs:test_sum_add_sub}}
```

The following table summarizes the types of integer operations in ghost code:

| operation | left-hand side type | right-hand side type | result type | notes                |
|-----------|---------------------|----------------------|-------------|----------------------|
| <=        | t1                  | t2                   | bool        |                      |
| <         | t1                  | t2                   | bool        |                      |
| >=        | t1                  | t2                   | bool        |                      |
| >         | t1                  | t2                   | bool        |                      |
| ==        | t1                  | t2                   | bool        |                      |
| !=        | t1                  | t2                   | bool        |                      |
| +         | t1                  | t2                   | int         | except for nat + nat |
| -         | t1                  | t2                   | int         |                      |
| *         | t1                  | t2                   | int         | except for nat * nat |
| +         | nat                 | nat                  | nat         |                      |
| *         | nat                 | nat                  | nat         |                      |
| /         | t                   | t                    | int         | for i8...isize, int  |
| /         | t                   | t                    | t           | for u8...usize, nat  |
| %         | t                   | t                    | t           |                      |
| add(_, _) | t                   | t                    | t           |                      |
| sub(_, _) | t                   | t                    | t           |                      |
| mul(_, _) | t                   | t                    | t           |                      |
| bitwise op| t                   | t                    | t           |                      |

Note that for convenience, addition and multiplication on two `nat` values return `nat`, not `int`,
so that for `n` of type `nat`, you can write `n + 1` to get a `nat` without having to write
`add(n, 1)` or `(n + 1) as nat`.

Finally, note that in ghost code, `/` and `%` compute
[Euclidean division and remainder](https://en.wikipedia.org/wiki/Euclidean_division),
rather than Rust's truncating division and remainder,
when operating on negative left-hand sides or negative right-hand sides.

================
File: ./guide/src/extensional_equality.md
================

# Equality via extensionality

In the [specification libraries](spec_lib.md) section,
we introduced the extensional equality operator `=~=`
to check equivalence for `Seq`, `Set`, and `Map`.

Suppose that a `struct` or `enum` datatype has a field containing `Seq`, `Set`, and `Map`,
and suppose that we'd like to prove that two values of the datatype are equal.
We could do this by using `=~=` on each field individually:

```rust
{{#include ../../../rust_verify/example/guide/ext_equal.rs:ext_eq_struct_fields}}
```

However, it's rather painful to use `=~=` on each field every time to check for equivalence.
To help with this, Verus supports the `#[verifier::ext_equal]` attribute
to mark datatypes that need extensionality on `Seq`, `Set`, `Map`, `Multiset`, `spec_fn`
fields or fields of other `#[verifier::ext_equal]` datatypes.  For example:

```rust
{{#include ../../../rust_verify/example/guide/ext_equal.rs:ext_eq_struct}}
```

(Note: adding `#[verifier::ext_equal]` does not change the meaning of `==`;
it just makes it more convenient to use `=~=` to prove `==` on datatypes.)

Collection datatypes like sequences and sets can contain other collection datatypes as elements
(for example, a sequence of sequences, or set of sequences).
The `=~=` operator only applies extensionality to the top-level collection,
not to the nested elements of the collection.
To also apply extensionality to the elements,
Verus provides a "deep" extensional equality operator `=~~=`
that handles arbitrary nesting of collections, `spec_fn`, and datatypes.
For example:

```rust
{{#include ../../../rust_verify/example/guide/ext_equal.rs:ext_eq_nested}}
```

The same applies to `spec_fn`, as in:

```rust
{{#include ../../../rust_verify/example/guide/ext_equal.rs:ext_eq_fnspec}}
```

================
File: ./guide/src/reference-assert-forall-by.md
================

# assert forall ... by

The `assert forall ... by` statement is used to write a proof of a `forall` expression
while introducing the quantified variables into the context.

```rust
assert forall |idents| P by {
    // ... proof here
}
// ... remainder
```

Much like an ordinary [`assert ... by`](./reference-assert-by.md) statement, the proof
inside the body does not enter the context for the remainder of the proof.
Only the `forall |idents| P` expression enters the context.
Furthermore, within the proof body, the variables in the `idents` may be 

Note that the **parentheses _must_ be left off**, in contrast to other kinds of `assert` statements.

For convenience, you can use `implies` to introduce a hypothesis automatically into
the proof block:

```rust
assert forall |idents| H implies P by {
    // ... proof here
}
// ... remainder
```

This will make `H` available in the proof block, so you only have to prove `P`.
In the end, the predicate `forall |idents| H ==> P` will be proved.

================
File: ./guide/src/bitvec.md
================

# Bit vectors and bitwise operations

Verus offers two dedicated mechanisms for reasoning about bit manipulation
(e.g., to prove that `xor(w, w) == 0`).  Small, one-off proofs can be done
via `assert(...) by(bit_vector)`. Larger proofs, or proofs that will be needed in more than one place, can be done by writing a proof function and adding the annotation 
`by(bit_vector)`.  
Both mechanisms export facts expressed over integers (e.g., in terms of `u32`), but internally, they translate the proof obligations into assertions about bit vectors and use a dedicated solver to discharge those assertions.

### `assert(...) by(bit_vector)`
This style can be used to prove a short and context-free bit-manipulation property.
Here are two example use cases:
```rust
{{#include ../../../rust_verify/example/guide/nonlinear_bitvec.rs:bitvector_easy}}
```

Currently, assertions expressed via `assert(...) by(bit_vector)` do not include any ambient facts from the surrounding context (e.g., from the surrounding function's `requires` clause or from previous variable assignments).  For example, the following example will fail.

```rust
{{#include ../../../rust_verify/example/guide/nonlinear_bitvec.rs:bitvector_fail}}
```

To make ambient facts available, add a `requires` clause to "import" these facts into the bit-vector assertion.  For example, the following example will now succeed.
```rust
{{#include ../../../rust_verify/example/guide/nonlinear_bitvec.rs:bitvector_success}}
```


### `proof fn ... by(bit_vector)`
This mechanism should be used when proving more complex facts about bit manipulation or when a proof will be used more than once. To use this mechanism, you should write a function in `proof` mode.
The function **should not** have a body. Context can be provided via a `requires` clause. 
For example:     
```rust
{{#include ../../../rust_verify/example/guide/nonlinear_bitvec.rs:de_morgan}}
```

## Limitations

### Supported Expressions 

The bit-manipulation reasoning mechanism supports only a subset of the full set of expressions Verus offers.
Currently, it supports:
- Unsigned integer types (as well as the `as` keyword between unsigned integers)
- Built-in operators
- `let` binding
- Quantifiers
- `if-then-else` 

Note that function calls are not supported. As a workaround, you may consider using a macro instead of a function. 


### Bitwise Operators As Uninterpreted Functions
Outside of `by(bit_vector)`, bitwise operators are translated into uninterpreted functions in Z3, meaning Z3 knows nothing about them when used in other contexts. 
As a consequence, basic properties such as the commutativity and associativity of bitwise-AND will not be applied automatically. To make use of these properties, please refer to [this example file](https://github.com/verus-lang/verus/blob/main/source/rust_verify/example/bitvector_basic.rs), which contains basic properties for bitwise operators.

### Naming Arithmetic Operators: `add/sub/mul`
Inside a bit-vector assertion, please use `add`, `sub`, and `mul` for fixed-width operators instead of `+` `-` `*`, as the latter operators widen the result to a mathematical integer. 

### Bit-Manipulation Examples Using the `get_bit!` and `set_bit!` Macros
You can use two macros, `get_bit!` and `set_bit!`, to access and modify a single bit of an integer variable. Please refer our [garbage collection example](https://github.com/verus-lang/verus/blob/main/source/rust_verify/example/bitvector_garbage_collection.rs) and our [bitvector equivalence example](https://github.com/verus-lang/verus/blob/main/source/rust_verify/example/bitvector_equivalence.rs).

================
File: ./guide/src/reference-assert-by-bit-vector.md
================

# assert ... by(bit_vector)

Invoke Z3's bitvector solver to prove the given predicate.

```
assert(P) by(bit_vector);
```

```
assert(P) by(bit_vector)
  requires Q;
```

The solver uses a technique called _bit-blasting_, which represents each numeric variable
by its binary representation as a bit vector, and every operation as a boolean circuit.

The prover does not have access to any prior context except that which is given in
the `requires` clause, if provided. If the `requires` clause is provided, then the
bit vector solver attempts to prove `Q ==> P`. Verus will also check (using its normal solver)
that `Q` holds from the prior proof context.

The expressions `P` and `Q` may only contain expressions that the bit solver understands.
The only types allowed are booleans and fixed-width unsigned integer types.
The allowed operations are bitwise (`&`, `|`, `^`, `!`, `<<`, `>>`) and arithmetic
(`add`, `sub`, `mul`, `/`, and `%`).

Note that `+`, `-`, and `*` return `int` or `nat` types when they are used as spec expressions.
Since the bit vector solver does not handle the infinite-width type `int`, it cannot
handle `+`, `-`, or `*`.
Function calls are also disallowed.

================
File: ./guide/src/lex_mutual.md
================

# Lexicographic decreases clauses

For some recursive functions,
it's difficult to specify a single value that decreases
in each recursive call.
For example, the [Ackermann function](https://en.wikipedia.org/wiki/Ackermann_function)
has two parameters `m` and `n`,
and neither `m` nor `n` decrease in all 3 of the recursive calls:

```rust
{{#include ../../../rust_verify/example/guide/recursion.rs:ackermann}}
```

For this situation, Verus allows the `decreases` clause to contain multiple expressions,
and it treats these expressions as
[lexicographically ordered](https://en.wikipedia.org/wiki/Lexicographic_order).
For example, `decreases m, n` means that one of the following must be true:
- m stays the same, and n decreases,
  which happens in the call `ackermann(m, (n - 1) as nat)`
- m decreases and n may increase or decrease arbitrarily,
  which happens in the two calls of the form `ackermann((m - 1) as nat, ...)`

# Mutual recursion

Functions may be mutually recursive,
as in the following example where `is_even` calls `is_odd` recursively
and `is_odd` calls `is_even` recursively:

```rust
{{#include ../../../rust_verify/example/guide/recursion.rs:even}}
```

The recursion here works for both positive and negative `i`;
in both cases, the recursion decreases `abs(i)`, the absolute value of `i`.

An alternate way to write this mutual recursion is:

```rust
{{#include ../../../rust_verify/example/guide/recursion.rs:even2}}
```

In this alternate version, the recursive call `!is_even(i)` doesn't
decrease `abs(i)`, so we can't just use `abs(i)` as the `decreases` clause by itself.
However, we can employ a trick with lexicographic ordering.
If we write `decreases abs(i), 1`,
then the call to `!is_even(i)` keeps the first expression `abs(i)` the same,
but decreases the second expression from `1` to `0`,
which satisfies the lexicographic requirements for decreasing.
The call `is_odd(i - 1)` also obeys lexicographic ordering,
since it decreases the first expression `abs(i)`,
which allows the second expression to increase from `0` to `1`.

================
File: ./guide/src/reference-assert-by.md
================

# assert ... by

The `assert ... by` statement is used to encapsulate a proof. For a boolean `spec` expression, `P`, one writes:

```rust
assert(P) by {
    // ... proof here
}
// ... remainder
```

Verus will validate the proof and then attempt to use it to prove the P.
The contents of the proof, however, will not be included in the context used to
prove the remainder.
Only `P` will be introduced into the context for the remainder.

================
File: ./internal/trait-notes.md
================

### 2023-06-07

Context: some notes about how we process traits in VIR, considerations needed for external/builtin traits, with an eye to some upcoming changes

---

Right now, the VIR ast keeps trait bounds for user-defined traits. A bunch of marker traits (like Sized) get dropped in rust_to_vir_base. We also ignore FnWithSpecification. I'm trying to decide if all that's okay as-is, and also what to do about an external trait like Allocator. It looks like VIR uses trait bounds for the following purposes:

1. recursion checking, treating trait bounds as conceptual dictionaries
2. check_functions_match in well_formed, used for decreases_by and when_used_as_spec
3. Check that there are no trait_bounds on broadcast_forall, as those would require more support to make sure they only activate when trait bounds are satisfied.

So, how does this functionality matter for all the external traits?

1. Not an issue for Sized or Allocator, these are all "nodes" that are conceptually defined before any Verus code. For FnWithSpecification, right now it only applies to closure types which can't be involved in any type cycles (enforced by Rust). Though, I have a PR that adds support for function types as well, so we'll need to start accounting for this.
2. This seems like it might be a (small) issue. If a spec function calls size_of (from Sized) or requires or ensures (from FnWithSpecification), and if an exec function redirects to that spec function via when_used_as_spec, we want to make sure that exec function also has the appropriate trait bound. However, this can easily be fixed by either remembering more traits at the VIR level or by doing the check at the Rust level. (I actually implemented this check as part of external_fn_specification, so we could just share code there.)
3. The broadcast_forall is the situation I'm most concerned about. Ideally we'd be able to write lemmas like:

```
#[broadcast_forall]
fn size_of_reference_type<V: Sized>()
  ensures size_of::<&V>() == size_of::<usize>()
```

However, this is not true for unsized types V (the reference &V is a "fat pointer" if V is unsized). So here, it's critically important the lemma only fire for types matching the trait bound. (It may also be little counterintuitive from our perspective, since we're not actually calling size_of::<V>() anywhere here.) Unfortunately, it's difficult to add a rule like "don't add a Sized trait bound to broadcast_forall lemmas" because Rust adds Sized bounds by default everywhere unless we add : ?Sized everywhere. Resolving this one way or the other is probably a blocking issue for making broadcast_forall un-trusted.

tl;dr We should probably be doing more checks relating to the trait bounds we're currently ignoring. That's not much of a problem, except for this one thorny case with broadcast_forall and Sized. However, there probably aren't any major issues with adding support for the external Allocator trait (needed to support std::Vec)

================
File: ./internal/trait-implementation-notes.md
================

**Written 2023-07-27**

Traits mostly fall into two buckets:

 * Verified traits - traits known by Verus, may include spec/proof/exec functions, can be used generically
 * External traits - traits not known by Verus, can only be used if statically resolved. (These are particularly useful for traits that implement syntactic features, like Index, which are unlikely to be used generically)
  - [ ] Originally it looks like there was a check to prevent external traits from being
        used as trait bounds. However, the check for this is buggy
        (https://github.com/verus-lang/verus/issues/629). We either need to allow this
        after all, or re-classify some external traits as verified traits.

"Verified" vs "external" is currently determined by whether Verus finds a trait in its
Krate object. Thus, any trait marked `#[external]` or defined in an external crate
will count as an "external trait".
  - [ ] The way we do this classification likely needs to change when we support more std traits like `Clone`.

Verus currently allows the user to write implementations for external traits. The functions
inside are treated as normal functions.

There are also a number of special cases:

 * Marker traits (`Copy`, `Send`, `Sync`, `Sized`, `Unpin`, `Tuple`) - these are pretty much treated as external (though `Sized` has some complications)
 * `Fn`, `FnMut`, `FnOnce`
    * Note that `FnWithSpecification` has been remove from builtin and is now defined as a user trait in vstd, so it's not important for soundness considerations.

### Expected Behaviors vs. current behaviors

 - External trait, external impl - Allowed, but calling one of its fns is disallowed
 - External trait, non-external impl, external fn - Allowed, but calling it is disallowed
 - External trait, verified impl - Allowed when calls are statically resolved
 - Verified trait, external impl - Allowed, but calling one of its fns is disallowed
   - [ ] TODO: fix panic
 - Verified trait, non-external impl, external f - Allowed, but calling it is disallowed
   - [ ] TODO: fix panic
 - Implement a marker trait - allowed (if unsafe, must be marked external)
 - impl FnOnce / Fn / FnMut - could be supported in principle, but probably not useful unless we also allow them to specify 'requires' and 'ensures' somehow. Currently an error.

# Overall architecture

### Static resolution

In `fn_call_to_vir`, we identify trait functions and determine if they can be statically resolved.
If so, we include this information in the `CallTargetKind` AST object.

After the VIR Krate is constructed, we `vir/src/traits.rs`, we check all the trait functions 
(`Function` entries) and their calls (`Expr` nodes) and see if the trait is known in the VIR 
krate.  If not, then we replace the call with the static resolution and pretend that it
isn't a trait function at all. (If there is no static resolution in that case, it's an error.) 

### AIR Encoding of verified traits

TODO fill in

### AIR Encoding of associated types

TODO fill in

### Handling FnOnce

Curerntly, FnOnce is only handled for closure types, though support
for named function types ("FnDef types") is coming: https://github.com/verus-lang/verus/pull/565

There are 3 functions to consider:

 * The exec call function (when the user writes `f(a)`)
 * The spec functions, `requires` and `ensures`

For the exec call, we internally translate these calls into `exec_nonstatic_call`, defined
in `vstd`, which provides a precondition and postcondition.

 - [ ] Internally, Rust actually has 3 functions: `FnOnce::call_once`, `FnMut::call_mut`, and `Fn::call`. We currently collapse all 3 ways of calling into 1. This is certainly fine for `call_once` and `call` (the only difference is the `&`), but we may want to revisit `call_mut` after we have more general `&mut` support.

For the spec functions, in VIR we represent these as `BuiltinSpecFun::{ClosureReq, ClosureEns}`,
and in AIR as `closure_req` and `closure_ens`. (Bit of a misnomer, since in the future,
they'll apply to all function types, not just closures.)

Also, `closure_req` and `closure_ens` are special-cased to _not include the decoration
for the function type_. This is so we can seemlessly handle both `FnOnce::call_once` and
`Fn::call`.

# Termination checking

Right now we're considering spec/proof only, not exec-termination.

Conceptually, we think of traits as "like typeclasses in Coq and F*". Specifically:

 * A trait is like the declaration of a record type.
 * A trait impl is a concrete instance of that record type.
 * Trait bounds (on functions or structs) are basically arguments of that record type.

For recursion checking, we need to check that everything can be defined in order.
We do this by creating a dependency graph and checking for cycles.

To do this checking, we need to know, for each call, which record instances get passed
in to satisfy the type bounds. This information is stored in the `ExprX::Call` node's `ImplPaths`
argument.

Special cases:

 * FnWithSpecification
   * Closures are easiest because Rust already prevents cyclicity with closures
   * For FnDef types (#565) we can define the record for a trait implementation
      `foo: FnWithSpecification` (for an exec function `foo`)
      when we define the `requires` and `ensures` of `foo`.

 * Marker traits
   * `Copy`, `Send`, `Sync`, `Sized`, `Unpin`, `Tuple` can all be ignored. This is fine since these traits don't have any functions.
 * External traits
   * Currently ignored. This could have implications for exec termination checking but shouldn't matter for spec termination checking. 

# Other considerations

**NOTE: this is now outdated.**

### `broadcast_forall`

Currently trait bounds on `broadcast_forall` are disallowed except for `Sized`
bounds which are implicit everywhere.

The expectation is that handling trait bounds in `broadcast_forall` will require an SMT `trait` sort,
an SMT predicate that types satisfy a trait bound, and SMT axioms for establishing that various types satisfy various trait bounds.

### `Sized`

Ideally we'd like to do:

```rust
#[broadcast_forall]
fn size_of_reference_type<V: Sized>()
  ensures size_of::<&V>() == size_of::<usize>()
```

Unfortunately we cannot because the `Sized` bounds are ignored. The current plan is to
not rely on `Sized` bounds at all and instead use a `is_sized::<V>() -> bool` function.

### Trait bound consistency

There are a few places where we need to check that two functions have the same function signatures, and therefore the same trait bounds:

 * `external_fn_specification` or `external_type_specification`
   * We check that the trait bounds match exactly, using `rustc_middle`'s `Predicate` objects.
     (But we might need to add special handling for https://github.com/verus-lang/verus/issues/656)
 * `when_used_as_spec`
   * Currently checked at VIR level. Marker traits and external traits are ignored at this point, as are function traits. Might be a good idea to change this check to be at the rustc level
     like the `external_fn_specification` checks.

### Drop

No plans regarding Drop support.

Implementing Drop is disallowed if it has any requires or if it is not marked `opens_invariants none` (https://github.com/verus-lang/verus/issues/723).

================
File: ./internal/modes.md
================

# Three kinds of code ... specification, proof, and executable

As stated in the project [goals](https://github.com/verus-lang/verus/wiki/Goals),
we want to provide a language that expresses specifications, proofs, and executable code.
These three kinds of code differ in significant ways.
For example, executable code is compiled, while proofs and specifications are erased.
In addition, to enable efficient SMT solving,
we [aim](https://github.com/verus-lang/verus/wiki/Goals) to keep the specification language close to the SMT solving language,
whereas executable code and proofs are more similar to programming languages
than to SMT formulas.

We describe these three kinds of code with three different "modes", `spec`, `proof`, and `exec`.
This is a slight extension to the concept of "ghost" and "non-ghost" code
in other verification frameworks like Dafny, in which `exec` corresponds to "non-ghost"
and `spec` and `proof` are two different kinds of "ghost".

Here is an example:
```
#[verifier(opaque)]
#[spec]
fn f(n: int) -> int { n + 1 }

#[proof]
fn lemma_f(n: int) {
    ensures(f(n) > n);

    reveal(f);
}

#[exec]
fn main() {
    #[spec] let x = 7;
    lemma_f(x);
    assert(f(7) > 7);
}
```

or, with a hypothetical future nice syntax:

```
#[verifier(opaque)]
spec fn f(n: int) -> int { n + 1 }

proof fn lemma_f(n: int)
    ensures
        f(n) > n
{
    reveal(f);
}

exec fn main() {
    spec let x = 7;
    lemma_f(x);
    assert(f(7) > 7);
}
```

In this example, `f` is a `spec` function, `lemma_f` is a `proof` function,
`main` is an `exec` function, `n` is a `spec` parameter, `x` is a `spec` variable,
and `f(n) > n` is a `spec` expression.
By default, `exec` function parameters are `exec` and `proof`/`spec` function parameters are `spec`,
so the function declarations above are equivalent to:

```
...
#[spec]
fn f(#[spec] n: int) -> int { n + 1 }

#[proof]
fn lemma_f(#[spec] n: int) {
...
```

There are no `proof` variables or parameters in this example --
we expect `proof` variables to be useful for some special kinds of proof,
but `spec` variables will be more common in standard Hoare-logic style proofs.

## `spec` and `proof` are different

As in Dafny, non-ghost (`exec`) code is compiled,
while ghost (`spec` and `proof`) code is erased before compilation.
However, `spec` and `proof` are treated differently in several ways.
First, `proof` is checked by the Rust lifetime checker,
while `spec` code is not:

```
spec  ---> type checker ---> SMT verifier
proof ---> type checker ---> SMT verifier ---> lifetime checker
exec  ---> type checker ---> SMT verifier ---> lifetime checker ---> compiler
```

Checking proofs for lifetimes enables styles of proof based on linearity,
where a linear `proof` value can represent evidence of the availability of some resource,
as in linear logic and separation logic.
By contrast, `spec` values are free from lifetime constraints:
programs can freely duplicate values within a specification.
More generally, even non-linear `proof` values may be considered evidence that something
has been proven (analogous to how values are used as proofs in constructive logics like Coq),
whereas `spec` values are not by themselves evidence of anything.

Second, proofs may have preconditions and postconditions (requires/ensures),
while specifications do not.
In fact, preconditions and postconditions are the whole point of proofs --
a proof's requires and ensures clause describe what a proof is proving --
but requires and ensures clauses are specifications, not proofs,
and do not carry their own additional requirements or provide
their own additional proofs.
This hard separation between proof and specification is similar to Boogie and Z3,
but differs from Dafny, F*, and Coq, where specifications are themselves verified.
For example, in Dafny, it is an error for a specification like `requires x / y <= 100` to divide by zero,
so that the program has to prove that `y != 0` to even state this specification.
By contrast, Boogie and Z3 treat division by zero in a specification as uninterpreted
rather than errant, and an assertion like `assert(1 / 0 == 1 / 0)` is perfectly valid.

Third, specifications treat all types as inhabited, while proofs (and executable code) do not.
Specifically, for uninhabited types like Rust's `never` type
(written `!` in nightly experimental Rust),
specifications allow for an additional special value called "bottom".
For example, the bottom value can be used to represent results returned by partial functions
that are applied to arguments outside the partial function's domain.
Executable code might create an empty vector `v` of type `vec<!>`.
Subscripting v, as in `v[5]`, would be an error in executable code.
However, specifications can freely refer to `v[5]`,
and the specification expression `v[5]` simply equals bottom.

On the other hand, `spec` and `proof` are similar in one important respect:
both proof functions (lemmas) and specification functions are checked for termination
when they use recursion.
To ensure termination, both `spec` and `proof` functions specify `decreases` clauses
that are checked by the SMT solver.
Proof functions must be checked for termination to avoid circular reasoning --
a proof can't prove itself by simply calling itself recursively infinitely many times.
Specification functions are checked for termination to make sure that they
define meaningful values (a non-terminating function like
`fn f(i: nat) -> nat {f(i) + 1}`
does not actually define a value f(7) such that f(7) = f(7) + 1,
as this is impossible to satisfy.)

## Some language design pitfalls to avoid

The distinction between `spec` and `proof` means that some care must
be taken along the boundary between the two.
In particular, since `spec` includes the bottom value and `proof` does not,
we have to make sure that bottom cannot accidentally flow from `spec` to `proof`
or otherwise malevolently influence proofs.
As described in the section below on mode checking,
it is illegal to directly assign a `spec` value to a `proof` or `exec` variable,
so bottom cannot directly flow into proof variables.
However, there are some more subtle issues.

First, `proof` expressions can pattern match on `spec` values using Rust's `match` expression.
When matching on an enumeration,
this is only sound if the enumeration is non-empty (contains at least one variant).
An empty enumeration is an uninhabited type,
which may be bottom in a specification value.
Allowing a proof match on bottom could generate a proof value of an uninhabited type.
Therefore, for soundness, the mode checking rules described below contain a side condition
that prohibits out this case.

Second, the SMT encoding of non-empty enumerations can assume that each
enumeration value belongs to one of the enumeration's variants.
The SMT encoding cannot make this assumption for empty enumerations,
though, since an empty enumeration contains no variants and may
be represented by bottom in specifications.

Third, refinement types (types whose values satisfy some user-defined predicate)
must be inhabited -- there must be a value of the type for which the predicate holds.
Otherwise, the predicate could simply be `false`,
and the SMT encoding of the predicate would assume `false` whenever a value
of the refinement type appears (in particular, when the bottom value appears in a specification).
Currently, the only refinement types are the built-in numeric types like `u8`, `u16`, etc.,
and these are all inhabited, since there exist integers in the range 0..255, 0..65535, etc.
(As an alternative, instead of requiring refinement types to be inhabited,
we could simply not make SMT assumptions about refinement types for `spec` values.
However, the lack of such assumptions might surprise programmers.
If a `spec` variable `x` has type `u8`, programmers might reasonably expect
that `assert(x < 256)` is automatically valid
without requiring any manual proof work by the programmer.)

Fourth, the Rust compiler can optimize code under the assumption that
no variables can possibly contain a value of the never (`!`) type.
Because `spec` variables can contain values of the never type,
we *must* erase `spec` code before running Rust's compiler.
(It's supposed to be erased anyway; we just have to make sure we really do it.) 

Lastly, consider a value `v` that is a first-class function or a value implementing a trait.
If the function type can have postconditions or the trait members can have postconditions,
then those postconditions are only valid if `v` is an `exec` or `proof` value,
not if `v` is a `spec` value.
In other words, the SMT encoding can assume that postconditions are true
for calls to first-functions and trait members,
but only when calling non-`spec` function and trait values.
This reflects the fact that some function types and trait types might be uninhabited,
a `spec` value of these types might be the bottom value rather than a real function or trait value.
See, for example, [Dafny issue 851](https://github.com/dafny-lang/dafny/issues/851),
where ghost Dafny code could create a ghost value of an uninhabited trait type and
then deduce false from a trait member's postcondition.
Note, though, that unlike Dafny's "ghost" expressions,
`spec` expressions by design ignore preconditions and postconditions
(SMT assertions and assumptions about requires/ensures are only introduced in `exec` and `proof` code).
In other words, making the distinction between `spec` and `proof` allows us to avoid the issue
that arose with Dafny's "ghost".
Nevertheless, it's worth remembering this issue as the language evolves
or we consider alternative designs.

## Mode checking

Each function, local variable, function parameter, function return value, and struct/enum field has a mode.
By default:
- functions are `exec`
- struct/enum fields are `exec`
- for `exec` functions:  variables, parameters, and return values are `exec`
- for `proof` and `spec` functions:  variables, parameters, and return values are `spec`

To override the defaults, programmers can annotate functions, variables, parameters,
return values, and fields with the #[exec], #[proof], or #[spec] attributes.

The formal rules below check the modes of expressions for a simplified model of the language.
The rules include named structs `S`, named enumerations `U`, and named functions `F`.
Both struct and enumeration fields are annotated with modes `m`.
The subsumption rule allows coercions from `exec` to `proof`/`spec` and from `proof` to `spec`,
but not the other way around
(`spec` values cannot flow into `proof`/`exec` variables,
and `proof` values cannot flow into `exec` variables).

Expressions are checked in an environment `m ; G`.
In this environment, `G` describes the modes and types of parameters and local variables.
`m` describes the mode of the code in which the expression lives.
For example, in a precondition or postcondition, `m` will be `spec` -- this ensures
that specifications cannot contain proofs or executable code.
In the body of a function, `m` will be equal to the mode of the function
(e.g. a `spec` function has a `spec` body and an `exec` function has an `exec` body).
This ensures, for example, that proofs (lemmas) cannot contain executable code.

```
Modes, mode ordering, least upper bounds
  m = exec | proof | spec
  exec <= proof <= spec
  LUB(m, m) = m
  LUB(m, spec) = LUB(spec, m) = spec
  LUB(m, exec) = LUB(exec, m) = m

Types, patterns, and expressions
  t = int | S | U
  p = x1 … xj
  e = x | n | e1 + e2 | let x: m t = e1 in e2
    | F(e1, …, ej)
    | S(e1, …, ej) | e.i
    | U.i(e1, …, ej)| match e {p1 => e1, …, pk => ek}

Function types
  f = mf (m1 t1, …, mj tj) -> m0 t0
    where mf <= m0 and … and mf <= mj

Assume a mapping from function names F to modes and types
  F1 -> f1, …, Fn -> fn

Struct/enumeration types:
  s = (m1 t1, …, mj tj)
  u = (s1, …, sk)

Assume a mapping from struct/enumeration names S/U to definitions s/u:
  S1 -> s1, …, Sm -> sm
  U1 -> u1, …, Un -> un

Typing environment m ; G
where G = x1: m1 t1, ..., xn: mn tn

Typing rules m ; G |- e : m' t

m ; G |- e : m1 t
m1 <= m2
----------------- ("subsumption rule")
m ; G |- e : m2 t

m ; G, x : mx tx |- x : LUB(m, mx) tx

m ; G |- n : m int

m ; G |- e1 : m1 int
m ; G |- e2 : m2 int
----------------------------------
m ; G |- e1 + e2 : LUB(m1, m2) int

m <= mx
m ; G |- ex : mx tx
m ; G, x : mx tx |- eb : mb tb
----------------------------------------
m ; G |- let x: mx tx = ex in eb : mb tb

F -> f
f = mf (m1 t1, …, mj tj) -> m0 t0
m <= mf
m ; G |- e1 : m1 t1
…
m ; G |- ej : mj tj
---------------------------------
m ; G |- F(e1, …, ej) : m0 t0

S -> (m1 t1, …, mj tj)
m ; G |- e1 : m1 t1
…
m ; G |- ej : mj tj
------------------------------
m ; G |- S(e1, …, en) : m S

m ; G |- e : me S
S -> (m1 t1, …, mj tj)
-----------------------------
m ; G |- e.i : LUB(me, mi) ti

U -> (s1, …, sk)
si = (m1 t1, …, mj tj)
m ; G |- e1 : m1 t1
…
m ; G |- ej : mj tj
-----------------------------
m ; G |- U.i(e1, …, ej) : m U

m ; G |- e : me U
U -> (s1, …, sk)
me = spec ==> k > 0
for each 1 <= i <= k:
  si = (m1 t1, …, mj tj)
  pi = x1, …, xj
  m' = (if m = exec and me != exec then proof else m)
  G' = G, x1: LUB(me, m1) t1, …, xj: LUB(me, mj) tj
  m' ; G' |- ei : mb t
-----------------------------------------------------
m ; G |- match e {p1 => e1, …, pk => ek} : mb t
```

The pattern match rule (`match e {…}`) contains some subtleties.
First, the  `me = spec ==> k > 0` condition disallows matching on an empty `spec` enumeration. 
This guards against the pitfall of matching with `e` equal to the "bottom" value
(see the previous section on pitfalls).

Second, the definition of `m'` allows the case `ei` to be executable
only if the matched expression `e` is executable.
Otherwise, the match would not be compilable -- you wouldn't be able to decide at run-time
which `ei` to execute if `e` were erased (as would happen if `e` were `proof` or `spec`).
Based on this requirement, you might expect the rule to say `m' = LUB(m, me)` or even just `m' = me`.
However, this would be stricter than necessary.
We can allow `m' = proof` even if `me = spec`.
This allows proofs to inspect `spec` values, which is both useful and safe.
For example, a proof by induction on a `spec` variable `n` might inspect `n` to see whether it is zero or non-zero,
and the proof can recursively call itself in non-zero case.

Note that we perform lifetime checking on `proof` code but not on `spec` code.
In other words, `spec` code is erased before we run Rust's lifetime checker on the `proof` code.
If the `proof` code matches on an expression `e` with mode `spec`,
then we will erase the `e` in the match before running the lifetime checker,
which would naively result in ill-formed Rust code.
To prevent this ill-formed code, such a match is instead erased into an if-else-if…-else expression,
where the condition of each `if` is a non-deterministic bool.

## Erasure

After mode checking, type checking, and SMT verification, we erase `spec` code.
After lifetime checking, we also erase `proof` code.
This way, only `exec` expressions remain for the Rust compiler to compile.
Note that expressions can contain mixtures of `spec`, `proof`, and `exec` code.
For example, if `e` is an argument to a function that expects a `spec` parameter,
`e` might contain some `exec` code that must be compiled for its side effects,
even though the ultimate result of evaluating `e` is an erased `spec` value.
(Note that the mode checker already prohibits `exec` subexpressions from
appearing inside `spec`/`proof` function bodies and `requires/ensures/invariant`,
so these can be always be entirely erased before compilation.
We might consider making the mode checker even more strict,
so that, for example, a `spec` argument could not contain `exec` code inside it.)

Let `ERASE(m_keep, m_expect, e)` be the result of performing erasure on `e`.
More specifically:
- `ERASE(exec, m_expect, e)` is the result of erasing all `spec` and `proof` code from `e`, keeping only the `exec` code
- `ERASE(proof, m_expect, e)` is the result of erasing all `spec` code from `e`, keeping only the `exec` and `proof` code
- `ERASE(spec, m_expect, e)` erases nothing, and just returns `e`

`m_expect` specifies what mode of value we expect `e` to produce.  If `m_expect = exec`, we expect `e` to produce an `exec` value, so we can't erase the generated value.  If `m_expect = proof` or `m_expect = spec`, we may be able to erase the generated value.  For example, `ERASE(_, exec, 99) = 99`, but `ERASE(exec, spec, 99) = ()`.  In the latter case, we erase the value `99` because the value will be used as a `spec` value, and `spec` values are being erased.  This can happen, for example, in the expression `F(99)` if `F` expects an argument of mode `spec`.

Note: `ERASE` may produce expressions like `(); ()` or matches with all cases returning `()`.  These can easily be further simplified.

```
Types, patterns, and expressions
  t = ... | ()
  e = ... | () | e; e | if * then e else e


Erasure in types

If m <= m_keep
  ERASE(m_keep, m t) = m t
Otherwise
  ERASE(m_keep, m t) = ()

Let f = mf (m1 t1, …, mj tj) -> m0 t0
Let f' = mf (ERASE(m_keep, m1 t1), ..., ERASE(m_keep, mj tj)) -> ERASE(m_keep, m0 t0)
If mf <= m_keep
  ERASE(m_keep, F -> f) = F -> f'
Otherwise
  ERASE(m_keep, F -> f) = {}

Let s = (m1 t1, …, mj tj)
Let s' = (ERASE(m_keep, m1 t1), ..., ERASE(m_keep, mj tj))
ERASE(m_keep, s) = s'

Let u = (s1, …, sk)
Let u' = (ERASE(m_keep, s1), …, ERASE(m_keep, sk))
ERASE(m_keep, u) = u'


Erasure in expressions

ERASE(m_keep, m_expect, ()) = ()

If m_expect <= m_keep
  ERASE(m_keep, m_expect, n) = n
Otherwise
  ERASE(m_keep, m_expect, n) = ()

Let e1' = ERASE(m_keep, m_expect, e1)
Let e2' = ERASE(m_keep, m_expect, e2)
If m_expect <= m_keep
  ERASE(m_keep, m_expect, e1 + e2) = e1' + e2'
Otherwise
  ERASE(m_keep, m_expect, e1 + e2) = e1'; e2'

(note: the value of e1 is discarded, so we have minimal expectations of it, so we set m_expect = spec for e1)
Let e1' = ERASE(m_keep, spec, e1)
Let e2' = ERASE(m_keep, m_expect, e2)
ERASE(m_keep, m_expect, e1; e2) = e1'; e2'

Let x: mx tx
If mx <= m_keep and m_expect <= m_keep
  ERASE(m_keep, m_expect, x) = x
Otherwise
  ERASE(m_keep, m_expect, x) = ()

Let ex' = ERASE(m_keep, mx, ex)
Let eb' = ERASE(m_keep, m_expect, eb)
If mx <= m_keep then
  ERASE(m_keep, m_expect, let x: mx tx = ex in eb) = let x: mx tx = ex' in eb'
Otherwise
  ERASE(m_keep, m_expect, let x: mx tx = ex in eb) = ex'; eb'

Let F -> f
Let f = mf (m1 t1, …, mj tj) -> m0 t0
Let e1' = ERASE(m_keep, m1, e1), …, ej' = ERASE(m_keep, mj, ej)
If mf <= m_keep
  If m_expect <= m_keep
    ERASE(m_keep, m_expect, F(e1, …, ej)) = F(e1', …, ej')
  Otherwise
    ERASE(m_keep, m_expect, F(e1, …, ej)) = F(e1', …, ej'); ()
Otherwise
  ERASE(m_keep, m_expect, F(e1, …, ej)) = e1'; …; ej'; ()

Let S -> (m1 t1, …, mj tj)
Let e1' = ERASE(m_keep, LUB(m_expect, m1), e1), …, ej' = ERASE(m_keep, LUB(m_expect, mj), ej)
If m_expect <= m_keep
  ERASE(m_keep, m_expect, S(e1, …, ej)) = S(e1', …, ej')
Otherwise
  ERASE(m_keep, m_expect, S(e1, …, ej)) = e1'; …; ej'; ()

Let S -> (m1 t1, …, mj tj)
Let e' = ERASE(m_keep, m_expect, e)
If mf <= m_keep and m_expect <= m_keep
  ERASE(m_keep, m_expect, e.i) = e'.i
Otherwise
  ERASE(m_keep, m_expect, e.i) = e'; ()

Let U -> (s1, …, sk)
Let si = (m1 t1, …, tj tj)
Let e1' = ERASE(m_keep, LUB(m_expect, m1), e1), …, ej' = ERASE(m_keep, LUB(m_expect, mj), ej)
If m_expect <= m_keep
  ERASE(m_keep, m_expect, U.i(e1, …, ej)) = U.i(e1', …, ej')
Otherwise
  ERASE(m_keep, m_expect, U.i(e1, …, ej)) = e1'; …; ej'; ()

Let e : me U
Let e' = ERASE(m_keep, me, e')
Let e1' = ERASE(m_keep, m_expect, e1), …, ek' = ERASE(m_keep, m_expect, ek)
If me = exec
  ERASE(m_keep, m_expect, match e {p1 => e1, …, pk => ek}) = match e' {p1 => e1', …, pk => ek'}
Otherwise
  If m_expect = exec
    This case should not happen; the mode checker should have already disallowed it
  Otherwise
    If m_keep = exec (note: exec code in cases is disallowed when me in {proof, spec}, so there's no exec code to keep in the cases)
      ERASE(m_keep, m_expect, match e {p1 => e1, …, pk => ek}) = e'
    If me = spec and m_keep = proof
      ERASE(m_keep, m_expect, match e {p1 => e1, …, pk => ek}) = e'; if * then e1' else if * then … else ek'
    Otherwise
      ERASE(m_keep, m_expect, match e {p1 => e1, …, pk => ek}) = match e' {p1 => e1', …, pk => ek'}
```

## Possible future extension: multi-mode functions

The rules above prohibit a specification from calling an `exec` function.
However, some `exec` functions could also work as `spec` functions.
The `len` function of Rust's `vec` type, for example, is deterministic and free of side effects,
so it would be safe to use within a `spec`.
We could extend the mode system to allow this.

Note, however, that we don't necessarily have to allow `spec` code to call `len`.
For example, we could define a separate function for getting the length as a `spec` value.
(We might also consider having `vec` auto-derive such separate `spec` functions.)
Or we could define a function that converts the entire `vec` value
into a more abstract sequence type (an abstract, mathematical "view" of the vector),
and this sequence type would then have a `spec` length function or method.
We could even consider some implicit coercions from the `vec` into the abstract view type
in some circumstances, such as when passing the `vec` as an argument to a function that
expects an abstract sequence, or when attempting to call an `exec` method like `len`
from within a specification.

If, however, we do want to allow `spec` code to call the original `exec` length function/method,
we could allow `len` to be annotated as both `spec` and `exec`.
This would be similar to a "function method" in Dafny,
which can be both compiled and used as a specification.

================
File: ./internal/record-history.md
================

The `record-history` feature records every invocation of Verus with the current source of the crate it was invoked on, and the Verus verification results and outputs.

To enable, re-build vargo, then compile Verus with `--features record-history`:

```
vargo build --release --features record-history
```

Then you need a per-project opt-in.
To opt-in place an empty directory named `.record-history` in the same directory as the file that acts as the crate root. That is, if you normally run Verus as

```
verus path/to/foo.rs
```

Add an empty folder named `path/to/.record-history`.

The next time Verus is run, it will create `path/to/.record-history/git`, which will contain a bare repo with the recordings.
================
File: ./README.md
================

# Verus Documentation

Verus is a tool for verifying the correctness of code written in Rust. This repository contains the documentation that is distributed as part of the Verus release.

Last updated: July 17, 2024.

================
File: ./state_machines/book.toml
================

[book]
language = "en"
multilingual = false
src = "src"
title = "Verus Transition Systems"

[output.html]
curly-quotes = true

[output.html.playground]
runnable = false

================
File: ./state_machines/src/macro-generated-reference.md
================

# Macro-generated code

================
File: ./state_machines/src/strategy-reference.md
================

# Strategy Reference

In a tokenized state machine, Verus produces a set of _token types_ such that any
state of the system represents some collection of objects of those types.
This tokenization process is determined by a _strategy_ declared on each field of
the state definition.
Specifically, for each field, Verus (potentially) generates a token type for the field
depending on the declared strategy, with the strategy determining some
relationship between the state's field value and a collection of such tokens.
The entire state, consisting of _all_ fields, then corresponds to a collection of objects
out of all the defined token types.

 * For example, consider a field `f` of type `T` with strategy `variable`.
   In this case, the token type (named `f`) has a value `T` on it, and we require the collection
   to always have exactly one such token, giving, of course, the value of `f`.

 * On the other hand, consider a field `g` of type `Map<K, V>` with strategy `map`.
   In this case, the token types have pairs `(k, v)`. The collection can have any number of
   tokens, although they have to all have distinct keys, and the pairs all together form a 
   map which gives the value of field `g`.

 * Or consider a field `h` of type `Option<V>` with strategy `option`.
   In this case, the token type has a value `v: V`, and the collection must contain either
   no tokens for this type (yielding `Option::None`), or exactly one
   (yielding `Option::Some(v)`).

![Graphic visualization of the examples](graphics/strategy-reference-examples.png)

Each transition of the system can be viewed both as a transition relation in the same sense
as in an orindary transition, but _also_ as an "exchange" of tokens,
where a sub-collection of tokens is taken in (consumed) and exchanged for a new sub-collection.
All of the rules we discuss below are meant to ensure that
each exchange performed on a valid collection will result in another valid collection
and that the corresponding global system states transition according to the relation.

## The `Instance` token and the `constant` strategy

Every tokenized state machine generates a special `Instance` token type.
Besides serving as a convenient object with which to serve the exchange function API,
the `Instance` also serves as "unique identifier" for a given instantiation of the protocol.
All other token types have an `instance: Instance` field, and in any exchange, all
of these instance markers are required to match.

The `Instance` type implements `Clone`, so it can be freely shared by all the clients
that need to manipulate some aspect of the protocol.

The `Instance` type also contains all fields declared with the `constant` strategy,
accessed as `instance.field_name()`. Fields with the `constant` strategy cannot be updated
after the protocol has been initialized, so this information will never be inconsistent.
Furthermore, `constant` fields do not not generate their own constant types.

## The `variable` strategy

If a field `f` has strategy `variable`, then Verus generates a token type `f`, with values
given by `token![$instance => f => $value]`.

Verus enforces that there is always exactly one token of the type `f`.

(Technical note: the reader might wonder what happens if the user attempts to `drop` the token.
This is allowed because dropped tokens are still considered to "exist" in the perspective of the abstract ghost program. Dropping a token only means that it is made inaccessible.)

The value of a `variable` field is manipulated using the ordinary `update` command, as in
ordinary transition definitions. The old value can be accessed as usual with `pre.f`.

If `f` is updated by a transition, then the corresponding exchange function takes an `f`
taken as an `&mut` argument. If `f` is read (via `pre.f`) but never updated, then it is
read as an `&` argument.
If the field is neither read nor written by the transition, then it is not taken as
an argument.

## The "collection-style" strategies with `remove`/`have`/`add`

(TODO not all of these exist yet)

A large number of tokenization strategies are specified in what we call _collection-style_
or _monoid-style_. Specifically, this includes
`option`, `map`, `multiset`, `set`, `count`, and `bool`,
as well as their "persistent" verions
`persistent_option`, `persistent_map`, `persistent_set`, `persistent_count`, and `persistent_bool`.

### Basic Collection Strategies


| Strategy | Type          | Token value                          | Requirements / relationship to field value                         |
|----------|---------------|--------------------------------------|--------------------------------------------------------------------|
| option   | `Option<V>`   | `token![$instance => f => $v]`       | No token for `None`, one token for `Some(v)`.                      |
| map      | `Map<K, V>`   | `token![$instance => f => $k => $v]` | At most one token for any given value of `k`.                      |
| multiset | `Multiset<V>` | `token![$instance => f => $v]`       | No restrictions.                                                   |
| set      | `Set<V>`      | `token![$instance => f => $v]`       | At most one token for any given value of `v`.                      |
| count    | `nat`         | `token![$instance => f => $n]`       | Any number of tokens; the sum of all tokens gives the field value. |
| bool     | `bool`        | `token![$instance => f => true]`     | Token either exists (for `true`) or doesn't exist (for `false`).   |

(In the table, `v` has type `V`, `k` has type `K`, `n` has type `nat`, and `b` has type `bool`.)

Initially, some of these might seem odd---why, for example, does `bool` have a `true` token, and no `false` token?
However, if the user wants a `false` token, they can just use the `variable` strategy. Instead, `bool`, here, is meant to
represent the case where we want a token that either exists, or doesn't, with no other information, and the natural
representation of such a thing is a bool. (Actually, `bool` is just isomorphic to `Option<()>`.)

Describing transitions for these collection types is somewhat more involved. Note that a user _cannot_ in general
establish the exact value of one of these fields simply by providing some tokens for the field, since it's always possible
that there are other tokens elsewhere. As such, the values of these fields are not manipulated through _update_ but through
three commands called `remove`, `have`, and `add`.

To describe these, we will first establish a notion of _composition_ on the field types.
Specifically, we define the composition `a · b` by the idea that if `a` and `b` each represent some collection
of tokens, then `a · b` should represent the union of those two collections.
Of course, this may not always be well defined: as we have discussed, not all possible collections of tokens
are valid collections for the given strategy. Thus, we let `a ## b` indicate that the composition is well-defined.

(Note: these operators are for documentation purposes only; currently, they are not operators that can be used in Verus code.)

| Strategy | `a ## b`                     | `a · b`                         |
|----------|------------------------------|---------------------------------|
| option   | <code>a === None \|\| b === None</code> | `if a == None { b } else { a }` |
| map      | `a.dom().disjoint(b.dom())`  | `a.union_prefer_right(b)`       |
| multiset | `true`                       | `a.add(b)`                      |
| set      | `a.disjoint(b)`              | `a.union(b)`                    |
| count    | `true`                       | `a + b`                         |
| bool     | `!(a && b)`                  | <code>a \|\| b</code>           |

Note that despite any apparent asymmetries, `a · b` is always commutative whenever `a ## b`, and these definitions
are all consistent with the union of token collections, given by the relationships in the above table.

Now, write `a >= b` if there exists some value `c` such that `a · c = b`.
Note that `c` is always unique when it exists. (This property is called _cancellativity_,
and it is not in general true for a monoid; however, it is true for all the ones we consider here.)
When `a >= b`, let `a - b` denote that unique value.

Now, with these operators defined, we can give a general meaning for the three transition commands,
`remove`, `have`, and `add`, in terms of [`require`, `update`, and `assert`](./transition-language.md).

| Command            | Meaning as transition on state      | Meaning for exchange function           |
|--------------------|-------------------------------------|-----------------------------------------|
| `remove f -= (x);` | `require f >= x;`<br>`update f = f - x;` | Input argument, consumed           |
| `have f >= (x);`   | `require f >= x;`                   | Input argument of type `&_`             |
| `add f += (x);`    | `assert f ## x;`<br>`update f = f · x;`  | Output argument                    |

Furthermore, for a given field, the commands always go in the order `remove` before `have` before `add`.
There could be multiple, or none, of each one.
The reason is that ordering would not impact the definition of the exchange function; furthermore,
this particular ordering gives the strongest possible relation definition, so it the easiest to work with.
For example, a `remove` followed by a `have` will capture the fact the two values used as arguments
must be disjoint by `##`.

Unfortunately, the _type_ of the input or output argument is, in general, somewhat complicated,
since it needs to correspond to the value `x` in the above table, which takes on the same type as the
field.
For example, suppose `f` and `x` take on values of type `Map<K, V>` with the `map` strategy.
In that case, the _token type_ (named `f`) represents only a single (key, value) pair of the map,
and the `tracked` objects passed into or out of the exchange function would need to be
_maps_ of tokens. (TODO link to documentation about using tracked maps)
The same is true of `option`, `set`, and `multiset`.

In the _common case_, transitions are defined so that arguments in or out are just single tokens
of the token type `f`, in the form given [in the above table](#basic-collection-strategies).
(The primary exceptions are output arguments [of the `init` routines](#init)
or large, bulk transitions that operate on a lot of state.)
The `remove`, `have`, and `add` commands all allows a syntactic shorthand for "singleton" elements:

 * `add f += Some(x)` is for `option`
 * `add f += [k => v]` is for `map` singletons
 * `add f += {x}` is for `multiset` and `set` singletons

Of course, this applies to `remove` and `have` as well.

The general form is `add f += (x)` as above, with `x` taking the same type as field `f`.
(The parentheses are necessary.)
The general form works for all the collection strategies.

Note that there is no "special" form for either `count`, since the general form
is perfectly suitable for those situations.

Also note that the special forms generate simpler proof obligations, and thus are
easier for the SMT solver to handle.

We supply, here, a reference table for all the different possible commands for each strategy:

| Type          | Command                 | Meaning in transition                                                                 | Exchange Fn Parameter |
|---------------|-------------------------|---------------------------------------------------------------------------------------|-----------------------|
|&nbsp;         |                         |                                                                                       |                       |
| `Option<V>`   | `remove f -= Some(v);`  | `require f === Some(v);`<br>`update f = None;`                                        | Input `f`             |
| `Option<V>`   | `have f >= Some(v);`    | `require f === Some(v);`                                                              | Input `&f`            |
| `Option<V>`   | `add f += Some(v);`     | `assert f === None;`<br>`update f = Some(v);`                                         | Output `f`            |
|&nbsp;         |                         |                                                                                       |                       |
| `Option<V>`   | `remove f -= (x);`      | <code>require x === None \|\| f === x;</code><br>`update f = if x === None { f } else { None };` | Input `Option<f>`     |
| `Option<V>`   | `have f >= (x);`        | <code>require x === None \|\| f === x;</code>                                                    | Input `&Option<f>`    |
| `Option<V>`   | `add f += (x);`         | <code>assert f === None \|\| x === None;</code><br>`update f = if x === None { f } else { x };`  | Output `Option<f>`    |
|&nbsp;         |                         |                                                                                       |                       |
| `Map<K, V>`   | `remove f -= [k => v];` | `require f.contains(k) && f.index(k) === v;`<br>`update f = f.remove(k);`             | Input `f`             |
| `Map<K, V>`   | `have f >= [k => v];`   | `require f.contains(k) && f.index(k) === v;`                                          | Input `&f`            |
| `Map<K, V>`   | `add f += [k => v];`    | `assert !f.contains(k);`<br>`update f = f.insert(k, v);`                              | Output `f`            |
|&nbsp;         |                         |                                                                                       |                       |
| `Map<K, V>`   | `remove f -= (x);`      | `require x.le(f);`<br>`update f = f.remove_keys(x.dom());`                            | Input `Map<K, f>`     |
| `Map<K, V>`   | `have f >= (x);`        | `require x.le(f);`                                                                    | Input `&Map<K, f>`    |
| `Map<K, V>`   | `add f += (x);`         | `assert x.dom().disjoint(f.dom();)`<br>`update f = f.union_prefer_right(x);`          | Output `Map<K, f>`    |
|&nbsp;         |                         |                                                                                       |                       |
| `Multiset<V>` | `remove f -= {v};`      | `require f.count(v) >= 1;`<br>`update f = f.remove(v);`                               | Input `f`             |
| `Multiset<V>` | `have f >= {v};`        | `require f.count(v) >= 1;`                                                            | Input `&f`            |
| `Multiset<V>` | `add f += {v};`         | `update f = f.insert(v);`                                                             | Output `f`            |
|&nbsp;         |                         |                                                                                       |                       |
| `Multiset<V>` | `remove f -= (x);`      | `require x.le(f);`<br>`update f = f.sub(x);`                                          | Input `Multiset<f>`   |
| `Multiset<V>` | `have f >= (x);`        | `require x.le(f);`                                                                    | Input `&Multiset<f>`  |
| `Multiset<V>` | `add f += (x);`         | `update f = f.add(x);`                                                                | Output `Multiset<f>`  |
|&nbsp;         |                         |                                                                                       |                       |
| `Set<V>`      | `remove f -= {v};`      | `require f.contains(v);`<br>`update f = f.remove(v);`                                 | Input `f`             |
| `Set<V>`      | `have f >= {v};`        | `require f.contains(v);`                                                              | Input `&f`            |
| `Set<V>`      | `add f += {v};`         | `assert !f.contains(v);`<br>`update f = f.insert(v);`                                 | Output `f`            |
|&nbsp;         |                         |                                                                                       |                       |
| `Set<V>`      | `remove f -= (x);`      | `require x.subset_of(f);`<br>`update f = f.difference(x);`                            | Input `Set<f>`        |
| `Set<V>`      | `have f >= (x);`        | `require x.subset_of(f);`                                                             | Input `&Set<f>`       |
| `Set<V>`      | `add f += (x);`         | `assert f.disjoin(t);`<br>`update f = f.union(x);`                                    | Output `Set<f>`       |
|&nbsp;         |                         |                                                                                       |                       |
| `nat`         | `remove f -= (x);`      | `require f >= x;`<br>`update f = f - x;`                                              | Input `f`             |
| `nat`         | `have f >= (x);`        | `require f >= x;`                                                                     | Input `&f`            |
| `nat`         | `add f += (x);`         | `update f = f + x;`                                                                   | Output `f`            |
|&nbsp;         |                         |                                                                                       |                       |
| `bool`        | `remove f -= true;`     | `require f == true;`<br>`update f = false;`                                           | Input `f`             |
| `bool`        | `have f >= true;`       | `require f == true;`                                                                  | Input `&f`            |
| `bool`        | `add f += true;`        | `assert f == false;`<br>`update f = true;`                                            | Output `f`            |
|&nbsp;         |                         |                                                                                       |                       |
| `bool`        | `remove f -= (x);`      | `require x ==> f;`<br>`update f = f && !x;`                                           | Input `Option<f>`     |
| `bool`        | `have f >= (x);`        | `require x ==> f;`                                                                    | Input `&Option<f>`    |
| `bool`        | `add f += (x);`         | `assert !(f && x);`<br><code>update f = f \|\| x;</code>                              | Output `Option<f>`    |


### Persistent Collection Strategies

Verus supports "persistent" versions for several of the collection types:
`persistent_option`, `persistent_map`, `persistent_set`, `persistent_count`, and `persistent_bool`.

By "persistent", we mean that any state introduced is permanent.

 * `persistent_option`: once a value becomes `Some(x)`, it will always remain `Some(x)`.
 * `persistent_map`: once a (key, value) pair is inserted, that key will always remain, and its value will never change.
 * `persistent_set`: once a value is inserted, that value will remain
 * `persistent_count`: the number can never decrease
 * `persistent_bool`: once it becomes true, it can never become false.

As a result, we can remove the uniqueness constraints on the tokens,
and we can implement `Clone` on the token type.
In other words, for a given token (say, `token![instance => f => k => v]`)
we can freely make clones of that token without tracking the number of clones.

| Strategy | `a ## b`                     | `a · b`                         |
|----------|------------------------------|---------------------------------|
| `persistent_option`   | <code>a === None \|\| b === None \|\| a === b</code> | `if a == None { b } else { a }` |
| `persistent_map`      | `a.agrees(b)`                | `a.union_prefer_right(b)`       |
| `persistent_set`      | `true`                       | `a.union(b)`                    |
| `persistent_count`    | `true`                       | `max(a, b)`                     |
| `persistent_bool`     | `true`                       | <code>a \|\| b</code>           |

Unlike before, `a ## a` always holds (with `a · a = a`).
At a technical level,
this property is what makes it safe to implement `Clone` on the tokens.

This property also lets us see why we cannot `remove` state.
These monoids are not _cancellative_ like the above; in particular,
if we have state `a` and attempt
to "subtract" `a`, then we might still be left with `a`.
Thus, from the perspective of the transition system, there can never be any point
to doing a remove.

`have` and `add` are specified in the same methodology as above, which amounts to the following:

| Type            | Command               | Meaning in transition                                                                             | Exchange Fn Parameter |
|-----------------|-----------------------|---------------------------------------------------------------------------------------------------|-----------------------|
| &nbsp;          |                       |                                                                                                   |                       |
| `Option<V>`     | `have f >= Some(v);`  | `require f === Some(v);`                                                                          | Input `&f`            |
| `Option<V>`     | `add f += Some(v);`   | <code>assert f === None \|\| f === Some(v);</code><br>`update f = Some(v);`                       | Output `f`            |
| &nbsp;          |                       |                                                                                                   |                       |
| `Option<V>`     | `have f >= (x);`      | <code>require x === None \|\| f === x;</code>                                                     | Input `&Option<f>`    |
| `Option<V>`     | `add f += (x);`       | <code>assert f === None \|\| x === None \|\| f === x;</code><br>`update f = if x === None { f } else { x };` | Output `Option<f>`    |
| &nbsp;          |                       |                                                                                                   |                       |
| `Map<K, V>`     | `have f >= [k => v];` | `require f.contains(k) && f.index(k) === v;`                                                      | Input `&f`            |
| `Map<K, V>`     | `add f += [k => v];`  | `assert f.contains(k) ==> f.index(k) === v;`<br>`update f = f.insert(k, v);`                      | Output `f`            |
| &nbsp;          |                       |                                                                                                   |                       |
| `Map<K, V>`     | `have f >= (x);`      | `require x.le(f);`                                                                                | Input `&Map<K, f>`    |
| `Map<K, V>`     | `add f += (x);`       | `assert x.agrees(f)`<br>`update f = f.union_prefer_right(x);`                                     | Output `Map<K, f>`    |
| &nbsp;          |                       |                                                                                                   |                       |
| `Set<V>`        | `have f >= {v};`      | `require f.contains(v);`                                                                          | Input `&f`            |
| `Set<V>`        | `add f += {v};`       | `update f = f.insert(v);`                                                                         | Output `f`            |
| &nbsp;          |                       |                                                                                                   |                       |
| `Set<V>`        | `have f >= (x);`      | `require x.subset_of(f);`                                                                         | Input `&Set<f>`       |
| `Set<V>`        | `add f += (x);`       | `update f = f.union(x);`                                                                          | Output `Set<f>`       |
| &nbsp;          |                       |                                                                                                   |                       |
| `nat`           | `have f >= (x);`      | `require f >= x;`                                                                                 | Input `&f`            |
| `nat`           | `add f += (x);`       | `update f = max(f, x);`                                                                           | Output `f`            |
| &nbsp;          |                       |                                                                                                   |                       |
| `bool`          | `have f >= true;`     | `require f == true;`                                                                              | Input `&f`            |
| `bool`          | `add f += true;`      | `update f = true;`                                                                                | Output `f`            |
| &nbsp;          |                       |                                                                                                   |                       |
| `bool`          | `have f >= (x);`      | `require x ==> f;`                                                                                | Input `&Option<f>`    |
| `bool`          | `add f += (x);`       | <code>update f = f \|\| x</code>                                                                  | Output `Option<f>`    |

### Inherent Safety Conditions

Above, we discussed the general meanings of `remove`, `have`, and `add`, which we repeat here
for reference:

| Command            | Meaning as transition on state      | Meaning for exchange function           |
|--------------------|-------------------------------------|-----------------------------------------|
| `remove f -= (x);` | `require f >= x;`<br>`update f = f - x;` | Input argument, consumed           |
| `have f >= (x);`   | `require f >= x;`                   | Input argument of type `&_`             |
| `add f += (x);`    | `assert f ## x;`<br>`update f = f · x;`  | Output argument                    |

The reader may wonder, why do we use `assert` for `add`, but not for the other two?

In the case of `remove` and `have`, we allow `f >= x` to be an enabling condition, and it is then
possible for the client of an exchange function to justify that the enabling condition is met by 
the existence of the tokens that it inputs.

In the case of `add`, however, there is no such justification because the tokens that correspond to `x`
are _output_ tokens. These tokens do not exist before the transition occurs, so we cannot use their
existence to justify the transition is safe. Rather, it is up to the developer of the transition system
to show that introducing the state given by `x` is always safe. Hence, we use `assert` to create a safety condition.
We call this the _inherent safety condition_ of the `add` command.

As with any ordinary `assert`, the developer is expected to show that it follows from the invariant
and from any preceeding enabling conditions.
If the proof, does not go through automatically, the developer can supply a proof body using `by`, e.g.,:

```rust,ignore
add f += Some(v) by {
    // proof that pre.f === None
};
```

### Init

TODO

### Pattern matching with `remove` and `have`


================
File: ./state_machines/src/SUMMARY.md
================

# Summary

[Intro](./intro.md)

# User Guide

  - [Tokenized State Machines](./tokenized.md)

    - [High-Level Idea](high-level-idea.md)

    - [Guide by example](tutorial-by-example.md)

      - [Counting to 2](./examples/counting-to-2.md)
        - [Unverified Source](./examples/rust-counting-to-2.md)
        - [Verified Source](./examples/src-counting-to-2.md)

      - [Counting to _n_](./examples/counting-to-n.md)
        - [Unverified Source](./examples/rust-counting-to-n.md)
        - [Verified Source](./examples/src-counting-to-n.md)

      - [Producer-consumer queue](./examples/producer-consumer-queue.md)
        - [Unverified Source](./examples/rust-producer-consumer-queue.md)
        - [Verified Source](./examples/src-producer-consumer-queue.md)

      - [Reference-counted smart pointer](./examples/rc.md)
        - [Unverified Source](./examples/rust-rc.md)
        - [Verified Source](./examples/src-rc.md)
        - [Exerises](./examples/rc-exercises.md)

    - [Guide TODO](tutorial-by-example.md)

      - [Counting to _n_ (again) (TODO)](./examples/counting-to-n-again.md)
      - [Hash table (TODO)](./examples/hash-table.md)
      - [Reader-writer lock (TODO)](./examples/rwlock.md)

# Reference

  - [State Machines](./state-machine-reference.md)
    - [State Machine Basics](./components.md)
    - [State Machine Macro Syntax (TODO)](./macro-high-level-reference.md)
    - [Transition Language](./transition-language.md)
    - [Invariants and Inductive Proofs](./invariants.md)
    - [Macro-generated code (TODO)](./macro-generated-reference.md)
    - [State Machine Refinements (TODO)](./refinements-reference.md)

  - [Tokenization](./tokenization-reference.md)
    - [Strategy Reference](strategy-reference.md)
      - [`option`](strategy-option.md)
    - [Formalism of Tokenization by monoids (TODO)](./monoid-formalism.md)

================
File: ./state_machines/src/monoid-formalism.md
================

Here, we provide justification for the concurrent state machine features in terms of a (pen-and-paper) monoid formalism.

Let the state machine have state `S = { f1: T1, f2: T2, ... }` with an invariant `Inv : S -> bool`.

We define a monoid `M`:

```
enum M {
    Unit,
    State(g1: S1, g2: S2, ...),
    Fail,
}
```

Each `Si` is a partial monoid defined in terms of `Ti` and its respective sharding strategy.

We let `Unit`, of course, be the unit, and we define `x · Fail = Fail` for all `x`. The composition of two `State` elements is defined pairwise, and if any of the compositions fails due to partiality, we go to the `Fail` state.

The sharding strategies are as follows, given in terms of a type `T`:

 * Strategy `variable`: We let `S` be `Option<T>` with `None` as the unit, and the composition `Some(...) · Some(...)` to be undefined.
 * Strategy `constant`: We let `S` be `Option<T>` with `None` as the unit, and the composition `Some(x) · Some(y) = if x == y { Some(x) } else { undefined }`.


For each strategy we have some map `W : S -> T`. (In all cases, the map is either the identity or `Some(_)`.) Now, define a predicate `P : M -> bool`:

```
P(Unit) = false
P(Fail) = false
P(State(g1, g2, ...)) = ∃ f1, f2, ... Inv(S(f1, f2, ...)) && Wi(fi) = gi
```

Now let `V : M -> bool` be given by:

```
V(x) = ∃ z , P(x · z)
```

The predicate `V` makes `M` a partial commutative monoid. From this, we can construct propositions (γ, m) where γ is a location and m : M under the standard rules, e.g., `(γ, m1) * (γ, m2) <==> (γ, m1 · m2)` and so on.

Now, the concurrent state machine framework produces a variety of tokens.

  * The `Instance` token (γ, c1, ..., ck) contains all the data for the fields of `constant` sharding strategy. It represents the proposition `(γ, State(...))` with fields `gi = Some(ci)` and all other fields unital. Note that this proposition is freely duplicable (because `Some(ci) · Some(ci) = Some(ci)`).
  * For (non-constant) field `f`, we create separate tokens for that field. Each token represents the same proposition as the `Instance` (which, again, is freely duplicable) and some proposition specific to the field, described below:
    * For a field `fi` of `variable` strategy, we have a token `(instance, fi)` which represents the proposition `(γ, State(...))` with field `gi = Some(fi)` (and all other fields unital).

================
File: ./state_machines/src/refinements-reference.md
================

# State Machine Refinements

================
File: ./state_machines/src/invariants.md
================

# Invariants

An _invariant_ on a transition system is a boolean predicate that must hold on any
reachable state of the system---i.e., a state reachable by starting at any `init`
and then executing a sequence of transitions.

Verus allows the user to specify an _inductive invariant_, that is, a predicate that
must satisfy the inductive criteria:

 * `init(state) ==> inv(state)`
 * `transition(pre, post) && inv(pre) ==> inv(post)`

By induction, any predicate satisfying the above criteria is necessarily a valid invariant
that holds for any reachable state.

There are many reasons the user might need to specify (and prove correct) such an invariant:

 * The invariant is needed to prove the _safety conditions_ of the state machine,
   that is, the [`assert` statements](./transition-language.md#the-assert-statement)
   that appear in any transitions or properties.
 
 * The invariant is needed to prove a [state machine refinement](./refinements-reference.md).

## Specifying the invariants

To make it easier to name individual clauses of the inductive invariant,
they are given as boolean predicates with `#[invariant]` attributes.
The boolean predicates should take a single argument, `&self`.

```rust,ignore
#[invariant]
pub fn inv_1(&self) -> bool { ... }

#[invariant]
pub fn inv_2(&self) -> bool { ... }
```

The state machine macro produces a single predicate `invariant` which is the conjunct of all the given invariants.

## Proving the inductive criteria

To prove that the invariants are correct,
the user needs to prove that every `init!` operation results in a state satisfying
the invariant, and that every `transition!` operation preserves the invariant
from one state to the next.
This is done by creating a lemma to contain the proof and annotating
it with the `inductive` attribute:

```rust,ignore
// For an `init!` routine:
#[inductive(init_name)]
fn initialize_inductive(post: Self) {
    // Proof here
}

// For a `transition!` routine:
#[inductive(transition_name)]
fn transition_inductive(pre: Self, post: Self, n: int) {
    // Proof here
} 
```

Verus requires one lemma for each `init!` and `transition!` routine, provided at least
one invariant predicate is specified.
(The lemma would be trivial for a `readonly!` transition, so for these, it is not required.)

 * For an `init!` operation, the lemma parameters should always be `post: Self, ...` where the `...` are the custom arguments to the transition.
 * For a `transition!` operation, the lemma parameters should always be `pre: Self, post: Self, ...`.

If the lemmas are omitted, then the Verus error will provide the expected type signatures in the console output.

Pre- and post-conditions for each lemma are automatically generated, so these should be left off. Specifically, the macro generates the following conditions:

```rust,ignore
// For an `init!` routine:
#[inductive(init_name)]
fn initialize_inductive(post: StateName, ...) {
    requires(init(post, ...));
    ensures(post.invariant());
    
    // ... The user's proof is placed here
} 

// For a `transition!` routine:
#[inductive(transition_name)]
fn transition_inductive(pre: StateName, post: StateName, ...) {
    requires(strong_transition(pre, post, ...) && pre.invariant());
    ensures(post.invariant());
    
    // ... The user's proof is placed here
}
```

Here, `init` and `strong_transition` refer to the relations generated from the DSL.
These contain all the predicates from the [`require` statements](./transition-language.md#the-require-statement) defined in the transition or initialization routine.

The `strong` indicates that we can assume the conditions given by any [`assert` statements](./transition-language.md#the-assert-statement) in addition to the `require` statements.
(Proof obligations for the `assert` statements are generated separately.)

## Example

(TODO should have an example)

================
File: ./state_machines/src/intro.md
================

# Intro

_**Note:** this guide is a work-in-progress._

### What's this guide about?

It's hard to say exactly what this guide is about.
It's easiest to say that it is primarily about
verifying **multi-threaded concurrent code** in [Verus](https://github.com/verus-lang/verus),
and in fact, we developed most of this framework with that goal in mind,
but these techniques are actually useful for single-threaded code, too.
We might also say that it's about verifying **code that needs unsafe features**
(especially raw pointers and unsafe cells), though again, there are plenty of use-cases
where this does not apply.

The unifying theme for the above are programs that require some kind of **nontrivial
ownership discipline**, where different objects that might be "owned independently"
need to coordinate somehow.
For example:

 * Locks need to manage ownership of some underlying resource between multiple clients.
 * Reference-counted smart pointers need to coordinate to agree on a reference-count.
 * Concurrent data structures (queues, hash tables, and so on) require their
    client threads to coordinate their access to the data structure.

This kind of nontrivial ownership can be implemented through Verus's
`tokenized_state_machine!` utility, and this utility will be the main
tool we'll learn how to use in this guide.

### Who's this guide for?

Read this if you're interested in learning how to:

 1. Verify multi-threaded concurrent code in Verus.
 2. Verify code that requires "unsafe" code in unverified Rust
    (e.g., code with raw pointers or unsafe cells)

Or if you just want to know what any of these Verus features are for:

 3. Verus's `state_machine!` or `tokenized_state_machine!` macros
 4. Verus's `tracked` variable mode ("linear ghost state").

This guide expects general familiarity with Verus, so readers unfamiliar with Verus
should check out the general [Verus user guide](https://verus-lang.github.io/verus/guide/)
first and become proficient at coding within its `spec`, `proof`, and `exec` modes,
using `ghost` and `exec` variables.

================
File: ./state_machines/src/state-machine-reference.md
================

# State Machine Basics

================
File: ./state_machines/src/components.md
================

# Components of a State Machine

The `state_machines_macros` library provides two macros, `state_machine!` and `tokenized_state_machine!`. This overview will discuss the first.

The `state_machine!` framework provides a way to establish a basic state machine, consisting of four components:

 1. The state definition
 2. The transitions (including initialization procedures)
 3. Invariants on the state
 4. Proofs that the invariants hold

Here's a very simple example:

```rust,ignore
state_machine!{
    AdderMachine {
        //// The state definition
        
        fields {
            pub number: int,
        }
        
        //// The transitions

        init!{
            initialize() {
                init number = 0;
            }
        }   

        transition!{
            add(n: int) {
                update number = pre.number + 2*n;
            }
        }
        
        //// Invariants on the state

        #[invariant]
        pub fn is_even() -> bool {
            pre.number % 2 == 0
        }
        
        //// Proofs that the invariants hold

        #[inductive(initialize)]
        fn initialize_inductive(post: AdderMachine) {
            // Verus proves that 0 % 2 == 0
        }

        #[inductive(add)]
        fn add_inductive(pre: AdderMachine, post: AdderMachine, n: int) {
            // Verus proves that if `pre.number % 2 == 0` then
            // `post.number` is `pre.number + 2*n` is divisble by 2 as well.
        }
    }
}
```

## State

The state definition is given inside a block labelled `fields` (a special keyword recognized by the `state_machine!` macro):

```rust,ignore
        fields {
            pub number: int,
        }
```

The fields are like you'd find in a struct: they must be named fields (i.e., there's no "tuple" option for the state). The fields are also implicitly `#[spec]`.

## Transitions

There are four different types of "operations": `init!`, `transition!`, `readonly!`, and `property!`. The body of the operation is a "transition DSL" which is interpretted by the macro:

 * An `init!` becomes a 1-state relation representing valid initial states of the system
 * A `transition!` becomes a 2-state relation representing a transition from one state (`pre`) to the next (`post`)
 * A `readonly!` becomes a 2-state relation where the state cannot be modified.
 * A `property!` allows the user to add safety conditions on a single state (`pre`).

When exported as relations:

 * 1-state `init!` operations take 1 argument, `pre`.
 * 2-state operations (`transition!` and `readonly!`) take 2 arguments, `pre` and `post`.
 * `property!` operations are not exported as relations.

Each operation (transition or otherwise) is deterministic in its input arguments, so any intended non-determinism should be done via the arguments.
The DSL allows the user to update fields; any field not updated is implied to remain the same.
An `init!` transition is required to initialize each field, so that the intialization is fully determined.
The DSL provides four fundamental operations (`init`, `update`, `require`, `assert`)
as detailed in the [transition language reference](./transition-language.md).
They are allowed according to the following table:

|           | `init!` | `transition!` | `readonly!` | `property!` |
|-----------|---------|---------------|-------------|-------------|
| `init`    | yes     |               |             |             |
| `update`  |         | yes           |             |             |
| `require` | yes     | yes           | yes         | yes         |
| `assert`  |         | yes           | yes         | yes         |

The distinction between `readonly!` and `property!` is somewhat pedantic: after all,
both are expressed as predicates on states which are not modified, and both
allow `require` and `assert` statements.
The difference is that
a `readonly!` operation is exported as an actual transition between `pre` and `post`
(with `pre === post`) whereas a `property!` is not exported as a transition.

## Invariants

See the documentation for [invariants](./invariants.md).

================
File: ./state_machines/src/transition-language.md
================

# Transition Language

All four operations (`init!`, `transition!`, `readonly!` and `property!`) use
the transition language (although `property!` operations are not technically transitions).
The operations can be declared like so:

```rust,ignore
transition!{
    name(params...) {
        TransitionStmt
    }
}
```

The `TransitionStmt` language allows very simple control-flow with if-else and match
statements, and allows let-bindings.

```rust,ignore
TransitionStmt :=
   | TransitionStmt; TransitionStmt;
   | if $expr { TransitionStmt }
   | if $expr { TransitionStmt } else { TransitionStmt }
   | match $expr { ( $pat => { TransitionStmt } )* }
   | let $pat = $expr;
   | SingleStmt
```

There are four fundamental statements: `init`, `update`, `require`, and `assert`.
For convenience, there are also higher-level statements that can be expressed
in those terms.

```rust,ignore
SingleStmt :=
   | init $field_name = $expr;
   | update $field_name = $expr;
   | require $bool_expr;
   | assert $bool_expr (by { ... })? ;

   // Higher-level statements:

   | require let $pat = $expr;
   | assert let $pat = $expr;
   | update $field_name ([sub_idx] | .subfield)* = $expr;
   | remove ... | have ... | add ... | deposit ... | guard ... | withdraw ...
```

Each `$field_name` should be a valid field name as declared in the `fields` block of the state machine definition.

Each `$expr`/`$bool_expr` is an ordinary [Verus (spec-mode) expression](https://verus-lang.github.io/verus/guide/operators.html).
These expressions can reference the params or bound variables.
They can also reference the pre-state of the transition, `pre` (except in `init!` operations).
(Note that it is not possible to access `post` directly,
though this may be added in the future.)

## Core statements

### The `init` statement

The `init` statement is used only in `init!` operations.
Each field of the state must be initialized exactly once in each `init!` operation.
If there is any control-flow-branching, then each field must be initialized
exactly once in each branch.

Example:

```rust,ignore
state_machine!{ InitExample {
    fields {
        pub x: int,
        pub y: int,
    }

    // Okay.
    init!{
        initialize_1(x_init_value: int) {
            init x = x_init_value;
            init y = 0;
        }
    }

    // Not okay (y is not initialized)
    init!{
        initialize_2(x_init_value: int) {
            init x = x_init_value;
        }
    }

    // Not okay (y is not initialized in the second branch)
    init!{
        initialize_3(b: bool) {
            if b {
                init x = 0;
                init y = 1;
            } else {
                init x = 5;
            }
        }
    }
}}
```

### The `update` statement

The `update` statement is the counterpart of `init` for the `transition!` operations:
it sets the value of a field for a `post` state.

However, (unlike `init`), not every field needs to be updated.
Any field for which no `update` statement appears will implicitly maintain its value
from the `pre` state.

Example:

```rust,ignore
state_machine!{ TransitionExample {
    fields {
        pub x: int,
        pub y: int,
    }

    // Okay.
    transition!{
        transition_1(x_new_value: int) {
            update x = x_new_value;
        }
    }

    // Okay.
    transition!{
        transition_2(b: bool) {
            if b {
                update x = 0;
                update y = 1;
            } else {
                update x = 5;
            }
        }
    }

    // Not okay.
    // (The first 'update' is meaningless because it is immediately overwritten.)
    transition!{
        transition_3(b: bool) {
            update x = 0;
            update x = 1;
        }
    }
}}
```

### The `require` statement

The `require` statement adds an _enabling condition_ to the operation.
This is a condition that must hold in order for the operation to be performed.
A `require` can be used in any of the operation types.

### The `assert` statement

The `assert` statement declares a _safety condition_ on the transition. Verus creates a proof obilgation for the validity of the state machine: the `assert` must follow from the state invariants, and from any enabling conditions (`require` statements) given prior to the `assert`.

If the user needs to provide manual proofs, they can do so using an assert-by:

```rust,ignore
assert $bool_expr by {
    /* proof here */
};
```

(TODO need a better example here)

Because we demand that the `assert` statement is proved,
clients of the state machine may assume that the condition holds whenever the transition is enabled (i.e., all its `require` conditions hold).
other proofs can assume that the predicate holds whenever this transition is enabled.
Therefore, the `assert` statement is not itself an enabling condition; that is, clients do not need to show the condition holds in order to show that the operation is enabled.

## High-level statements

### `require let` and `assert let`

You can write,

```rust,ignore
require let $pat = $expr;
```

where `$pat` is a _refutable_ pattern.
This is roughly equivalent to writing the following (which would ordinarily be disallowed
because of the refutable pattern).

```rust,ignore
require ($expr matches $pat);
let $pat = $expr;
```

The `assert let` statement is similar, but for `assert` instead of `require`.

Example:

```rust,ignore
state_machine!{ RequireLetExample {
    fields {
        x_opt: Option<int>,
    }

    transition!{
        add_1() {
            require let Some(x) = pre.x_opt;
            update x_opt = Some(x + 1);
        }
    }

    // Equivalent to:
    transition!{
        add_1_alternative() {
            require pre.x_opt.is_Some();
            let x = pre.x_opt.get_Some_0();
            update x_opt = Some(x + 1);
        }
    }
}}
```

### Update with subscript and fields

_**Note:** This feature is currently in-development._

To update nested data structures, you can use fields (for structs)
or subscripts (for maps or sequences) in `update` statements.
For example,

```rust,ignore
update field.x.y[idx].z[key] = expr;
```

### `remove` / `have` / `add` / `deposit` / `guard` / `withdraw`

These are complex operations used specially for specific sharding strategies
in a `tokenized_state_machine`.
See the [strategy reference](strategy-reference.md) for details.

================
File: ./state_machines/src/tokenization-reference.md
================

# Tokenization

================
File: ./state_machines/src/tokenized.md
================

# Tokenized State Machines

================
File: ./state_machines/src/token-exchanges-as-transitions.md
================

# Token exchanges as transitions

The aim of the framework of tokenized state machines is to marry the power and ergonomics of general transition systems with the token-based approach to concurrency reasoning.

To make this work, the developer has to do two special things when describing their transitions system:

 * First, they must annotate each field of their state datatype with what we call a _strategy_: the the strategy tells Verus how the state should break down into tokens.
 * Second, they must define their transitions using special commands so that the transitions can be interpretted simultaneously as [transitions on the state](./components.md)  _and_ as [token exchange functions](./thinking-tokens.md).

TODO write an explanation for why we need special transitions

================
File: ./state_machines/src/examples/counting-to-n.md
================

# Counting to _n_

Let's now generalize the [previous exercise](./counting-to-2.md) from using a fixed number
of threads (2) to using an an arbitrary number of threads. Specifically, we'll verify
the equivalent of the following Rust program:

 * The main thread instantiates a counter to 0.
 * The main thread forks `num_threads` child threads.
   * Each child thread (atomically) increments the counter.
 * The main thread joins all the threads (i.e., waits for them to complete).
 * The main thread reads the counter.

**Our objective:** Prove the counter read in the final step has value `num_threads`.

```rust,ignore
{{#include ../../../../rust_verify/example/state_machines/tutorial/unverified_counting_to_n.rs:full}}
```

## Verified implementation

We'll build off the [previous exercise](./counting-to-2.md) here, so make sure you're
familiar with that one first.

Our first step towards verifying the generalized program
is to update the `tokenized_state_machine` from the earlier example.
Recall that in that example, we had two boolean fields, `inc_a` and `inc_b`,
to represent the two tickets.
This time, we will merely maintain counts of the number of tickets:
we'll have one field for the number of unstamped tickets and one for the number
of stamped tickets.

Let's start with the updated state machine, but ignore the tokenization aspect for now.
Here's the updated state machine as an atomic state machine:

```rust,ignore
{{#include ../../../../rust_verify/example/state_machines/tutorial/counting_to_n_atomic.rs:main}}

        // ... invariant proofs here
    }
}
```

Note that we added a new field, `num_threads`, and we replaced `inc_a` and `inc_b` with `unstamped_tickets` and `stampted_tickets`.

Now, let's talk about the tokenization. In the previous example, all of our fields used the `variable` strategy, but we never got a chance to talk about what that meant. Let's now see some of the other strategies.

For our new program, we will need to make two changes.

### The `constant` strategy

First, the `num_threads` can be marked as a `constant`, since this value is really just
a parameter to the protocol, and will be fixed for any given instance of it.
By marking it `constant`, we won't get a token for it, but instead the value will be available
from the shared `Instance` object.

### The `count` strategy

This change is far more subtle. The key problem we need to solve is that the "tickets" need
to be spread across multiple threads. However, if `unstamped_tickets` and `stamped_tickets`
were marked as `variable` then we would only get one token for each field.

Recall our physical analogy with the tickets and the chalkboard (used for the `counter` field),
and compare: there's actually something fundamentally different about the tickets
and the chalkboard, which is that the tickets are actually a _count_ of something.
Think of it this way:

 * If Alice has 3 tickets, and Bob has 2 tickets, then together they have 5 tickets.
 * If Alice has a chalkboard with the number 3 written on it, and Bob has a chalkboard with the number 2 on it, then together do they have a chalkboard with the number 5 written on it?
   * No! They just have two chalkboards with 2 and 3 written on them. In fact,
     in our scenario, we aren't even supposed to have more than 1 chalkboard anyway.
     Alice and Bob are in an invalid state here.

We need a way to mark this distinction, that is, we need a way to be able to say,
"this field is a value on a chalkboard" versus "the field indicates the number of some thing".
The `variable` strategy we have been using until now is the former;
the newly introduce `count` strategy is the latter.
Thus, we need to use the `count` strategy for the ticket fields.

We need to mark the ticket fields as being a "count" of something, and this is exactly
what the `count` strategy is for. Rather than having exactly one token for the
field value, the `count` strategy will make it so that the field value is
the _sum total_ of all the tokens in the system
associated with that field. (However, this new flexibility will come
with some restrictions, as we will see.)

Here, we can visualize how the ghost tokens are spread throughout the running system,
and how they relate to the global state:

![Graphic visualization of the system state, ghost tokens, and global state](../graphics/counting-to-n-diagram.png)

In this scenario, we have three threads, all of which are currenlty executing,
where thread 2 has incremented the counter, but threads 1 and 3 have not.
Thus, threads 1 and 3 each have an "unstamped ticket" token,
while thread 2 has a "stamped ticket" token.
The abstract global state, then, has 
`unstamped_tickets == 2` and `stamped_tickets == 1`.

### Building the new `tokenized_state_machine`

First, we mark the fields with the appropriate strategies, as we discussed:

```rust,ignore
{{#include ../../../../rust_verify/example/state_machines/tutorial/counting_to_n.rs:fields}}
```

Just by marking the strategies, we can already see how it impacts the generated token code.
Let's look at `unstamped_tickets` (the `stamped_tickets` is, of course, similar):

```rust,ignore
// Code auto-generated by tokenized_state_machine! macro

#[proof]
#[verifier(unforgeable)]
pub struct unstamped_tickets {
    #[spec] pub instance: Instance,
    #[spec] pub value: nat,
}

impl unstamped_tickets {
    #[proof]
    #[verifier(returns(proof))]
    pub fn join(#[proof] self, #[proof] other: Self) -> Self {
        requires(equal(self.instance, other.instance));
        ensures(|s: Self| {
            equal(s.instance, self.instance)
                && equal(s.value, self.value + other.value)
        });

        // ...
    }

    #[proof]
    #[verifier(returns(proof))]
    pub fn split(#[proof] self, #[spec] i: nat) -> (Self, Self) {
        requires(i <= self.value);
        ensures(|s: (Self, Self)| {
             equal(s.0.instance, self.instance)
                && equal(s.1.instance, self.instance)
                && equal(s.0.value, i)
                && equal(s.1.value, self.value - i)
        });

        // ...
    }
}
```

The token type, `unstamped_tickets` comes free with 2 associated methods,
`join` and `split`. First, `join` lets us take two tokens with an associate count and
merge them together to get a single token with the combined count value;
meanwhile, `split` goes the other way.
So for example, when we start out with a single token of count `num_threads`, we can
split into `num_threads` tokens, each with count `1`.

Now, let's move on to the rest of the system.
Our invariant and the initialization routine will be identical to before.
(In general, `init` statements are used for all sharding strategies.
The sharding strategies might affect the token method that gets generated, but the
`init!` definition itself will remain the same.)

```rust,ignore
{{#include ../../../../rust_verify/example/state_machines/tutorial/counting_to_n.rs:inv}}

{{#include ../../../../rust_verify/example/state_machines/tutorial/counting_to_n.rs:init}}
```

The `tr_inc` definition is where it gets interesting. Let's take a closer look at the definition
we gave earlier:

```rust,ignore
        transition!{
            tr_inc() {
                // Replace a single unstamped ticket with a stamped ticket
                require(pre.unstamped_tickets >= 1); 
                update unstamped_tickets = pre.unstamped_tickets - 1;
                update stamped_tickets = pre.stamped_tickets + 1;

                assert(pre.counter < pre.num_threads);
                update counter = pre.counter + 1;
            }   
        }  
```

There's a problem here, which is that the operation directly accesses `pre.unstamped_tickets`
and writes to the same field with an `update` statement, and likewise for the
`stamped_tickets` field. Because these fields are marked with the `count` strategy,
Verus will reject this definition.

So why does Verus have to reject it? Keep in mind that whatever definition we give here,
Verus has to be able to create a transition definition that works in the _tokenized_
view of the world. In any tokenized transition, the tokens that serve as input must by themselves
be able to justify the validity of the transition being performed.

Unfortunately, this justification is impossible when we are using the `count` strategy.
When the field is tokenized according to the `count` strategy,
there is no way for a client to produce a set of
tokens that definitively determines the value of the `unstamped_tickets` field in the global state machine.
For instance, suppose the client provides three such tokens; this does not necessarily means
that `pre.unstamped_tickets` is equal to `3`! Rather, there might be other tokens
elsewhere in the system held on by other threads, so all we can justify from the existence
of those tokens is that `pre.unstamped_tickets` is _greater than or equal_ to 3.

Thus, Verus demands that we do not read or write to the field arbitrarily.
Effectively, we can only perform operations that look like one of the following for a `count`-strategy field:

 * Require the field's value to be greater than some natural number
 * Subtract a natural number
 * Add a natural number

Luckily, we can see that the transition from earlier only does these allowed things.
To get Verus to accept it, we only need to write the transition using a special syntax so that it can identify
the patterns involved.

```rust,ignore
{{#include ../../../../rust_verify/example/state_machines/tutorial/counting_to_n.rs:tr_inc}}
```

Generally, a `remove` corresponds to destroying a token, while `add` corresponds to creating a token. Thus the generated exchange function takes an `unstamped_tickets` token as input
and gives a `stamped_tickets` token as output.
Ultimately, thus, it exchanges an unstamped ticket for a stamped ticket.

```rust,ignore
// Code auto-generated by tokenized_state_machine! macro

#[proof]
#[verifier(returns(proof))]
pub fn tr_inc(
    #[proof] &self,
    #[proof] token_counter: &mut counter,
    #[proof] token_0_unstamped_tickets: unstamped_tickets, // input (destroyed)
) -> stamped_tickets                                       // output (created)
{
    requires([
        equal(old(token_counter).instance, (*self)),
        equal(token_0_unstamped_tickets.instance, (*self)),
        equal(token_0_unstamped_tickets.value, 1),                      // remove unstamped_tickets -= (1);
    ]);
    ensures(|token_1_stamped_tickets: stamped_tickets| {
        [
            equal(token_counter.instance, (*self)),
            equal(token_1_stamped_tickets.instance, (*self)),
            equal(token_1_stamped_tickets.value, 1),                    // add stamped_tickets += (1);
            (old(token_counter).value < (*self).num_threads()),         // assert(pre.counter < pre.num_threads);
            equal(token_counter.value, old(token_counter).value + 1),   // update counter = pre.counter + 1;
        ]
    });

    // ...
}
```

The `finalize` transition needs to be updated in a similar way:

```rust,ignore
{{#include ../../../../rust_verify/example/state_machines/tutorial/counting_to_n.rs:finalize}}
```

The `have` statement is similar to `remove`, except that it doesn't do the remove.
It just requires the client to provide tokens counting in total at least `pre.num_threads` here,
but it doesn't consume them.

Again, notice that the condition we have to write is equivalent to a `>=` condition.
We can't just require that `stamped_tickets == pre.num_threads`.

(Incidentally, it _does_ happen to be the case that `pre.stamped_tickets >= pre.num_threads`
implies that `pre.stamped_tickets == pre.num_threads`. This implication follows
from the the invariant, but it isn't something we know a priori.
Therefore, it is still the case that we have to write the transition with the weaker requirement
that `pre.stamped_tickets >= pre.num_threads`. The safety proof will then deduce that
`pre.stamped_tickets == pre.num_threads` from the invariant, and then deduce that
`pre.counter == pre.num_threads`, which is what we really want in the end.)

```rust,ignore
// Code auto-generated by tokenized_state_machine! macro

#[proof]
pub fn finalize(
    #[proof] &self,
    #[proof] token_counter: &counter,
    #[proof] token_0_stamped_tickets: &stamped_tickets,
) {
    requires([
        equal(token_counter.instance, (*self)),
        equal(token_0_stamped_tickets.instance, (*self)),
        equal(token_0_stamped_tickets.value, (*self).num_threads()),     // have stamped_tickets >= (pre.num_threads);
    ]);
    ensures([(token_counter.value == (*self).num_threads())]);           // assert(pre.counter == pre.num_threads);

    // ...
}
```

### Verified Implementation

The implementation of a thread's action hasn't change much from before. The only difference
is that we are now
exchanging an `unstamped_ticket` for a `stamped_ticket`, rather than updating a
boolean field.

```rust,ignore
{{#include ../../../../rust_verify/example/state_machines/tutorial/counting_to_n.rs:thread_run}}
```

Perhaps more interesting now is the `main` function which does the spawning and joining.
It has to spawn threads in a loop. Note that we start with a `stamped_tokens` count of
`num_threads`. Each iteration of the loop, we "peel off" a single ticket (1 unit's worth)
and pass it into the newly spawned thread.

```rust,ignore
{{#include ../../../../rust_verify/example/state_machines/tutorial/counting_to_n.rs:loop_spawn}}
```

Then, when we join the threads, we do the opposite: we collect the "stamped ticket" tokens
until we have collected all `num_threads` of them.

```rust,ignore
{{#include ../../../../rust_verify/example/state_machines/tutorial/counting_to_n.rs:loop_join}}
```

See [the full verified source](src-counting-to-n.md) for more detail.

================
File: ./state_machines/src/examples/hash-table.md
================

# Hash table (TODO)

================
File: ./state_machines/src/examples/producer-consumer-queue.md
================

# Single-Producer, Single-Consumer queue, tutorial

Here, we'll walk through an example of verifying a single-producer, single-consumer queue.
Specifically, we're interested in the following interface:

```rust,ignore
type Producer<T>
type Consumer<T>

impl<T> Producer<T> {
    pub fn enqueue(&mut self, t: T)
}

impl<T> Consumer<T> {
    pub fn dequeue(&mut self) -> T
}

pub fn new_queue<T>(len: usize) -> (Producer<T>, Consumer<T>)
```

## Unverified implementation

First, let's discuss the reference implementation, written in ordinary Rust,
that we're going to be verifying (an equivalent of).

The implementation is going to use a ring buffer of fixed length `len`,
with a `head` and a `tail` pointer,
with the producer adding new entries to the `tail` and
the consumer popping old entries from the `head`.
Thus the entries in the range `[head, tail)` will always be full.
If `head == tail` then the ring buffer will be considered empty,
and if `head > tail`, then the interval wraps around.

![Graphic visualization of ring buffer with head and tail pointers](../graphics/fifo-head-tail.png)

The crucial design choice is what data structure to use for the buffer itself.
The key requirements of the buffer are:

 * A reference to the buffer memory must be shared between threads (the producer and the consumer)
 * Each entry might or might not store a valid `T` element at any given point in time.

In our unverified Rust implementation, we'll let each entry be an [`UnsafeCell`](https://doc.rust-lang.org/stable/std/cell/struct.UnsafeCell.html).
The `UnsafeCell` gives us [interior mutability](https://doc.rust-lang.org/book/ch15-05-interior-mutability.html), so that we can
read and write the contents from multiple threads without
any extra metadata associated to each entry. `UnsafeCell` is of course, as the name suggests, _unsafe_, meaning that it's up to the programmer to ensure the all these reads and writes are performed safely. For our purposes, safely mostly means _data-race-free_.

More specifically, we'll use an `UnsafeCell<MaybeUninit<T>>` for each entry.
The [`MaybeUninit`](https://doc.rust-lang.org/stable/std/mem/union.MaybeUninit.html)
allows for the possibility that an entry is uninitialized. Like with `UnsafeCell`, there are no
runtime safety checks, so it is entirely upon the programmer to make sure it doesn't try to read
from the entry when it's uninitialized.

> **Hang on, why not just use `Option<T>`?**
> 
> To be safer, we could use an `Option<T>` instead of `MaybeUninit<T>`, but
> we are already doing low-level data management anyway, and an `Option<T>` would be less efficient.
> In particular, if we used an `Option<T>`, then popping an entry out of the queue would mean we having
> to write `None` back into the queue to signify its emptiness.
> With `MaybeUninit<T>`, we can just move the `T` out and leave the memory "uninitialized" without actually
> having to overwrite its bytes.)

So the buffer will be represented by `UnsafeCell<MaybeUninit<T>>`.
We'll also use atomics to represent the `head` and `tail`.

```rust,ignore
{{#include ../../../../rust_verify/example/state_machines/tutorial/unverified_fifo.rs:queue}}
```

The producer and consumer types will each have a reference to the queue.
Also, the producer will have a redundant copy of the `tail` (which slightly reduces contended
access to the shared atomic `tail`), and likewise,
the consumer will have a redundant copy of the `head`.
(This is possible because we only have a single producer and consumer each
the producer is the only entity that ever updates the `tail` and
the consumer is the only entity that ever updates the `head`.)

```rust,ignore
{{#include ../../../../rust_verify/example/state_machines/tutorial/unverified_fifo.rs:producer_consumer}}
```

Finally, we come to the actual implementation:

```rust,ignore
{{#include ../../../../rust_verify/example/state_machines/tutorial/unverified_fifo.rs:impl}}
```

## Verified implementation

With verification, we always need to start with the question of what, exactly, we are
verifying. In this case, we aren't actually going to add any new specifications to
the `enqueue` or `dequeue` functions; our only aim is to implement the queue and
show that it is memory-type-safe, e.g., that `dequeue` returns a well-formed `T` value without
exhibiting any undefined behavior.

Showing this is not actually trivial! The unverified Rust code above used `unsafe` code,
which means memory-type-safety is _not_ a given.

In our verified queue implementation, we will need a safe, verified alternative to the 
`unsafe` code. We'll start with introducing our verified alternative to `UnsafeCell<MaybeUninit<T>>`.

### Verified interior mutability with `PCell`

In Verus, `PCell` (standing for "permissioned cell") is the verified equivalent.
(By equivalent, we mean that, subject to inlining and the optimizations doing what we expect,
it ought to generate the same machine code.)
Unlike `UnsafeCell`, the optional-initializedness is built-in, so `PCell<T>` can stand in
for `UnsafeCell<MaybeUninit<T>>`.

In order to verify our use of `PCell`, Verus requires the user to present a special _permission token_
on each access (read or write) to the `PCell`. Each `PCell` has a unique identifier (given by `pcell.id()`)
and each permission token connects an identifier to the (possibly uninitialized value) stored at the cell.
In the permission token, this value is represented as an `Option` type, though the option tag has no runtime representation.

```rust,ignore
{{#include ../../../../rust_verify/example/state_machines/tutorial/pcell_example.rs:example}}
```

After erasure, the above code reduces to something like this:

```rust,ignore
{{#include ../../../../rust_verify/example/state_machines/tutorial/pcell_example.rs:erased}}
```

### Using `PCell` in a verified queue.

Let's look back at the Rust code from above (the code that used `UnsafeCell`) and mark six points of interest:
four places where we manipulate an atomic and two where we manipulate a cell:

```rust,ignore
impl<T> Producer<T> {
    pub fn enqueue(&mut self, t: T) {
        loop {
            let len = self.queue.buffer.len();

            let next_tail = if self.tail + 1 == len
                { 0 } else { self.tail + 1 };

            let head = self.queue.head.load(Ordering::SeqCst);                + produce_start (atomic load)
                                                                              +
            if head != next_tail as u64 {                                     +
                unsafe {                                                      +
                    (*self.queue.buffer[self.tail].get()).write(t);           +   write to cell
                }                                                             +
                                                                              +
                self.queue.tail.store(next_tail as u64, Ordering::SeqCst);    + produce_end (atomic store)
                self.tail = next_tail;

                return;
            }
        }
    }
}

impl<T> Consumer<T> {
    pub fn dequeue(&mut self) -> T {
        loop {
            let len = self.queue.buffer.len();

            let next_head = if self.head + 1 == len
                { 0 } else { self.head + 1 };

            let tail = self.queue.tail.load(Ordering::SeqCst);                + consume_start (atomic load)
                                                                              +
            if self.head as u64 != tail {                                     +
                let t = unsafe {                                              +
                    let mut tmp = MaybeUninit::uninit();                      +
                    std::mem::swap(                                           +   read from cell
                        &mut *self.queue.buffer[self.head].get(),             +
                        &mut tmp);                                            +   
                    tmp.assume_init()                                         +
                };                                                            +
                                                                              +
                self.queue.head.store(next_head as u64, Ordering::SeqCst);    + consume_end (atomic store)
                self.head = next_head;

                return t;
            }
        }
    }
}
```

Now, if we're going to be using a `PCell` instead of an `UnsafeCell`, then at the two points where we manipulate the cell,
we are somehow going to need to have the permission token at those points.

Furthermore, we have four points that manipulate atomics. _Informally_, these atomic operations let us synchronize
access to the cell in a data-race-free way. _Formally_, in the verified setting, these atomics will let us transfer control
of the permission tokens that we need to access the cells.

Specifically:

 * `enqueue` needs to obtain the permission at `produce_start`, use it to perform a write, and relinquish it at `produce_end`.
 * `dequeue` needs to obtain the permission at `consume_start`, use it to perform a read, and relinquish it at `consume_end`.

> **Woah, woah, woah. Why is this so complicated? We marked the 6 places of interest, so now let's go
> build a `tokenized_state_machine!` with those 6 transitions already!**
>
> Good question. That approach might have worked if we were using an atomic to store the value `T`
> instead of a `PCell` (although this would, of course, require the `T` to be word-sized).
>
> However, the `PCell` requires its own considerations. The crucial point is that reading or writing
> to `PCell` is _non-atomic_. That sounds tautological, but I'm not just talking about the name of
> the type here. By _atomic_ or _non-atomic_, I'm actually referring to the atomicity of the operation
> in the execution model. We can't freely abstract `PCell` operations as atomic operations that
> allow arbitrary interleaving.
>
> **Okay, so what would go wrong in Verus if we tried?**
>
> Recall how it works for atomic memory locations.
> With an atomic memory location, we can access it any time if we just have an atomic invariant
> for it. We open the invariant (acquiring permission to access the value along with any ghost data),
> perform the operation, which is atomic, and then close the invariant.
> In this scenario, the invariant is restored after a single atomic operation, as is necessary.
>
> But we can't do the same for `PCell`.
> `PCell` operations are non-atomic, so we _can't_ perform a `PCell` read or write
> while an atomic invariant is open.
> Thus, the `PCell`'s permission token needs to be transferred at the points in the program where
> we _are_ performing atomic operations, that is, at the four marked atomic operations.

### Abstracting the program while handling permissions

Verus's `tokenized_state_machine!` supports a notion called _storage_. 
An instance of a protocol is allowed to _store_ tokens, which client threads can operate on
by temporarily "checking them out". This provides a convenient means for transferring ownership of
tokens through the system.

Think of the instance as like a library. (Actually, think of it like a network of libraries with
an inter-library loan system, where the librarians tirelessly follow a protocol to make sure any
given library has a book whenever a patron is ready to check a book out.)

Anyway, the `tokenized_state_machine!` we'll use here should look something like this:

 * It should be able to _store_ all the permission tokens for each `PCell` in the buffer.
 * It should have 4 transitions:
   * `produce_start` should allow the producer to "check out" the permission for the cell that
     it is ready to write to.
   * `produce_end` should allow the producer to "check back in" the permission that it checked out.
   * `consume_start` should allow the consumer to "check out" the permission for the cell that
     it is ready to read from.
   * `consume_end` should allow the consumer to "check back in" the permission that it checked out.
 
> **Hang on, I read ahead and learned that Verus's storage mechanism has a different mechanism for handling reads. Why aren't we using that for the consumer?**
>
> A few reasons.
>
> 1. That mechanism is useful specifically for read-_sharing_, which we aren't using here.
> 2. We actually can't use it, since the "read" isn't _really_ a read. Well, at the byte-level, it
>     should just be a read. But we actually _do_ change the value that is stored there in the high-level
>     program semantics: we move the value out and replaced it with an "uninitialized" value.
>     And we have to do it this way, unless `T` implemented `Copy`.

The producer and consumer each have a small "view into the world": each one might have access to one
of the permission tokens if they have it "checked out", but that's it.

To understand the state machine protocol we're going to build, we have to look at the protocol dually to the producer
and the consumer. If the producer and consumer might have 0 or 1 permissions checked out at a given time,
then complementarily, the protocol state should be "almost all of the permissions, except possibly up to 2 permissions that
are currently checked out".

For example, here is the full sequence of operations for an `enqueue` step, both from the perspective of the producer
and of the storage protocol:

| operation         | Producer's perspective                            | Storage protocol's perspective                   |
|-------------------|---------------------------------------------------|--------------------------------------------------|
| `produce_start`   | receives a permission for an uninitialized cell   | lends out a permission for an uninitialized cell |
| write to the cell | writes to the cell with `PCell::put`              |                                                  |
| `produce_end`     | returns a permission for the now-initialized cell | receives back the permission, now initialized    |

And here is the storage protocol's perspective, graphically:

![Graphic visualizing of the storage protocol's perspective](../graphics/fifo-protocol-perspective.png)

### Building the `tokenized_state_machine!`

Now that we finally have a handle on the protocol, let's implement it. It should have all the following state:

 * The value of the shared `head` atomic
 * The value of the shared `tail` atomic
 * The producer's state
   * Is the producer step in progress?
   * Local `tail` field saved by the producer
 * The consumer's state
   * Is the consumer step in progress?
   * Local `head` field saved by the producer
 * The IDs of cells in the buffer (so we know what permissions we're meant to be storing)
 * The permissions that are actually stored.

And now, in code:

```rust,ignore
{{#include ../../../../rust_verify/example/state_machines/tutorial/fifo.rs:enum_state}}

{{#include ../../../../rust_verify/example/state_machines/tutorial/fifo.rs:fields}}
    // ...
}}
```

As you can see, Verus allows us to utilize storage by declaring it in the sharding strategy.
Here, the strategy we use is `storage_map`. In the `storage_map` strategy,
the stored token items are given by the values in the map.
The keys in the map can be an arbitrary type that we choose to use as an index to refer to
stored items. Here, the index we'll use will just the index into the queue.
Thus keys of the `storage` map will take on values in the range `[0, len)`.

> **Hmm. For a second, I thought you were going to use the cell IDs as keys in the map.
> Could it work that way as well?**
>
> Yes, although it would be slightly more complicated. For one, we'd need to track an invariant
> that all the IDs are distinct, just to show that there aren't overlapping keys.
> But that's an extra invariant to prove that we don't need if we do it this way.
> Much easier to declare a correspondance between `backing_cells[i]` and `storage[i]` for each `i`.
>
> **Wait, does that mean we _aren't_ going to prove an invariant that all the IDs are distinct?
> That can't possibly be right, right?**
>
> It _does_ mean that!
>
> Certainly, it _is_ true that in any execution of the program, the IDs of the cells are going to
> be distinct, but this isn't something we need to track ourselves as users of the `PCell` library.
>
> You might be familiar with an approach where we have some kind of "heap model," which maps
> addresses to values. When we update one entry, we have to show how nothing else of interest
> is changing. But like I just said, we aren't using that sort of heap model in the `Fifo` protocol,
> we're just indexing based on queue index. And we don't rely on any sort of heap model like that
> in the implementations of `enqueue` or `dequeue` either; there, we use the separated permission model.

Now, let's dive into the transitions. Let's start with `produce_start` transition.

```rust,ignore
{{#include ../../../../rust_verify/example/state_machines/tutorial/fifo.rs:transition_produce_start}}
```

It's a doozy, but we just need to break it down into three parts:

 * The enabling conditions (`require`).
   * The client needs to exhibit that these conditions hold
       (e.g., by doing the approparite comparison between the `head` and `tail` values) in order
       to perform the transition.
 * The stuff that gets updated:
   * We `update` the producer's local state
   * We `withdraw` ("check out") the permission, which is represented simply by removing the key from the map.
 * Guarantees about the result of the transition.
   * These guarantees will follow from internal invariants about the `FifoQueue` system
   * In this case, we care about guarantees on the permission token that is checked out.

Now, let's see `produce_end`. The main difference, here, is that the client is checking the permission token
back into the system, which means we have to provide the guarantees about the permission token
in the enabing condition rather than in a post-guarantee.

```rust,ignore
{{#include ../../../../rust_verify/example/state_machines/tutorial/fifo.rs:transition_produce_end}}
```

Check the [full source](./src-producer-consumer-queue.md) for the `consume_start` and `consume_end` transitions, which are pretty similar,
and for the invariants we use to prove that the transitions are all well-formed.

### Verified Implementation

For the implementation, let's start with the definitions for the `Producer`, `Consumer`, and `Queue` structs,
which are based on the ones from the unverified implementation, augmented with `proof` variables.
The `Producer`, for example, gets a proof token for the `producer: ProducerState` field.

The well-formedness condition here demands us to be in the `ProducerState::Idle` state
(in every call to `enqueue`, we must start and end in the `Idle` state).

```rust,ignore
{{#include ../../../../rust_verify/example/state_machines/tutorial/fifo.rs:impl_producer_struct}}
```

For the `Queue` type itself, we add an atomic invariant for the `head` and `tail` fields:

```rust,ignore
{{#include ../../../../rust_verify/example/state_machines/tutorial/fifo.rs:impl_queue_struct}}
```

Now we can implement and verify `enqueue`:

```rust,ignore
{{#include ../../../../rust_verify/example/state_machines/tutorial/fifo.rs:impl_producer}}
```

================
File: ./state_machines/src/examples/counting-to-n-again.md
================

# Counting to n (again) (TODO)

================
File: ./state_machines/src/examples/rust-producer-consumer-queue.md
================

# Single-Producer, Single-Consumer queue, unverified Rust source

```rust,ignore
{{#include ../../../../rust_verify/example/state_machines/tutorial/unverified_fifo.rs:full}}
```

================
File: ./state_machines/src/examples/src-producer-consumer-queue.md
================

# Single-Producer, Single-Consumer queue, example source

```rust,ignore
{{#include ../../../../rust_verify/example/state_machines/tutorial/fifo.rs:full}}
```

================
File: ./state_machines/src/examples/src-rc.md
================

# Reference-counted smart pointer, verified source

```rust,ignore
{{#include ../../../../rust_verify/example/state_machines/tutorial/rc.rs:full}}
```

================
File: ./state_machines/src/examples/rust-rc.md
================

# Reference-counted smart pointer, unverified Rust source

```rust,ignore
{{#include ../../../../rust_verify/example/state_machines/tutorial/unverified_rc.rs:full}}
```

================
File: ./state_machines/src/examples/rc-exercises.md
================

# Exerises

 1. Implement a thread-safe reference-counted pointer, `Arc`.
    The `Arc<T>` typed should satisfy the `Send` and `Sync` marker traits.

    Answer the following:

      (a) In terms of _executable_ code, which part of `Rc` is not thread-safe?
          How does it need to change?

      (b) In terms of _ghost_ code, which component prevents `Rc` from satisfying
         `Send` or `Sync`? What should it be changed to to support `Send` and `Sync`?

      (c) In order to make change (b), it is necessary to also make change (a).  Why?

 2. Augment the verified `Rc` to allow weak pointers.
    The allocation should include 2 counts: a strong reference count (as before)
    and a weak reference count. The inner `T` is dropped when the strong reference
    count hits 0, but the memory is not freed until both counts hit 0.
    Upgrading a weak pointer should fail in the case that the strong count has already hit 0.

    Implement the above and verify a spec like the following:

```rust
type Rc<T>
type Weak<T>

impl<T> Rc<T> {
    pub spec fn view(&self) -> T;

    pub fn new(t: T) -> (rc: Self)
        ensures rc@ === t

    pub fn clone(&self) -> (rc: Self)
        ensures rc@ === self@

    pub fn drop(self)

    pub fn borrow(&self) -> (t: &T)
        ensures *t === self@

    pub fn downgrade(&self) -> (weak: Weak<T>)
        ensures weak@ === self@
}

impl<T> Weak<T> {
    pub spec fn view(&self) -> T;

    pub fn clone(&self) -> (weak: Self)
        ensures weak@ === self@

    pub fn drop(self)

    pub fn upgrade(&self) -> (rc_opt: Option<Rc<T>>)
        ensures match rc_opt {
            None => true,
            Some(rc) => rc@ === self@,
        }
}
```

================
File: ./state_machines/src/examples/counting-to-2.md
================

# Counting to 2

Suppose we want to verify a program like the following:

 * The main thread instantiates a counter to 0.
 * The main thread forks two child threads.
   * Each child thread (atomically) increments the counter.
 * The main thread joins the two threads (i.e., waits for them to complete).
 * The main thread reads the counter.

**Our objective:** Prove the counter read in the final step has value 2.

```rust,ignore
{{#include ../../../../rust_verify/example/state_machines/tutorial/unverified_counting_to_2.rs:full}}
```

We'll walk through the verification of this snippet, starting with the planning stage.

In general, the verification of a concurrent program will look something like the following:

 * Devise an abstraction of the concurrent program. We want an abstraction that is both easy to reason about on its own, but which is “shardable” enough to capture the concurrent execution of the code.
 * Formalize the abstraction as a `tokenized_state_machine!` system. Use Verus to check that it is well-formed.
 * Implement the desired code, “annotating” it with ghost tokens provided by `tokenized_state_machine!`.

### Devising the abstraction

We'll explain our abstraction using a (possibly overwrought) analogy.

Let's imagine that the program is taking place in a classroom, with threads and other concepts personified as students.

To start, we'll use the chalkboard to represent the counter, so we'll start by writing a 0 on the chalkboard. Then we'll ask the student council president to watch the chalkboard and make sure that everybody accessing the chalkboard follows the rules.

The rule is simple: the student can walk up to the chalkboard, and if they have a ticket, they can erase the value and increment it by 1. The student council president will stamp the ticket so the same ticket can't be used again.

Now: suppose you create two tickets and give them to Alice and Bob. Then, you go take a nap, and when you come back, Alice and Bob both give you two _stamped_ tickets. Now, you go look at the chalkboard. Is it possible to see anything than 2?

No, of course not. It must say 2, since both tickets got stamped, so the chalkboard counter must have incremented 2 times.

There are some implicit assumptions here, naturally. For example, we have to assume that nobody could have forged their own ticket, or their own stamp, or remove stamps...

On the other hand—subject to the players playing by the rules of the game as we laid out—our conclusion that the chalkboard holds the number 2 holds without even making any assumptions about what Alice and Bob did while we were away. For all we know, Alice handed the ticket off to Carol who gave it to Dave, who incremented the counter, who then gave it back to Alice. Maybe Alice and Bob switched tickets. Who knows? It's all implementation details.

### Formalizing the abstraction

It's time to formalize the above intuition with a `tokenized_state_machine!`.

The machine is going to have two pieces of state: the `counter: int` (“the number on the chalkboard”) and the state representing the “tickets”. For the latter, since our example is fixed to the number `2`, we'll represent these as two separate fields, `ticket_a: bool` and `ticket_b: bool`, where `false` means an “unstamped ticket” (i.e., has not incremented the counter) and `true` represents a “stamped ticket” (i.e., _has_ incremented the counter).

(In [the next section](./counting-to-n.md) we'll see how to generalize to 2 to `n`, so we won't need a separate field for each ticket, but we'll keep things simple for now.)

Here's our first (incomplete) attempt at a definition:

```rust,ignore
tokenized_state_machine!{
    X {
        fields {
            #[sharding(variable)]
            pub counter: int,

            #[sharding(variable)]
            pub ticket_a: bool,

            #[sharding(variable)]
            pub ticket_b: bool,
        }

        init!{
            initialize() {
                init counter = 0;                   // Initialize “chalkboard” to 0
                init ticket_a = false;              // Create one “unstamped ticket”
                init ticket_b = false;              // Create another “unstamped ticket”
            }
        }

        transition!{
            do_increment_a() {
                require(!pre.ticket_a);             // Require the client to provide an “unstamped ticket”
                update counter = pre.counter + 1;   // Increment the chalkboard counter by 1
                update ticket_a = true;             // Stamp the ticket
            }
        }

        transition!{
            do_increment_b() {
                require(!pre.ticket_b);             // Require the client to provide an “unstamped ticket”
                update counter = pre.counter + 1;   // Increment the chalkboard counter by 1
                update ticket_b = true;             // Stamp the ticket
            }
        }

        readonly!{
            finalize() {
                require(pre.ticket_a);              // Given that both tickets are stamped
                require(pre.ticket_b);              // ...
                assert(pre.counter == 2);           // one can conclude the chalkboard value is 2.
            }
        }
    }
}
```

Let's take this definition one piece at a time. In the `fields` block, we declared our three states. Note that each one is tagged with a _sharding strategy_, which tells Verus how to break the state into pieces—we'll talk about that below. We'll talk more about the strategies in the next section; right now, all three of our fields use the `variable` strategy, so we don't have anything to compare to.

Now we defined four operations on the state machine. The first one is an initialization procedure, named `initialize`: It lets instantiate the protocol with the counter at 0 and with two unstamped tickets.

The transition `do_increment_a` lets the client trade in an unstamped ticket for a stamped ticket, while incrementing the counter. The transition `do_increment_b` is similar, for the `ticket_b` ticket.

Lastly, we come to the `finalize` operation. This one is `readonly!`, as it doesn't actually update any state. Instead, it lets the client _conclude_ something about the state that we read: just by having the two stamped tickets, we can conclude that the `counter` value is 2.

Let's run and see what happens.

```ignore
error: unable to prove assertion safety condition
  --> y.rs:50:17
   |
50 |                 assert(pre.counter == 2);
   |                 ^^^^^^^^^^^^^^^^^^^^^^^^^

error: aborting due to previous error; 1 warning emitted
```

Uh-oh. Verus wasn't able to prove the safety condition. Of course not—we didn't provide any invariant for our system! For all Verus knows, the state `{counter: 1, ticket_a: true, ticket_b: true}` is valid. Let's fix this up:

```rust,ignore
{{#include ../../../../rust_verify/example/state_machines/tutorial/counting_to_2.rs:inv}}
```

Our invariant is pretty straightforward: The value of the counter should be equal to the number of stamps. Now, we need to supply stub lemmas to prove that the invariant is preserved by every transition. In this case, Verus completes the proofs easily, so we don't need to supply any proofs in the lemma bodies to help out Verus.

```rust,ignore
{{#include ../../../../rust_verify/example/state_machines/tutorial/counting_to_2.rs:inv_proof}}
```

Now that we've completed our abstraction, let's turn towards the implementation.

### The Auto-generated Token API

Given a `tokenized_state_machine!` like the above, Verus will analyze it and produce a series of _token types_ representing pieces of the state, and a series of _exchange functions_ that perform the transitions on the tokens.

(TODO provide instructions for the user to get this information themselves)

Let's take a look at the tokens that Verus generates here. First, Verus generates an _Instance_ type for instances of the protocol. For the simple state machine here, this doesn't do very much other than serve as a unique identifier for each instantiation.

```rust,ignore
#[proof]
#[verifier(unforgeable)]
pub struct Instance { ... }
```

Next, we have token types that represent the actual fields of the state machine. We get one token for each field:

```rust,ignore
#[proof]
#[verifier(unforgeable)]
pub struct counter {
    #[spec] pub instance: X::Instance,
    #[spec] pub value: int,
}

#[proof]
#[verifier(unforgeable)]
pub struct ticket_a {
    #[spec] pub instance: X::Instance,
    #[spec] pub value: bool,
}

#[proof]
#[verifier(unforgeable)]
pub struct ticket_b {
    #[spec] pub instance: X::Instance,
    #[spec] pub value: bool,
}
```

For example, ownership of a token `X::counter { instance: inst, value: 5 }` represents proof that the instance `inst` of the protocol currently has its `counter` state set to `5`. With all three tokens for a given instance taken altogether, we recover the full state.

Now, let's take a look at the exchange functions. We start with `X::Instance::initialize`, generated from our declared `initialize` operation.  This function returns a fresh instance of the protocol (`X::Instance`) and tokens for each field (`X::counter`, `X::ticket_a`, and `X::ticket_b`) all initialized to the values as we declared them (`0`, `false`, and `false`).

```rust,ignore
impl Instance {
    // init!{
    //      initialize() {
    //          init counter = 0;
    //          init ticket_a = false;
    //          init ticket_b = false;
    //      }
    //  }

    #[proof]
    #[verifier(returns(proof))]
    pub fn initialize() -> (X::Instance, X::counter, X::ticket_a, X::ticket_b) {
        ensures(|tmp_tuple: (X::Instance, X::counter, X::ticket_a, X::ticket_b)| {
            [{
                let (instance, token_counter, token_ticket_a, token_ticket_b) = tmp_tuple;
                (equal(token_counter.instance, instance))
                    && (equal(token_ticket_a.instance, instance))
                    && (equal(token_ticket_b.instance, instance))
                    && (equal(token_counter.value, 0))            // init counter = 0;
                    && (equal(token_ticket_a.value, false))       // init ticket_a = false;
                    && (equal(token_ticket_b.value, false))       // init ticket_b = false;
            }]
        });
        ...
    }
```

Next, the function for the `do_increment_a` transition. Note that enabling condition in the user's declared transition
becomes a precondition for calling of `do_increment_a`. The exchange function takes a `X::counter` and `X::ticket_a` token as input,
and since the transition modifies both fields, the exchange function takes the tokens as `&mut`.

Also note, crucially, that _it does not take a `X::ticket_b` token at all_ because the transition doesn't depend on the `ticket_b` field.
The transition can be performed entirely without reference to it.

```rust,ignore
    //  transition!{
    //      do_increment_a() {
    //          require(!pre.ticket_a);
    //          update counter = pre.counter + 1;
    //          update ticket_a = true;
    //      }
    //  }

    #[proof]
    pub fn do_increment_a(
        #[proof] &self,
        #[proof] token_counter: &mut X::counter,
        #[proof] token_ticket_a: &mut X::ticket_a,
    ) {
        requires([
            equal(old(token_counter).instance, (*self)),
            equal(old(token_ticket_a).instance, (*self)),
            (!old(token_ticket_a).value),                        // require(!pre.ticket_a)
        ]);
        ensures([
            equal(token_counter.instance, (*self)),
            equal(token_ticket_a.instance, (*self)),
            equal(token_counter.value, old(token_counter).value + 1),   // update counter = pre.counter + 1
            equal(token_ticket_a.value, true),                          // update ticket_a = true
        ]);
        ...
    }
```

The function for the `do_increment_b` transition is similar:

```rust,ignore
    //  transition!{
    //      do_increment_b() {
    //          require(!pre.ticket_b);
    //          update counter = pre.counter + 1;
    //          update ticket_b = true;
    //      }
    //  }

    #[proof]
    pub fn do_increment_b(
        #[proof] &self,
        #[proof] token_counter: &mut X::counter,
        #[proof] token_ticket_b: &mut X::ticket_b,
    ) {
        requires([
            equal(old(token_counter).instance, (*self)),
            equal(old(token_ticket_b).instance, (*self)),
            (!old(token_ticket_b).value),                        // require(!pre.ticket_b)
        ]);
        ensures([
            equal(token_counter.instance, (*self)),
            equal(token_ticket_b.instance, (*self)),
            equal(token_counter.value, old(token_counter).value + 1),   // update counter = pre.counter + 1
            equal(token_ticket_b.value, true),                          // update ticket_b = true
        ]);
        ...
    }
```

Finally, we come to the `finalize` operation. Again this is a “no-op” transition that doesn't update any fields, so the generated exchange method takes the tokens as readonly parameters (non-mutable borrows).  Here, we observe that the `assert` becomes a post-condition, that is, by performing this operation, though it does not update any state, causes us to learn something about that state.

```rust,ignore
    //  readonly!{
    //      finalize() {
    //          require(pre.ticket_a);
    //          require(pre.ticket_b);
    //          assert(pre.counter == 2);
    //      }
    //  }

    #[proof]
    pub fn finalize(
        #[proof] &self,
        #[proof] token_counter: &X::counter,
        #[proof] token_ticket_a: &X::ticket_a,
        #[proof] token_ticket_b: &X::,
    ) {
        requires([
            equal(token_counter.instance, (*self)),
            equal(token_ticket_a.instance, (*self)),
            equal(token_ticket_b.instance, (*self)),
            (token_ticket_a.value),                     // require(pre.ticket_a)
            (token_ticket_b.value),                     // require(pre.ticket_b)
        ]);
        ensures([token_counter.value == 2]);            // assert(pre.counter == 2)
        ...
    }
}
```

### Writing the verified implementation

To verify the implementation, our plan is to instantiate this ghost protocol and associate
the `counter` field of the protocol to the atomic memory location we use in our code.

To do this, we'll use the Verus library `atomic_ghost`.
Specifically, we'll use the type `atomic_ghost::AtomicU32<X::counter>`.
This is a wrapper around an `AtomicU32` location which associates it to a `tracked`
ghost token `X::counter`.

More specifically, all threads will share this global state:

```rust,ignore
{{#include ../../../../rust_verify/example/state_machines/tutorial/counting_to_2.rs:global_struct}}
```

Note that we track `instance` as a separate field. This ensures that all threads agree
on which instance of the protocol they are running.

(Keep in mind that whenever we perform a transition on the ghost tokens, all the tokens
have to have the same instance. Why does Verus enforce restriction? Because if it did not,
then the programmer could instantiate two instances of the protocol, the mix-and-match to get
into an invalid state. For example, they could increment the counter twice, using up
both "tickets" of that instance, and then use the ticket of another instance to increment
it a third time.)

TODO finish writing the explanation

================
File: ./state_machines/src/examples/rc.md
================

# Reference-counted smart pointer, tutorial

Our next example is a reference-counted smart pointer like
[`Rc`](https://doc.rust-lang.org/std/rc/struct.Rc.html).

We're going to focus on 4 functions: `new`, `clone`, and `drop`, and `borrow`.
The `clone` and `drop` functions will be incrementing and decrementing
the reference count, and `drop` will be responsible for freeing memory when
the count hits zero.
Meanwhile, the `borrow` function provides access to the underlying data.
Recall that since `Rc` is a shareable pointer, the underlying data must be
accessed via shared pointer.

```rust,ignore
type Rc<T>

impl<T> Rc<T> {
    pub spec fn view(&self) -> T;

    pub fn new(t: T) -> (rc: Self)
        ensures rc@ === t

    pub fn clone(&self) -> (rc: Self)
        ensures rc@ === self@

    pub fn drop(self)

    pub fn borrow(&self) -> (t: &T)
        ensures *t === self@
}
```

In terms of specification, the `view()` interpretation of an `Rc<T>` object
will simply be the underlying `T`, as is reflected in the post-conditions above.

**NOTE:** A current limitation, at the time of writing, is that
Verus doesn't yet have proper support for `Drop`,
so the `drop` function of our `Rc` here needs to be called manually to avoid
memory leaks.

## Unverified implementation

As usual, we'll start with an unverified implementation.

```rust,ignore
{{#include ../../../../rust_verify/example/state_machines/tutorial/unverified_rc.rs:full}}
```

## Verified implementation

The main challenge here is to figure out what structure the ghost code will take.

 * We need a "something" that will let us get the `&PointsTo` object that we need
    to dereference the pointer. This has to be a shared reference by necessity.
 * The "something" needs to be duplicateable somehow; we need to obtain a new one whenever
    we call `Rc::clone`.
     * The counter, somehow, needs to correspond to the number of "somethings" in existence.
       In other words, we should be able to get a new "something" when we increment
       the counter, and we should destroy a "something" when we decrement it.
 * We need a way to obtain ownership of the the `PointsTo` object for the `PCell`
    storing the counter, so that we can write to it.

Let's stop being coy and name the ghost components. The "something" is the driver of action
here, so let's go ahead and call it a `ref`.
Let's have another ghost object called a `counter`---the `counter` counts the `ref`s.
The ghost `counter` needs to be tied to the actual `u64` counter,
which we will do with a `LocalInvariant`.

Therefore, an `Rc` ought to have:

 * A `ref` object, which will somehow let us obtain access a `&ptr::PointsTo<InnerRc>`.
 * A `LocalInvariant` storing both a `counter` and a `cell::PointsTo<u64>`.

![Graphic visualization of the ghost structure of the Rc](../graphics/rc-ghost-diagram.png)

Now, with this rough plan in place, we can finally begin devising our `tokenized_state_machine`
to define the `ref` and `counter` tokens along with the relationship between the
`ref` token and the `ptr::PointsTo`.

![Graphic visualization of the ghost structure of the Rc](../graphics/rc-ghost-diagram-ghost-only.png)

```rust
{{#include ../../../../rust_verify/example/state_machines/tutorial/rc.rs:fields}}
```

TODO - finish the rest of this tutorial

================
File: ./state_machines/src/examples/rust-counting-to-2.md
================

# Counting to 2, unverified Rust source

```rust,ignore
{{#include ../../../../rust_verify/example/state_machines/tutorial/unverified_counting_to_2.rs:full}}
```

================
File: ./state_machines/src/examples/refcount.md
================

# Reference-counted memory (TODO)

================
File: ./state_machines/src/examples/src-counting-to-n.md
================

# Counting to _n_, verified source

```rust,ignore
{{#include ../../../../rust_verify/example/state_machines/tutorial/counting_to_n.rs:full}}
```

================
File: ./state_machines/src/examples/rwlock.md
================

# Reader-writer lock (TODO)

================
File: ./state_machines/src/examples/src-counting-to-2.md
================

# Counting to 2, verified source

```rust,ignore
{{#include ../../../../rust_verify/example/state_machines/tutorial/counting_to_2.rs:full}}
```

================
File: ./state_machines/src/examples/rust-counting-to-n.md
================

# Counting to _n_, unverified Rust source

```rust,ignore
{{#include ../../../../rust_verify/example/state_machines/tutorial/unverified_counting_to_n.rs:full}}
```

================
File: ./state_machines/src/strategy-option.md
================

# The `option` strategy

The `option` strategy can be applied to fields of type `Option<V>` for any type `V`.

```rust
fields {
    #[sharding(option)]
    pub field: Option<V>,
}
```

This creates a token type, `State::field`, which a field `value: V`.
When `field` is `None`, this corresponds to no token existing, while
when `field` is `Some(v)`, this corresponds to a token of value `v` existing.
Having multiple such tokens at the same time is an impossible state.

### Quick Reference

<div class="table-wrapper" style="font-size: 13px"><table>
  <colgroup>
     <col span="1" style="width: 40%;">
     <col span="1" style="width: 45%;">
     <col span="1" style="width: 15%;">
  </colgroup>
  <thead>
    <tr>
      <th>Command</th>
      <th>Meaning in transition</th>
      <th>Exchange Fn Parameter</th>
    </tr>
  </thead>
  <tbody>
    <tr><td></td><td></td><td></td></tr>
    <tr>
      <td><code>init field = v_opt;</code></td>
      <td><code>init field = v_opt;</code></td>
      <td>Output <code>Option&lt;State::field&gt;</code></td>
    </tr> <tr>
      <td><code>remove field -= Some(v);</code></td>
      <td><code>require field === Some(v);</code><br><code>update field = None;</code></td>
      <td>Input <code>State::field</code></td>
    </tr> <tr>
      <td><code>have field &gt;= Some(v);</code></td>
      <td><code>require field === Some(v);</code></td>
      <td>Input <code>&amp;State::field</code></td>
    </tr> <tr>
      <td><code>add field += Some(v);</code></td>
      <td><code>assert field === None;</code><br><code>update field = Some(v);</code></td>
      <td>Output <code>State::field</code></td>
    </tr> <tr>
      <td><code>remove field -= (v_opt);</code></td>
      <td><code style="white-space: pre">require v_opt === None || field === v_opt;
update field = if v_opt === None { field }
               else { None };</code></td>
      <td>Input <code>Option&lt;State::field&gt;</code></td>
    </tr> <tr>
      <td><code>have field &gt;= (v_opt);</code></td>
      <td><code>require v_opt === None || field === v_opt;</code></td>
      <td>Input <code>&amp;Option&lt;State::field&gt;</code></td>
    </tr> <tr>
      <td><code>add field += (v_opt);</code></td>
      <td><code style="white-space: pre">assert field === None || v_opt === None;
update field = if v_opt === None { field }
               else { v_opt };</code></td>
      <td>Output <code>Option&lt;State::field&gt;</code></td>
    </tr>
  </tbody>
</table></div>

### Initializing the field

Initializing the field is done with the usual `init` statement (as it for all strategies).

```rust
init field = opt_v;
```

The instance-init function will return a token of type `Option<State::field>`,
related as follows:

<table>
  <tr>
    <th>value of <code>opt_v: V</code></th>
    <th>&nbsp;&nbsp;&nbsp;value of optional token <code>Option&lt;State::field></code></th>
  </tr>
  <tr>
    <td><code>None</code></td>
    <td><code>None</code></td>
  </tr>
  <tr>
    <td><code>Some(v)</code></td>
    <td><code>Some(tok)</code> where <code>tok@.value === v</code></td>
  </tr>
</table>

### Adding a token

To write an operation that _creates_ a token with value `v`,
equivalently,
updating the field's value from `None` to `Some(v)`, write, inside any `transition!`
operation:

```rust
add field += Some(v);
```

This operation has an inherent safety condition that the prior value of `field` is `None`.
The resulting token exchange function will return a token of type `State::field`
and with value `v`.

If you require manual proof to prove the inherent safety condition, you can add
an optional `by` clause:

```rust
add field += Some(v)
by {
    // proof goes here
};
```

### Removing a token

To write an operation that _removes_ a token with value `v`,
equivalently,
updating the field's value from `Some(v)` to `None`, write, inside any `transition!`
operation:

```rust
remove field -= Some(v);
```

The resulting exchange function will consume a `State::field` token with value `v`
as a parameter.

Instead of specifying `v` as an exact expression, you can also pattern-match
by using the `let` keyword.

```rust
remove field -= Some(let $pat);
```

This will require the prior value of `field` to match `Some($pat)`,
and this statement binds all the variables in `$pat` for use later in the transition.

### Checking the value of the token

To check the value of the token without removing it,
write, inside any `transition!`, `readonly!` or `property!` operation:

```rust
have field >= Some(v);
```

The resulting exchange function will accept an immutable reference
`&State::field` (that is, it takes the token as input but does not consume it).

Instead of specifying `v` as an exact expression, you can also pattern-match
by using the `let` keyword.

```rust
have field >= Some(let $pat);
```

This will require the prior value of `field` to match `Some($pat)`,
and this statement binds all the variables in `$pat` for use later in the transition.

### Updating a token

To update the value of an `option` token, first `remove` it, then `add` it,
in sequence.

```rust
remove field -= Some(let _);
add field += Some(new_v);
```

### Operations that manipulate optional tokens

You can also write versions of the above operations that operate on optional tokens.
These operations are equivalent to above versions whenever `opt_v = Some(v)`,
and they are all no-ops when `opt_v = None`.

To create an `Option<State::field>`:

```rust
add field += (opt_v);
```

To consume an `Option<State::field>`:

```rust
remove field -= (opt_v);
```

To check the value of an `Option<State::field>`:

```rust
have field >= (opt_v);
```


The value of `opt_v` is related to the value of `Option<State::field>`
as [they are for initialization](#initializing-the-field).

## Example

```rust,ignore
{{#include ../../../rust_verify/example/state_machines/reference-examples/strategy_option.rs:full}}
```

================
File: ./state_machines/src/tokenized-overview.md
================

# Overview (TODO)

================
File: ./state_machines/src/tutorial-by-example.md
================

# Tutorial by example

In this section, we will walk through a series of increasingly complex examples to illustrate how to use Verus's `tokenized_state_machine!` framework to verify concurrent programs.

================
File: ./state_machines/src/macro-high-level-reference.md
================

# State Machine Macro Syntax (TODO)

================
File: ./state_machines/src/high-level-idea.md
================

# High-Level Concepts

The approach we follow for each of the examples follows roughly this high-level recipe:

 1. Consider the program you want to verify.
 2. Create an "abstraction" of the program as a tokenized state machine.
 3. Verus will automatically produce for you a bunch of ghost "token types" that make up the
    tokenized state machine.
 4. Implement a verified program using the token types

That doesn't sound too bad, but there's a bit of an art to it, especially in step (2).
To build a proper abstraction, one needs to choose an abstraction which is both abstract
enough that it's easy to prove the relevant properties about, but still concrete enough
that it can be properly connected back to the implementation in step (4).
Choosing this abstraction requires one to identify which pieces of state need to be
in the abstraction, as well as which "tokenization strategy" to use---that's a concept
we'll be introducing soon.

In the upcoming examples, we'll look at a variety of scenarios and the techniques
we can use to tackle them.

